{
  "metadata": {
    "description": "Complete operator instances extracted from 34 AI models",
    "total_operators": 6244,
    "source": "Het-Benchmark Model Dataset"
  },
  "operators": [
    {
      "op_id": "Qwen2.5_7B_op_1",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Embedding",
      "name": "embed_tokens",
      "layer": "global",
      "parameters": 544538624,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_2",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "norm",
      "layer": "global",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_3",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "lm_head",
      "layer": "global",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_4",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_q_proj",
      "layer": "layer_0",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_5",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_k_proj",
      "layer": "layer_0",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_6",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_v_proj",
      "layer": "layer_0",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_7",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_o_proj",
      "layer": "layer_0",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_8",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_gate_proj",
      "layer": "layer_0",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_9",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_up_proj",
      "layer": "layer_0",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_10",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_down_proj",
      "layer": "layer_0",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_11",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer0_input_layernorm",
      "layer": "layer_0",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_12",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer0_post_attention_layernorm",
      "layer": "layer_0",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_13",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_14",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_15",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer0_attention_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_16",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_q_proj",
      "layer": "layer_1",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_17",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_k_proj",
      "layer": "layer_1",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_18",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_v_proj",
      "layer": "layer_1",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_19",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_o_proj",
      "layer": "layer_1",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_20",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_gate_proj",
      "layer": "layer_1",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_21",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_up_proj",
      "layer": "layer_1",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_22",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_down_proj",
      "layer": "layer_1",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_23",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer1_input_layernorm",
      "layer": "layer_1",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_24",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer1_post_attention_layernorm",
      "layer": "layer_1",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_25",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_26",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_27",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer1_attention_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_28",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_q_proj",
      "layer": "layer_2",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_29",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_k_proj",
      "layer": "layer_2",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_30",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_v_proj",
      "layer": "layer_2",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_31",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_o_proj",
      "layer": "layer_2",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_32",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_gate_proj",
      "layer": "layer_2",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_33",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_up_proj",
      "layer": "layer_2",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_34",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_down_proj",
      "layer": "layer_2",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_35",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer2_input_layernorm",
      "layer": "layer_2",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_36",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer2_post_attention_layernorm",
      "layer": "layer_2",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_37",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_38",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_39",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer2_attention_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_40",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_q_proj",
      "layer": "layer_3",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_41",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_k_proj",
      "layer": "layer_3",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_42",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_v_proj",
      "layer": "layer_3",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_43",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_o_proj",
      "layer": "layer_3",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_44",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_gate_proj",
      "layer": "layer_3",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_45",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_up_proj",
      "layer": "layer_3",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_46",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_down_proj",
      "layer": "layer_3",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_47",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer3_input_layernorm",
      "layer": "layer_3",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_48",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer3_post_attention_layernorm",
      "layer": "layer_3",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_49",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_50",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_51",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer3_attention_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_52",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_q_proj",
      "layer": "layer_4",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_53",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_k_proj",
      "layer": "layer_4",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_54",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_v_proj",
      "layer": "layer_4",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_55",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_o_proj",
      "layer": "layer_4",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_56",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_gate_proj",
      "layer": "layer_4",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_57",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_up_proj",
      "layer": "layer_4",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_58",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_down_proj",
      "layer": "layer_4",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_59",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer4_input_layernorm",
      "layer": "layer_4",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_60",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer4_post_attention_layernorm",
      "layer": "layer_4",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_61",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_62",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_63",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer4_attention_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_64",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_q_proj",
      "layer": "layer_5",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_65",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_k_proj",
      "layer": "layer_5",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_66",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_v_proj",
      "layer": "layer_5",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_67",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_o_proj",
      "layer": "layer_5",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_68",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_gate_proj",
      "layer": "layer_5",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_69",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_up_proj",
      "layer": "layer_5",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_70",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_down_proj",
      "layer": "layer_5",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_71",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer5_input_layernorm",
      "layer": "layer_5",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_72",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer5_post_attention_layernorm",
      "layer": "layer_5",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_73",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_74",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_75",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer5_attention_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_76",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_q_proj",
      "layer": "layer_6",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_77",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_k_proj",
      "layer": "layer_6",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_78",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_v_proj",
      "layer": "layer_6",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_79",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_o_proj",
      "layer": "layer_6",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_80",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_gate_proj",
      "layer": "layer_6",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_81",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_up_proj",
      "layer": "layer_6",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_82",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_down_proj",
      "layer": "layer_6",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_83",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer6_input_layernorm",
      "layer": "layer_6",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_84",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer6_post_attention_layernorm",
      "layer": "layer_6",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_85",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_86",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_87",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer6_attention_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_88",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_q_proj",
      "layer": "layer_7",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_89",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_k_proj",
      "layer": "layer_7",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_90",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_v_proj",
      "layer": "layer_7",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_91",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_o_proj",
      "layer": "layer_7",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_92",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_gate_proj",
      "layer": "layer_7",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_93",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_up_proj",
      "layer": "layer_7",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_94",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_down_proj",
      "layer": "layer_7",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_95",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer7_input_layernorm",
      "layer": "layer_7",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_96",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer7_post_attention_layernorm",
      "layer": "layer_7",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_97",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_98",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_99",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer7_attention_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_100",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_q_proj",
      "layer": "layer_8",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_101",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_k_proj",
      "layer": "layer_8",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_102",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_v_proj",
      "layer": "layer_8",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_103",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_o_proj",
      "layer": "layer_8",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_104",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_gate_proj",
      "layer": "layer_8",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_105",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_up_proj",
      "layer": "layer_8",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_106",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_down_proj",
      "layer": "layer_8",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_107",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer8_input_layernorm",
      "layer": "layer_8",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_108",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer8_post_attention_layernorm",
      "layer": "layer_8",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_109",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_110",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_111",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer8_attention_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_112",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_q_proj",
      "layer": "layer_9",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_113",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_k_proj",
      "layer": "layer_9",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_114",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_v_proj",
      "layer": "layer_9",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_115",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_o_proj",
      "layer": "layer_9",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_116",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_gate_proj",
      "layer": "layer_9",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_117",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_up_proj",
      "layer": "layer_9",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_118",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_down_proj",
      "layer": "layer_9",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_119",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer9_input_layernorm",
      "layer": "layer_9",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_120",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer9_post_attention_layernorm",
      "layer": "layer_9",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_121",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_122",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_123",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer9_attention_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_124",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_q_proj",
      "layer": "layer_10",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_125",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_k_proj",
      "layer": "layer_10",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_126",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_v_proj",
      "layer": "layer_10",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_127",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_o_proj",
      "layer": "layer_10",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_128",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_gate_proj",
      "layer": "layer_10",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_129",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_up_proj",
      "layer": "layer_10",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_130",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_down_proj",
      "layer": "layer_10",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_131",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer10_input_layernorm",
      "layer": "layer_10",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_132",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer10_post_attention_layernorm",
      "layer": "layer_10",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_133",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_134",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_135",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer10_attention_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_136",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_q_proj",
      "layer": "layer_11",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_137",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_k_proj",
      "layer": "layer_11",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_138",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_v_proj",
      "layer": "layer_11",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_139",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_o_proj",
      "layer": "layer_11",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_140",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_gate_proj",
      "layer": "layer_11",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_141",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_up_proj",
      "layer": "layer_11",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_142",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_down_proj",
      "layer": "layer_11",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_143",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer11_input_layernorm",
      "layer": "layer_11",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_144",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer11_post_attention_layernorm",
      "layer": "layer_11",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_145",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_146",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_147",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer11_attention_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_148",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_q_proj",
      "layer": "layer_12",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_149",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_k_proj",
      "layer": "layer_12",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_150",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_v_proj",
      "layer": "layer_12",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_151",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_o_proj",
      "layer": "layer_12",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_152",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_gate_proj",
      "layer": "layer_12",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_153",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_up_proj",
      "layer": "layer_12",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_154",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_down_proj",
      "layer": "layer_12",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_155",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer12_input_layernorm",
      "layer": "layer_12",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_156",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer12_post_attention_layernorm",
      "layer": "layer_12",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_157",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer12_attention_softmax",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_158",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer12_activation",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_159",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer12_attention_dropout",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_160",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_q_proj",
      "layer": "layer_13",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_161",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_k_proj",
      "layer": "layer_13",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_162",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_v_proj",
      "layer": "layer_13",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_163",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_o_proj",
      "layer": "layer_13",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_164",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_gate_proj",
      "layer": "layer_13",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_165",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_up_proj",
      "layer": "layer_13",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_166",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_down_proj",
      "layer": "layer_13",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_167",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer13_input_layernorm",
      "layer": "layer_13",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_168",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer13_post_attention_layernorm",
      "layer": "layer_13",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_169",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer13_attention_softmax",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_170",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer13_activation",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_171",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer13_attention_dropout",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_172",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_q_proj",
      "layer": "layer_14",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_173",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_k_proj",
      "layer": "layer_14",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_174",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_v_proj",
      "layer": "layer_14",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_175",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_o_proj",
      "layer": "layer_14",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_176",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_gate_proj",
      "layer": "layer_14",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_177",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_up_proj",
      "layer": "layer_14",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_178",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_down_proj",
      "layer": "layer_14",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_179",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer14_input_layernorm",
      "layer": "layer_14",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_180",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer14_post_attention_layernorm",
      "layer": "layer_14",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_181",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer14_attention_softmax",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_182",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer14_activation",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_183",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer14_attention_dropout",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_184",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_q_proj",
      "layer": "layer_15",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_185",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_k_proj",
      "layer": "layer_15",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_186",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_v_proj",
      "layer": "layer_15",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_187",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_o_proj",
      "layer": "layer_15",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_188",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_gate_proj",
      "layer": "layer_15",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_189",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_up_proj",
      "layer": "layer_15",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_190",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_down_proj",
      "layer": "layer_15",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_191",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer15_input_layernorm",
      "layer": "layer_15",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_192",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer15_post_attention_layernorm",
      "layer": "layer_15",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_193",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer15_attention_softmax",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_194",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer15_activation",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_195",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer15_attention_dropout",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_196",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_q_proj",
      "layer": "layer_16",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_197",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_k_proj",
      "layer": "layer_16",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_198",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_v_proj",
      "layer": "layer_16",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_199",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_o_proj",
      "layer": "layer_16",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_200",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_gate_proj",
      "layer": "layer_16",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_201",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_up_proj",
      "layer": "layer_16",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_202",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_down_proj",
      "layer": "layer_16",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_203",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer16_input_layernorm",
      "layer": "layer_16",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_204",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer16_post_attention_layernorm",
      "layer": "layer_16",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_205",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer16_attention_softmax",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_206",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer16_activation",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_207",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer16_attention_dropout",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_208",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_q_proj",
      "layer": "layer_17",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_209",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_k_proj",
      "layer": "layer_17",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_210",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_v_proj",
      "layer": "layer_17",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_211",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_o_proj",
      "layer": "layer_17",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_212",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_gate_proj",
      "layer": "layer_17",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_213",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_up_proj",
      "layer": "layer_17",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_214",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_down_proj",
      "layer": "layer_17",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_215",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer17_input_layernorm",
      "layer": "layer_17",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_216",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer17_post_attention_layernorm",
      "layer": "layer_17",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_217",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer17_attention_softmax",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_218",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer17_activation",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_219",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer17_attention_dropout",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_220",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_q_proj",
      "layer": "layer_18",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_221",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_k_proj",
      "layer": "layer_18",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_222",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_v_proj",
      "layer": "layer_18",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_223",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_o_proj",
      "layer": "layer_18",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_224",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_gate_proj",
      "layer": "layer_18",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_225",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_up_proj",
      "layer": "layer_18",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_226",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_down_proj",
      "layer": "layer_18",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_227",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer18_input_layernorm",
      "layer": "layer_18",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_228",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer18_post_attention_layernorm",
      "layer": "layer_18",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_229",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer18_attention_softmax",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_230",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer18_activation",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_231",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer18_attention_dropout",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_232",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_q_proj",
      "layer": "layer_19",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_233",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_k_proj",
      "layer": "layer_19",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_234",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_v_proj",
      "layer": "layer_19",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_235",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_o_proj",
      "layer": "layer_19",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_236",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_gate_proj",
      "layer": "layer_19",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_237",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_up_proj",
      "layer": "layer_19",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_238",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_down_proj",
      "layer": "layer_19",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_239",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer19_input_layernorm",
      "layer": "layer_19",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_240",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer19_post_attention_layernorm",
      "layer": "layer_19",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_241",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer19_attention_softmax",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_242",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer19_activation",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_243",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer19_attention_dropout",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_244",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_q_proj",
      "layer": "layer_20",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_245",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_k_proj",
      "layer": "layer_20",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_246",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_v_proj",
      "layer": "layer_20",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_247",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_o_proj",
      "layer": "layer_20",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_248",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_gate_proj",
      "layer": "layer_20",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_249",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_up_proj",
      "layer": "layer_20",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_250",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_down_proj",
      "layer": "layer_20",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_251",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer20_input_layernorm",
      "layer": "layer_20",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_252",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer20_post_attention_layernorm",
      "layer": "layer_20",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_253",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer20_attention_softmax",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_254",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer20_activation",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_255",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer20_attention_dropout",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_256",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_q_proj",
      "layer": "layer_21",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_257",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_k_proj",
      "layer": "layer_21",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_258",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_v_proj",
      "layer": "layer_21",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_259",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_o_proj",
      "layer": "layer_21",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_260",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_gate_proj",
      "layer": "layer_21",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_261",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_up_proj",
      "layer": "layer_21",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_262",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_down_proj",
      "layer": "layer_21",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_263",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer21_input_layernorm",
      "layer": "layer_21",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_264",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer21_post_attention_layernorm",
      "layer": "layer_21",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_265",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer21_attention_softmax",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_266",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer21_activation",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_267",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer21_attention_dropout",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_268",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_q_proj",
      "layer": "layer_22",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_269",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_k_proj",
      "layer": "layer_22",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_270",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_v_proj",
      "layer": "layer_22",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_271",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_o_proj",
      "layer": "layer_22",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_272",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_gate_proj",
      "layer": "layer_22",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_273",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_up_proj",
      "layer": "layer_22",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_274",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_down_proj",
      "layer": "layer_22",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_275",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer22_input_layernorm",
      "layer": "layer_22",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_276",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer22_post_attention_layernorm",
      "layer": "layer_22",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_277",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer22_attention_softmax",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_278",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer22_activation",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_279",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer22_attention_dropout",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_280",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_q_proj",
      "layer": "layer_23",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_281",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_k_proj",
      "layer": "layer_23",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_282",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_v_proj",
      "layer": "layer_23",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_283",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_o_proj",
      "layer": "layer_23",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_284",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_gate_proj",
      "layer": "layer_23",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_285",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_up_proj",
      "layer": "layer_23",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_286",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_down_proj",
      "layer": "layer_23",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_287",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer23_input_layernorm",
      "layer": "layer_23",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_288",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer23_post_attention_layernorm",
      "layer": "layer_23",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_289",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer23_attention_softmax",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_290",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer23_activation",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_291",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer23_attention_dropout",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_292",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_q_proj",
      "layer": "layer_24",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_293",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_k_proj",
      "layer": "layer_24",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_294",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_v_proj",
      "layer": "layer_24",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_295",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_o_proj",
      "layer": "layer_24",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_296",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_gate_proj",
      "layer": "layer_24",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_297",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_up_proj",
      "layer": "layer_24",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_298",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_down_proj",
      "layer": "layer_24",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_299",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer24_input_layernorm",
      "layer": "layer_24",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_300",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer24_post_attention_layernorm",
      "layer": "layer_24",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_301",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer24_attention_softmax",
      "layer": "layer_24",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_302",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer24_activation",
      "layer": "layer_24",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_303",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer24_attention_dropout",
      "layer": "layer_24",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_304",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_q_proj",
      "layer": "layer_25",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_305",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_k_proj",
      "layer": "layer_25",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_306",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_v_proj",
      "layer": "layer_25",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_307",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_o_proj",
      "layer": "layer_25",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_308",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_gate_proj",
      "layer": "layer_25",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_309",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_up_proj",
      "layer": "layer_25",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_310",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_down_proj",
      "layer": "layer_25",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_311",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer25_input_layernorm",
      "layer": "layer_25",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_312",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer25_post_attention_layernorm",
      "layer": "layer_25",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_313",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer25_attention_softmax",
      "layer": "layer_25",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_314",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer25_activation",
      "layer": "layer_25",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_315",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer25_attention_dropout",
      "layer": "layer_25",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_316",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_q_proj",
      "layer": "layer_26",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_317",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_k_proj",
      "layer": "layer_26",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_318",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_v_proj",
      "layer": "layer_26",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_319",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_o_proj",
      "layer": "layer_26",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_320",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_gate_proj",
      "layer": "layer_26",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_321",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_up_proj",
      "layer": "layer_26",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_322",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_down_proj",
      "layer": "layer_26",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_323",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer26_input_layernorm",
      "layer": "layer_26",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_324",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer26_post_attention_layernorm",
      "layer": "layer_26",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_325",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer26_attention_softmax",
      "layer": "layer_26",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_326",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer26_activation",
      "layer": "layer_26",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_327",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer26_attention_dropout",
      "layer": "layer_26",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_328",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_q_proj",
      "layer": "layer_27",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_329",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_k_proj",
      "layer": "layer_27",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_330",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_v_proj",
      "layer": "layer_27",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_331",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_o_proj",
      "layer": "layer_27",
      "parameters": 12845056,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_332",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_gate_proj",
      "layer": "layer_27",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_333",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_up_proj",
      "layer": "layer_27",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_334",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_down_proj",
      "layer": "layer_27",
      "parameters": 67895296,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Qwen2.5_7B_op_335",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer27_input_layernorm",
      "layer": "layer_27",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_336",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer27_post_attention_layernorm",
      "layer": "layer_27",
      "parameters": 3584,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Qwen2.5_7B_op_337",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer27_attention_softmax",
      "layer": "layer_27",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Qwen2.5_7B_op_338",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer27_activation",
      "layer": "layer_27",
      "parameters": 0,
      "input_shape": "[batch, seq, 18944]",
      "output_shape": "[batch, seq, 18944]"
    },
    {
      "op_id": "Qwen2.5_7B_op_339",
      "model_name": "Qwen2.5-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer27_attention_dropout",
      "layer": "layer_27",
      "parameters": 0,
      "input_shape": "[batch, seq, 3584]",
      "output_shape": "[batch, seq, 3584]"
    },
    {
      "op_id": "Mistral_7B_op_1",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Embedding",
      "name": "embed_tokens",
      "layer": "global",
      "parameters": 131072000,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_2",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "norm",
      "layer": "global",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_3",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "lm_head",
      "layer": "global",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_4",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_q_proj",
      "layer": "layer_0",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_5",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_k_proj",
      "layer": "layer_0",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_6",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_v_proj",
      "layer": "layer_0",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_7",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_o_proj",
      "layer": "layer_0",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_8",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_gate_proj",
      "layer": "layer_0",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_9",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_up_proj",
      "layer": "layer_0",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_10",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_down_proj",
      "layer": "layer_0",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_11",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer0_input_layernorm",
      "layer": "layer_0",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_12",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer0_post_attention_layernorm",
      "layer": "layer_0",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_13",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_14",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_15",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer0_attention_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_16",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_q_proj",
      "layer": "layer_1",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_17",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_k_proj",
      "layer": "layer_1",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_18",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_v_proj",
      "layer": "layer_1",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_19",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_o_proj",
      "layer": "layer_1",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_20",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_gate_proj",
      "layer": "layer_1",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_21",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_up_proj",
      "layer": "layer_1",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_22",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_down_proj",
      "layer": "layer_1",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_23",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer1_input_layernorm",
      "layer": "layer_1",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_24",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer1_post_attention_layernorm",
      "layer": "layer_1",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_25",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_26",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_27",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer1_attention_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_28",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_q_proj",
      "layer": "layer_2",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_29",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_k_proj",
      "layer": "layer_2",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_30",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_v_proj",
      "layer": "layer_2",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_31",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_o_proj",
      "layer": "layer_2",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_32",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_gate_proj",
      "layer": "layer_2",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_33",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_up_proj",
      "layer": "layer_2",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_34",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_down_proj",
      "layer": "layer_2",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_35",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer2_input_layernorm",
      "layer": "layer_2",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_36",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer2_post_attention_layernorm",
      "layer": "layer_2",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_37",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_38",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_39",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer2_attention_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_40",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_q_proj",
      "layer": "layer_3",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_41",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_k_proj",
      "layer": "layer_3",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_42",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_v_proj",
      "layer": "layer_3",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_43",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_o_proj",
      "layer": "layer_3",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_44",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_gate_proj",
      "layer": "layer_3",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_45",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_up_proj",
      "layer": "layer_3",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_46",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_down_proj",
      "layer": "layer_3",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_47",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer3_input_layernorm",
      "layer": "layer_3",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_48",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer3_post_attention_layernorm",
      "layer": "layer_3",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_49",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_50",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_51",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer3_attention_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_52",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_q_proj",
      "layer": "layer_4",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_53",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_k_proj",
      "layer": "layer_4",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_54",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_v_proj",
      "layer": "layer_4",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_55",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_o_proj",
      "layer": "layer_4",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_56",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_gate_proj",
      "layer": "layer_4",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_57",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_up_proj",
      "layer": "layer_4",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_58",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_down_proj",
      "layer": "layer_4",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_59",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer4_input_layernorm",
      "layer": "layer_4",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_60",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer4_post_attention_layernorm",
      "layer": "layer_4",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_61",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_62",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_63",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer4_attention_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_64",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_q_proj",
      "layer": "layer_5",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_65",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_k_proj",
      "layer": "layer_5",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_66",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_v_proj",
      "layer": "layer_5",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_67",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_o_proj",
      "layer": "layer_5",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_68",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_gate_proj",
      "layer": "layer_5",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_69",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_up_proj",
      "layer": "layer_5",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_70",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_down_proj",
      "layer": "layer_5",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_71",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer5_input_layernorm",
      "layer": "layer_5",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_72",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer5_post_attention_layernorm",
      "layer": "layer_5",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_73",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_74",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_75",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer5_attention_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_76",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_q_proj",
      "layer": "layer_6",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_77",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_k_proj",
      "layer": "layer_6",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_78",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_v_proj",
      "layer": "layer_6",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_79",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_o_proj",
      "layer": "layer_6",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_80",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_gate_proj",
      "layer": "layer_6",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_81",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_up_proj",
      "layer": "layer_6",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_82",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_down_proj",
      "layer": "layer_6",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_83",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer6_input_layernorm",
      "layer": "layer_6",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_84",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer6_post_attention_layernorm",
      "layer": "layer_6",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_85",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_86",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_87",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer6_attention_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_88",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_q_proj",
      "layer": "layer_7",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_89",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_k_proj",
      "layer": "layer_7",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_90",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_v_proj",
      "layer": "layer_7",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_91",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_o_proj",
      "layer": "layer_7",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_92",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_gate_proj",
      "layer": "layer_7",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_93",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_up_proj",
      "layer": "layer_7",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_94",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_down_proj",
      "layer": "layer_7",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_95",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer7_input_layernorm",
      "layer": "layer_7",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_96",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer7_post_attention_layernorm",
      "layer": "layer_7",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_97",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_98",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_99",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer7_attention_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_100",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_q_proj",
      "layer": "layer_8",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_101",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_k_proj",
      "layer": "layer_8",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_102",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_v_proj",
      "layer": "layer_8",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_103",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_o_proj",
      "layer": "layer_8",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_104",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_gate_proj",
      "layer": "layer_8",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_105",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_up_proj",
      "layer": "layer_8",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_106",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_down_proj",
      "layer": "layer_8",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_107",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer8_input_layernorm",
      "layer": "layer_8",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_108",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer8_post_attention_layernorm",
      "layer": "layer_8",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_109",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_110",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_111",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer8_attention_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_112",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_q_proj",
      "layer": "layer_9",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_113",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_k_proj",
      "layer": "layer_9",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_114",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_v_proj",
      "layer": "layer_9",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_115",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_o_proj",
      "layer": "layer_9",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_116",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_gate_proj",
      "layer": "layer_9",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_117",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_up_proj",
      "layer": "layer_9",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_118",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_down_proj",
      "layer": "layer_9",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_119",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer9_input_layernorm",
      "layer": "layer_9",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_120",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer9_post_attention_layernorm",
      "layer": "layer_9",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_121",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_122",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_123",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer9_attention_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_124",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_q_proj",
      "layer": "layer_10",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_125",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_k_proj",
      "layer": "layer_10",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_126",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_v_proj",
      "layer": "layer_10",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_127",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_o_proj",
      "layer": "layer_10",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_128",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_gate_proj",
      "layer": "layer_10",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_129",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_up_proj",
      "layer": "layer_10",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_130",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_down_proj",
      "layer": "layer_10",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_131",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer10_input_layernorm",
      "layer": "layer_10",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_132",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer10_post_attention_layernorm",
      "layer": "layer_10",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_133",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_134",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_135",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer10_attention_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_136",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_q_proj",
      "layer": "layer_11",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_137",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_k_proj",
      "layer": "layer_11",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_138",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_v_proj",
      "layer": "layer_11",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_139",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_o_proj",
      "layer": "layer_11",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_140",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_gate_proj",
      "layer": "layer_11",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_141",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_up_proj",
      "layer": "layer_11",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_142",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_down_proj",
      "layer": "layer_11",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_143",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer11_input_layernorm",
      "layer": "layer_11",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_144",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer11_post_attention_layernorm",
      "layer": "layer_11",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_145",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_146",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_147",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer11_attention_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_148",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_q_proj",
      "layer": "layer_12",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_149",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_k_proj",
      "layer": "layer_12",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_150",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_v_proj",
      "layer": "layer_12",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_151",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_o_proj",
      "layer": "layer_12",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_152",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_gate_proj",
      "layer": "layer_12",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_153",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_up_proj",
      "layer": "layer_12",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_154",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_down_proj",
      "layer": "layer_12",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_155",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer12_input_layernorm",
      "layer": "layer_12",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_156",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer12_post_attention_layernorm",
      "layer": "layer_12",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_157",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer12_attention_softmax",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_158",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer12_activation",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_159",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer12_attention_dropout",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_160",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_q_proj",
      "layer": "layer_13",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_161",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_k_proj",
      "layer": "layer_13",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_162",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_v_proj",
      "layer": "layer_13",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_163",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_o_proj",
      "layer": "layer_13",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_164",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_gate_proj",
      "layer": "layer_13",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_165",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_up_proj",
      "layer": "layer_13",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_166",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_down_proj",
      "layer": "layer_13",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_167",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer13_input_layernorm",
      "layer": "layer_13",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_168",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer13_post_attention_layernorm",
      "layer": "layer_13",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_169",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer13_attention_softmax",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_170",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer13_activation",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_171",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer13_attention_dropout",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_172",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_q_proj",
      "layer": "layer_14",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_173",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_k_proj",
      "layer": "layer_14",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_174",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_v_proj",
      "layer": "layer_14",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_175",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_o_proj",
      "layer": "layer_14",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_176",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_gate_proj",
      "layer": "layer_14",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_177",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_up_proj",
      "layer": "layer_14",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_178",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_down_proj",
      "layer": "layer_14",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_179",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer14_input_layernorm",
      "layer": "layer_14",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_180",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer14_post_attention_layernorm",
      "layer": "layer_14",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_181",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer14_attention_softmax",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_182",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer14_activation",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_183",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer14_attention_dropout",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_184",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_q_proj",
      "layer": "layer_15",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_185",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_k_proj",
      "layer": "layer_15",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_186",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_v_proj",
      "layer": "layer_15",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_187",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_o_proj",
      "layer": "layer_15",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_188",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_gate_proj",
      "layer": "layer_15",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_189",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_up_proj",
      "layer": "layer_15",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_190",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_down_proj",
      "layer": "layer_15",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_191",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer15_input_layernorm",
      "layer": "layer_15",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_192",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer15_post_attention_layernorm",
      "layer": "layer_15",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_193",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer15_attention_softmax",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_194",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer15_activation",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_195",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer15_attention_dropout",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_196",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_q_proj",
      "layer": "layer_16",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_197",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_k_proj",
      "layer": "layer_16",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_198",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_v_proj",
      "layer": "layer_16",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_199",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_o_proj",
      "layer": "layer_16",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_200",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_gate_proj",
      "layer": "layer_16",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_201",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_up_proj",
      "layer": "layer_16",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_202",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_down_proj",
      "layer": "layer_16",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_203",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer16_input_layernorm",
      "layer": "layer_16",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_204",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer16_post_attention_layernorm",
      "layer": "layer_16",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_205",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer16_attention_softmax",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_206",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer16_activation",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_207",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer16_attention_dropout",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_208",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_q_proj",
      "layer": "layer_17",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_209",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_k_proj",
      "layer": "layer_17",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_210",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_v_proj",
      "layer": "layer_17",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_211",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_o_proj",
      "layer": "layer_17",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_212",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_gate_proj",
      "layer": "layer_17",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_213",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_up_proj",
      "layer": "layer_17",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_214",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_down_proj",
      "layer": "layer_17",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_215",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer17_input_layernorm",
      "layer": "layer_17",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_216",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer17_post_attention_layernorm",
      "layer": "layer_17",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_217",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer17_attention_softmax",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_218",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer17_activation",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_219",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer17_attention_dropout",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_220",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_q_proj",
      "layer": "layer_18",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_221",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_k_proj",
      "layer": "layer_18",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_222",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_v_proj",
      "layer": "layer_18",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_223",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_o_proj",
      "layer": "layer_18",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_224",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_gate_proj",
      "layer": "layer_18",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_225",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_up_proj",
      "layer": "layer_18",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_226",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_down_proj",
      "layer": "layer_18",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_227",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer18_input_layernorm",
      "layer": "layer_18",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_228",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer18_post_attention_layernorm",
      "layer": "layer_18",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_229",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer18_attention_softmax",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_230",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer18_activation",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_231",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer18_attention_dropout",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_232",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_q_proj",
      "layer": "layer_19",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_233",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_k_proj",
      "layer": "layer_19",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_234",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_v_proj",
      "layer": "layer_19",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_235",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_o_proj",
      "layer": "layer_19",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_236",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_gate_proj",
      "layer": "layer_19",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_237",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_up_proj",
      "layer": "layer_19",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_238",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_down_proj",
      "layer": "layer_19",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_239",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer19_input_layernorm",
      "layer": "layer_19",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_240",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer19_post_attention_layernorm",
      "layer": "layer_19",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_241",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer19_attention_softmax",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_242",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer19_activation",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_243",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer19_attention_dropout",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_244",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_q_proj",
      "layer": "layer_20",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_245",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_k_proj",
      "layer": "layer_20",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_246",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_v_proj",
      "layer": "layer_20",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_247",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_o_proj",
      "layer": "layer_20",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_248",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_gate_proj",
      "layer": "layer_20",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_249",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_up_proj",
      "layer": "layer_20",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_250",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_down_proj",
      "layer": "layer_20",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_251",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer20_input_layernorm",
      "layer": "layer_20",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_252",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer20_post_attention_layernorm",
      "layer": "layer_20",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_253",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer20_attention_softmax",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_254",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer20_activation",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_255",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer20_attention_dropout",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_256",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_q_proj",
      "layer": "layer_21",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_257",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_k_proj",
      "layer": "layer_21",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_258",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_v_proj",
      "layer": "layer_21",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_259",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_o_proj",
      "layer": "layer_21",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_260",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_gate_proj",
      "layer": "layer_21",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_261",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_up_proj",
      "layer": "layer_21",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_262",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_down_proj",
      "layer": "layer_21",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_263",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer21_input_layernorm",
      "layer": "layer_21",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_264",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer21_post_attention_layernorm",
      "layer": "layer_21",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_265",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer21_attention_softmax",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_266",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer21_activation",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_267",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer21_attention_dropout",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_268",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_q_proj",
      "layer": "layer_22",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_269",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_k_proj",
      "layer": "layer_22",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_270",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_v_proj",
      "layer": "layer_22",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_271",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_o_proj",
      "layer": "layer_22",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_272",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_gate_proj",
      "layer": "layer_22",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_273",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_up_proj",
      "layer": "layer_22",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_274",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_down_proj",
      "layer": "layer_22",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_275",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer22_input_layernorm",
      "layer": "layer_22",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_276",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer22_post_attention_layernorm",
      "layer": "layer_22",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_277",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer22_attention_softmax",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_278",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer22_activation",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_279",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer22_attention_dropout",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_280",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_q_proj",
      "layer": "layer_23",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_281",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_k_proj",
      "layer": "layer_23",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_282",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_v_proj",
      "layer": "layer_23",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_283",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_o_proj",
      "layer": "layer_23",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_284",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_gate_proj",
      "layer": "layer_23",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_285",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_up_proj",
      "layer": "layer_23",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_286",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_down_proj",
      "layer": "layer_23",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_287",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer23_input_layernorm",
      "layer": "layer_23",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_288",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer23_post_attention_layernorm",
      "layer": "layer_23",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_289",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer23_attention_softmax",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_290",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer23_activation",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_291",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer23_attention_dropout",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_292",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_q_proj",
      "layer": "layer_24",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_293",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_k_proj",
      "layer": "layer_24",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_294",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_v_proj",
      "layer": "layer_24",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_295",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_o_proj",
      "layer": "layer_24",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_296",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_gate_proj",
      "layer": "layer_24",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_297",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_up_proj",
      "layer": "layer_24",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_298",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_down_proj",
      "layer": "layer_24",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_299",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer24_input_layernorm",
      "layer": "layer_24",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_300",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer24_post_attention_layernorm",
      "layer": "layer_24",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_301",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer24_attention_softmax",
      "layer": "layer_24",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_302",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer24_activation",
      "layer": "layer_24",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_303",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer24_attention_dropout",
      "layer": "layer_24",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_304",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_q_proj",
      "layer": "layer_25",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_305",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_k_proj",
      "layer": "layer_25",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_306",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_v_proj",
      "layer": "layer_25",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_307",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_o_proj",
      "layer": "layer_25",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_308",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_gate_proj",
      "layer": "layer_25",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_309",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_up_proj",
      "layer": "layer_25",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_310",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_down_proj",
      "layer": "layer_25",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_311",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer25_input_layernorm",
      "layer": "layer_25",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_312",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer25_post_attention_layernorm",
      "layer": "layer_25",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_313",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer25_attention_softmax",
      "layer": "layer_25",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_314",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer25_activation",
      "layer": "layer_25",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_315",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer25_attention_dropout",
      "layer": "layer_25",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_316",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_q_proj",
      "layer": "layer_26",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_317",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_k_proj",
      "layer": "layer_26",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_318",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_v_proj",
      "layer": "layer_26",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_319",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_o_proj",
      "layer": "layer_26",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_320",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_gate_proj",
      "layer": "layer_26",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_321",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_up_proj",
      "layer": "layer_26",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_322",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_down_proj",
      "layer": "layer_26",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_323",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer26_input_layernorm",
      "layer": "layer_26",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_324",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer26_post_attention_layernorm",
      "layer": "layer_26",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_325",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer26_attention_softmax",
      "layer": "layer_26",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_326",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer26_activation",
      "layer": "layer_26",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_327",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer26_attention_dropout",
      "layer": "layer_26",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_328",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_q_proj",
      "layer": "layer_27",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_329",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_k_proj",
      "layer": "layer_27",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_330",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_v_proj",
      "layer": "layer_27",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_331",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_o_proj",
      "layer": "layer_27",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_332",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_gate_proj",
      "layer": "layer_27",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_333",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_up_proj",
      "layer": "layer_27",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_334",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_down_proj",
      "layer": "layer_27",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_335",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer27_input_layernorm",
      "layer": "layer_27",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_336",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer27_post_attention_layernorm",
      "layer": "layer_27",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_337",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer27_attention_softmax",
      "layer": "layer_27",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_338",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer27_activation",
      "layer": "layer_27",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_339",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer27_attention_dropout",
      "layer": "layer_27",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_340",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_q_proj",
      "layer": "layer_28",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_341",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_k_proj",
      "layer": "layer_28",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_342",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_v_proj",
      "layer": "layer_28",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_343",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_o_proj",
      "layer": "layer_28",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_344",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_gate_proj",
      "layer": "layer_28",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_345",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_up_proj",
      "layer": "layer_28",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_346",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_down_proj",
      "layer": "layer_28",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_347",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer28_input_layernorm",
      "layer": "layer_28",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_348",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer28_post_attention_layernorm",
      "layer": "layer_28",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_349",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer28_attention_softmax",
      "layer": "layer_28",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_350",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer28_activation",
      "layer": "layer_28",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_351",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer28_attention_dropout",
      "layer": "layer_28",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_352",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_q_proj",
      "layer": "layer_29",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_353",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_k_proj",
      "layer": "layer_29",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_354",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_v_proj",
      "layer": "layer_29",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_355",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_o_proj",
      "layer": "layer_29",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_356",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_gate_proj",
      "layer": "layer_29",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_357",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_up_proj",
      "layer": "layer_29",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_358",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_down_proj",
      "layer": "layer_29",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_359",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer29_input_layernorm",
      "layer": "layer_29",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_360",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer29_post_attention_layernorm",
      "layer": "layer_29",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_361",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer29_attention_softmax",
      "layer": "layer_29",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_362",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer29_activation",
      "layer": "layer_29",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_363",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer29_attention_dropout",
      "layer": "layer_29",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_364",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_q_proj",
      "layer": "layer_30",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_365",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_k_proj",
      "layer": "layer_30",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_366",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_v_proj",
      "layer": "layer_30",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_367",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_o_proj",
      "layer": "layer_30",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_368",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_gate_proj",
      "layer": "layer_30",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_369",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_up_proj",
      "layer": "layer_30",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_370",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_down_proj",
      "layer": "layer_30",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_371",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer30_input_layernorm",
      "layer": "layer_30",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_372",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer30_post_attention_layernorm",
      "layer": "layer_30",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_373",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer30_attention_softmax",
      "layer": "layer_30",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_374",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer30_activation",
      "layer": "layer_30",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_375",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer30_attention_dropout",
      "layer": "layer_30",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_376",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_q_proj",
      "layer": "layer_31",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_377",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_k_proj",
      "layer": "layer_31",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_378",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_v_proj",
      "layer": "layer_31",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_379",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_o_proj",
      "layer": "layer_31",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_380",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_gate_proj",
      "layer": "layer_31",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_381",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_up_proj",
      "layer": "layer_31",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_382",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_down_proj",
      "layer": "layer_31",
      "parameters": 58720256,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Mistral_7B_op_383",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer31_input_layernorm",
      "layer": "layer_31",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_384",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer31_post_attention_layernorm",
      "layer": "layer_31",
      "parameters": 4096,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Mistral_7B_op_385",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer31_attention_softmax",
      "layer": "layer_31",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Mistral_7B_op_386",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer31_activation",
      "layer": "layer_31",
      "parameters": 0,
      "input_shape": "[batch, seq, 14336]",
      "output_shape": "[batch, seq, 14336]"
    },
    {
      "op_id": "Mistral_7B_op_387",
      "model_name": "Mistral-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer31_attention_dropout",
      "layer": "layer_31",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Phi_3_mini_op_1",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Embedding",
      "name": "embed_tokens",
      "layer": "global",
      "parameters": 98500608,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_2",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "norm",
      "layer": "global",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_3",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "lm_head",
      "layer": "global",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_4",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_q_proj",
      "layer": "layer_0",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_5",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_k_proj",
      "layer": "layer_0",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_6",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_v_proj",
      "layer": "layer_0",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_7",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_o_proj",
      "layer": "layer_0",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_8",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_gate_proj",
      "layer": "layer_0",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_9",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_up_proj",
      "layer": "layer_0",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_10",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_down_proj",
      "layer": "layer_0",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_11",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer0_input_layernorm",
      "layer": "layer_0",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_12",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer0_post_attention_layernorm",
      "layer": "layer_0",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_13",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_14",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_15",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer0_attention_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_16",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_q_proj",
      "layer": "layer_1",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_17",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_k_proj",
      "layer": "layer_1",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_18",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_v_proj",
      "layer": "layer_1",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_19",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_o_proj",
      "layer": "layer_1",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_20",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_gate_proj",
      "layer": "layer_1",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_21",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_up_proj",
      "layer": "layer_1",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_22",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_down_proj",
      "layer": "layer_1",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_23",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer1_input_layernorm",
      "layer": "layer_1",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_24",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer1_post_attention_layernorm",
      "layer": "layer_1",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_25",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_26",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_27",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer1_attention_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_28",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_q_proj",
      "layer": "layer_2",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_29",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_k_proj",
      "layer": "layer_2",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_30",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_v_proj",
      "layer": "layer_2",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_31",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_o_proj",
      "layer": "layer_2",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_32",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_gate_proj",
      "layer": "layer_2",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_33",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_up_proj",
      "layer": "layer_2",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_34",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_down_proj",
      "layer": "layer_2",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_35",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer2_input_layernorm",
      "layer": "layer_2",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_36",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer2_post_attention_layernorm",
      "layer": "layer_2",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_37",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_38",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_39",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer2_attention_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_40",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_q_proj",
      "layer": "layer_3",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_41",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_k_proj",
      "layer": "layer_3",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_42",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_v_proj",
      "layer": "layer_3",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_43",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_o_proj",
      "layer": "layer_3",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_44",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_gate_proj",
      "layer": "layer_3",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_45",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_up_proj",
      "layer": "layer_3",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_46",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_down_proj",
      "layer": "layer_3",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_47",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer3_input_layernorm",
      "layer": "layer_3",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_48",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer3_post_attention_layernorm",
      "layer": "layer_3",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_49",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_50",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_51",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer3_attention_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_52",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_q_proj",
      "layer": "layer_4",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_53",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_k_proj",
      "layer": "layer_4",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_54",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_v_proj",
      "layer": "layer_4",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_55",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_o_proj",
      "layer": "layer_4",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_56",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_gate_proj",
      "layer": "layer_4",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_57",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_up_proj",
      "layer": "layer_4",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_58",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_down_proj",
      "layer": "layer_4",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_59",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer4_input_layernorm",
      "layer": "layer_4",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_60",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer4_post_attention_layernorm",
      "layer": "layer_4",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_61",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_62",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_63",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer4_attention_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_64",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_q_proj",
      "layer": "layer_5",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_65",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_k_proj",
      "layer": "layer_5",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_66",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_v_proj",
      "layer": "layer_5",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_67",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_o_proj",
      "layer": "layer_5",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_68",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_gate_proj",
      "layer": "layer_5",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_69",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_up_proj",
      "layer": "layer_5",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_70",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_down_proj",
      "layer": "layer_5",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_71",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer5_input_layernorm",
      "layer": "layer_5",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_72",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer5_post_attention_layernorm",
      "layer": "layer_5",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_73",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_74",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_75",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer5_attention_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_76",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_q_proj",
      "layer": "layer_6",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_77",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_k_proj",
      "layer": "layer_6",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_78",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_v_proj",
      "layer": "layer_6",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_79",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_o_proj",
      "layer": "layer_6",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_80",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_gate_proj",
      "layer": "layer_6",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_81",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_up_proj",
      "layer": "layer_6",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_82",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_down_proj",
      "layer": "layer_6",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_83",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer6_input_layernorm",
      "layer": "layer_6",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_84",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer6_post_attention_layernorm",
      "layer": "layer_6",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_85",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_86",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_87",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer6_attention_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_88",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_q_proj",
      "layer": "layer_7",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_89",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_k_proj",
      "layer": "layer_7",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_90",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_v_proj",
      "layer": "layer_7",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_91",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_o_proj",
      "layer": "layer_7",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_92",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_gate_proj",
      "layer": "layer_7",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_93",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_up_proj",
      "layer": "layer_7",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_94",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_down_proj",
      "layer": "layer_7",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_95",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer7_input_layernorm",
      "layer": "layer_7",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_96",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer7_post_attention_layernorm",
      "layer": "layer_7",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_97",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_98",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_99",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer7_attention_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_100",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_q_proj",
      "layer": "layer_8",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_101",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_k_proj",
      "layer": "layer_8",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_102",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_v_proj",
      "layer": "layer_8",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_103",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_o_proj",
      "layer": "layer_8",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_104",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_gate_proj",
      "layer": "layer_8",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_105",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_up_proj",
      "layer": "layer_8",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_106",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_down_proj",
      "layer": "layer_8",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_107",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer8_input_layernorm",
      "layer": "layer_8",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_108",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer8_post_attention_layernorm",
      "layer": "layer_8",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_109",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_110",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_111",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer8_attention_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_112",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_q_proj",
      "layer": "layer_9",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_113",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_k_proj",
      "layer": "layer_9",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_114",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_v_proj",
      "layer": "layer_9",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_115",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_o_proj",
      "layer": "layer_9",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_116",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_gate_proj",
      "layer": "layer_9",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_117",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_up_proj",
      "layer": "layer_9",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_118",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_down_proj",
      "layer": "layer_9",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_119",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer9_input_layernorm",
      "layer": "layer_9",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_120",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer9_post_attention_layernorm",
      "layer": "layer_9",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_121",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_122",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_123",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer9_attention_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_124",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_q_proj",
      "layer": "layer_10",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_125",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_k_proj",
      "layer": "layer_10",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_126",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_v_proj",
      "layer": "layer_10",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_127",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_o_proj",
      "layer": "layer_10",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_128",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_gate_proj",
      "layer": "layer_10",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_129",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_up_proj",
      "layer": "layer_10",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_130",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_down_proj",
      "layer": "layer_10",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_131",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer10_input_layernorm",
      "layer": "layer_10",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_132",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer10_post_attention_layernorm",
      "layer": "layer_10",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_133",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_134",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_135",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer10_attention_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_136",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_q_proj",
      "layer": "layer_11",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_137",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_k_proj",
      "layer": "layer_11",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_138",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_v_proj",
      "layer": "layer_11",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_139",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_o_proj",
      "layer": "layer_11",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_140",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_gate_proj",
      "layer": "layer_11",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_141",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_up_proj",
      "layer": "layer_11",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_142",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_down_proj",
      "layer": "layer_11",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_143",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer11_input_layernorm",
      "layer": "layer_11",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_144",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer11_post_attention_layernorm",
      "layer": "layer_11",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_145",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_146",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_147",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer11_attention_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_148",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_q_proj",
      "layer": "layer_12",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_149",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_k_proj",
      "layer": "layer_12",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_150",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_v_proj",
      "layer": "layer_12",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_151",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_o_proj",
      "layer": "layer_12",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_152",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_gate_proj",
      "layer": "layer_12",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_153",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_up_proj",
      "layer": "layer_12",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_154",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_down_proj",
      "layer": "layer_12",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_155",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer12_input_layernorm",
      "layer": "layer_12",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_156",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer12_post_attention_layernorm",
      "layer": "layer_12",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_157",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer12_attention_softmax",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_158",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer12_activation",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_159",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer12_attention_dropout",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_160",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_q_proj",
      "layer": "layer_13",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_161",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_k_proj",
      "layer": "layer_13",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_162",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_v_proj",
      "layer": "layer_13",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_163",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_o_proj",
      "layer": "layer_13",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_164",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_gate_proj",
      "layer": "layer_13",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_165",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_up_proj",
      "layer": "layer_13",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_166",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_down_proj",
      "layer": "layer_13",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_167",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer13_input_layernorm",
      "layer": "layer_13",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_168",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer13_post_attention_layernorm",
      "layer": "layer_13",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_169",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer13_attention_softmax",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_170",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer13_activation",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_171",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer13_attention_dropout",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_172",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_q_proj",
      "layer": "layer_14",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_173",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_k_proj",
      "layer": "layer_14",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_174",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_v_proj",
      "layer": "layer_14",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_175",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_o_proj",
      "layer": "layer_14",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_176",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_gate_proj",
      "layer": "layer_14",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_177",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_up_proj",
      "layer": "layer_14",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_178",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_down_proj",
      "layer": "layer_14",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_179",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer14_input_layernorm",
      "layer": "layer_14",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_180",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer14_post_attention_layernorm",
      "layer": "layer_14",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_181",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer14_attention_softmax",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_182",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer14_activation",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_183",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer14_attention_dropout",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_184",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_q_proj",
      "layer": "layer_15",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_185",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_k_proj",
      "layer": "layer_15",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_186",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_v_proj",
      "layer": "layer_15",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_187",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_o_proj",
      "layer": "layer_15",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_188",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_gate_proj",
      "layer": "layer_15",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_189",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_up_proj",
      "layer": "layer_15",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_190",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_down_proj",
      "layer": "layer_15",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_191",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer15_input_layernorm",
      "layer": "layer_15",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_192",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer15_post_attention_layernorm",
      "layer": "layer_15",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_193",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer15_attention_softmax",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_194",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer15_activation",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_195",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer15_attention_dropout",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_196",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_q_proj",
      "layer": "layer_16",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_197",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_k_proj",
      "layer": "layer_16",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_198",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_v_proj",
      "layer": "layer_16",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_199",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_o_proj",
      "layer": "layer_16",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_200",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_gate_proj",
      "layer": "layer_16",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_201",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_up_proj",
      "layer": "layer_16",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_202",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_down_proj",
      "layer": "layer_16",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_203",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer16_input_layernorm",
      "layer": "layer_16",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_204",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer16_post_attention_layernorm",
      "layer": "layer_16",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_205",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer16_attention_softmax",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_206",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer16_activation",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_207",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer16_attention_dropout",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_208",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_q_proj",
      "layer": "layer_17",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_209",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_k_proj",
      "layer": "layer_17",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_210",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_v_proj",
      "layer": "layer_17",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_211",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_o_proj",
      "layer": "layer_17",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_212",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_gate_proj",
      "layer": "layer_17",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_213",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_up_proj",
      "layer": "layer_17",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_214",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_down_proj",
      "layer": "layer_17",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_215",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer17_input_layernorm",
      "layer": "layer_17",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_216",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer17_post_attention_layernorm",
      "layer": "layer_17",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_217",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer17_attention_softmax",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_218",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer17_activation",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_219",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer17_attention_dropout",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_220",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_q_proj",
      "layer": "layer_18",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_221",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_k_proj",
      "layer": "layer_18",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_222",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_v_proj",
      "layer": "layer_18",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_223",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_o_proj",
      "layer": "layer_18",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_224",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_gate_proj",
      "layer": "layer_18",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_225",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_up_proj",
      "layer": "layer_18",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_226",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_down_proj",
      "layer": "layer_18",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_227",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer18_input_layernorm",
      "layer": "layer_18",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_228",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer18_post_attention_layernorm",
      "layer": "layer_18",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_229",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer18_attention_softmax",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_230",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer18_activation",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_231",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer18_attention_dropout",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_232",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_q_proj",
      "layer": "layer_19",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_233",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_k_proj",
      "layer": "layer_19",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_234",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_v_proj",
      "layer": "layer_19",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_235",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_o_proj",
      "layer": "layer_19",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_236",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_gate_proj",
      "layer": "layer_19",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_237",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_up_proj",
      "layer": "layer_19",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_238",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_down_proj",
      "layer": "layer_19",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_239",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer19_input_layernorm",
      "layer": "layer_19",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_240",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer19_post_attention_layernorm",
      "layer": "layer_19",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_241",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer19_attention_softmax",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_242",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer19_activation",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_243",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer19_attention_dropout",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_244",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_q_proj",
      "layer": "layer_20",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_245",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_k_proj",
      "layer": "layer_20",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_246",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_v_proj",
      "layer": "layer_20",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_247",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_o_proj",
      "layer": "layer_20",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_248",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_gate_proj",
      "layer": "layer_20",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_249",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_up_proj",
      "layer": "layer_20",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_250",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_down_proj",
      "layer": "layer_20",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_251",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer20_input_layernorm",
      "layer": "layer_20",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_252",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer20_post_attention_layernorm",
      "layer": "layer_20",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_253",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer20_attention_softmax",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_254",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer20_activation",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_255",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer20_attention_dropout",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_256",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_q_proj",
      "layer": "layer_21",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_257",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_k_proj",
      "layer": "layer_21",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_258",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_v_proj",
      "layer": "layer_21",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_259",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_o_proj",
      "layer": "layer_21",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_260",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_gate_proj",
      "layer": "layer_21",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_261",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_up_proj",
      "layer": "layer_21",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_262",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_down_proj",
      "layer": "layer_21",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_263",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer21_input_layernorm",
      "layer": "layer_21",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_264",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer21_post_attention_layernorm",
      "layer": "layer_21",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_265",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer21_attention_softmax",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_266",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer21_activation",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_267",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer21_attention_dropout",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_268",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_q_proj",
      "layer": "layer_22",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_269",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_k_proj",
      "layer": "layer_22",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_270",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_v_proj",
      "layer": "layer_22",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_271",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_o_proj",
      "layer": "layer_22",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_272",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_gate_proj",
      "layer": "layer_22",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_273",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_up_proj",
      "layer": "layer_22",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_274",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_down_proj",
      "layer": "layer_22",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_275",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer22_input_layernorm",
      "layer": "layer_22",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_276",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer22_post_attention_layernorm",
      "layer": "layer_22",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_277",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer22_attention_softmax",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_278",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer22_activation",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_279",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer22_attention_dropout",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_280",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_q_proj",
      "layer": "layer_23",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_281",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_k_proj",
      "layer": "layer_23",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_282",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_v_proj",
      "layer": "layer_23",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_283",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_o_proj",
      "layer": "layer_23",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_284",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_gate_proj",
      "layer": "layer_23",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_285",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_up_proj",
      "layer": "layer_23",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_286",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_down_proj",
      "layer": "layer_23",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_287",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer23_input_layernorm",
      "layer": "layer_23",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_288",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer23_post_attention_layernorm",
      "layer": "layer_23",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_289",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer23_attention_softmax",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_290",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer23_activation",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_291",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer23_attention_dropout",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_292",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_q_proj",
      "layer": "layer_24",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_293",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_k_proj",
      "layer": "layer_24",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_294",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_v_proj",
      "layer": "layer_24",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_295",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_o_proj",
      "layer": "layer_24",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_296",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_gate_proj",
      "layer": "layer_24",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_297",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_up_proj",
      "layer": "layer_24",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_298",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_down_proj",
      "layer": "layer_24",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_299",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer24_input_layernorm",
      "layer": "layer_24",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_300",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer24_post_attention_layernorm",
      "layer": "layer_24",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_301",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer24_attention_softmax",
      "layer": "layer_24",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_302",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer24_activation",
      "layer": "layer_24",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_303",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer24_attention_dropout",
      "layer": "layer_24",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_304",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_q_proj",
      "layer": "layer_25",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_305",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_k_proj",
      "layer": "layer_25",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_306",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_v_proj",
      "layer": "layer_25",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_307",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_o_proj",
      "layer": "layer_25",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_308",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_gate_proj",
      "layer": "layer_25",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_309",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_up_proj",
      "layer": "layer_25",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_310",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_down_proj",
      "layer": "layer_25",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_311",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer25_input_layernorm",
      "layer": "layer_25",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_312",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer25_post_attention_layernorm",
      "layer": "layer_25",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_313",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer25_attention_softmax",
      "layer": "layer_25",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_314",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer25_activation",
      "layer": "layer_25",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_315",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer25_attention_dropout",
      "layer": "layer_25",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_316",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_q_proj",
      "layer": "layer_26",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_317",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_k_proj",
      "layer": "layer_26",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_318",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_v_proj",
      "layer": "layer_26",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_319",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_o_proj",
      "layer": "layer_26",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_320",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_gate_proj",
      "layer": "layer_26",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_321",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_up_proj",
      "layer": "layer_26",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_322",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_down_proj",
      "layer": "layer_26",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_323",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer26_input_layernorm",
      "layer": "layer_26",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_324",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer26_post_attention_layernorm",
      "layer": "layer_26",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_325",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer26_attention_softmax",
      "layer": "layer_26",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_326",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer26_activation",
      "layer": "layer_26",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_327",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer26_attention_dropout",
      "layer": "layer_26",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_328",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_q_proj",
      "layer": "layer_27",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_329",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_k_proj",
      "layer": "layer_27",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_330",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_v_proj",
      "layer": "layer_27",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_331",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_o_proj",
      "layer": "layer_27",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_332",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_gate_proj",
      "layer": "layer_27",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_333",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_up_proj",
      "layer": "layer_27",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_334",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_down_proj",
      "layer": "layer_27",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_335",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer27_input_layernorm",
      "layer": "layer_27",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_336",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer27_post_attention_layernorm",
      "layer": "layer_27",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_337",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer27_attention_softmax",
      "layer": "layer_27",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_338",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer27_activation",
      "layer": "layer_27",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_339",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer27_attention_dropout",
      "layer": "layer_27",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_340",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_q_proj",
      "layer": "layer_28",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_341",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_k_proj",
      "layer": "layer_28",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_342",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_v_proj",
      "layer": "layer_28",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_343",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_o_proj",
      "layer": "layer_28",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_344",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_gate_proj",
      "layer": "layer_28",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_345",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_up_proj",
      "layer": "layer_28",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_346",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_down_proj",
      "layer": "layer_28",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_347",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer28_input_layernorm",
      "layer": "layer_28",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_348",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer28_post_attention_layernorm",
      "layer": "layer_28",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_349",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer28_attention_softmax",
      "layer": "layer_28",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_350",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer28_activation",
      "layer": "layer_28",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_351",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer28_attention_dropout",
      "layer": "layer_28",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_352",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_q_proj",
      "layer": "layer_29",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_353",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_k_proj",
      "layer": "layer_29",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_354",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_v_proj",
      "layer": "layer_29",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_355",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_o_proj",
      "layer": "layer_29",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_356",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_gate_proj",
      "layer": "layer_29",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_357",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_up_proj",
      "layer": "layer_29",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_358",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_down_proj",
      "layer": "layer_29",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_359",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer29_input_layernorm",
      "layer": "layer_29",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_360",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer29_post_attention_layernorm",
      "layer": "layer_29",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_361",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer29_attention_softmax",
      "layer": "layer_29",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_362",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer29_activation",
      "layer": "layer_29",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_363",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer29_attention_dropout",
      "layer": "layer_29",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_364",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_q_proj",
      "layer": "layer_30",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_365",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_k_proj",
      "layer": "layer_30",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_366",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_v_proj",
      "layer": "layer_30",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_367",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_o_proj",
      "layer": "layer_30",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_368",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_gate_proj",
      "layer": "layer_30",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_369",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_up_proj",
      "layer": "layer_30",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_370",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_down_proj",
      "layer": "layer_30",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_371",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer30_input_layernorm",
      "layer": "layer_30",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_372",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer30_post_attention_layernorm",
      "layer": "layer_30",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_373",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer30_attention_softmax",
      "layer": "layer_30",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_374",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer30_activation",
      "layer": "layer_30",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_375",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer30_attention_dropout",
      "layer": "layer_30",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_376",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_q_proj",
      "layer": "layer_31",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_377",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_k_proj",
      "layer": "layer_31",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_378",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_v_proj",
      "layer": "layer_31",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_379",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_o_proj",
      "layer": "layer_31",
      "parameters": 9437184,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_380",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_gate_proj",
      "layer": "layer_31",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_381",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_up_proj",
      "layer": "layer_31",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_382",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_down_proj",
      "layer": "layer_31",
      "parameters": 25165824,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Phi_3_mini_op_383",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer31_input_layernorm",
      "layer": "layer_31",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_384",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer31_post_attention_layernorm",
      "layer": "layer_31",
      "parameters": 3072,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Phi_3_mini_op_385",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer31_attention_softmax",
      "layer": "layer_31",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Phi_3_mini_op_386",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer31_activation",
      "layer": "layer_31",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Phi_3_mini_op_387",
      "model_name": "Phi-3-mini",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer31_attention_dropout",
      "layer": "layer_31",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BLOOM_560M_op_1",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Embedding",
      "name": "wte",
      "layer": "global",
      "parameters": 1048576,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_2",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Embedding",
      "name": "wpe",
      "layer": "global",
      "parameters": 1048576,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_3",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "ln_f",
      "layer": "global",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_4",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_attn",
      "layer": "layer_0",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_5",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_proj",
      "layer": "layer_0",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_6",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_fc",
      "layer": "layer_0",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_7",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_proj_mlp",
      "layer": "layer_0",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_8",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer0_ln_1",
      "layer": "layer_0",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_9",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer0_ln_2",
      "layer": "layer_0",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_10",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_11",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_12",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer0_attn_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_13",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer0_resid_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_14",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_attn",
      "layer": "layer_1",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_15",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_proj",
      "layer": "layer_1",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_16",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_fc",
      "layer": "layer_1",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_17",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_proj_mlp",
      "layer": "layer_1",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_18",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer1_ln_1",
      "layer": "layer_1",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_19",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer1_ln_2",
      "layer": "layer_1",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_20",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_21",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_22",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer1_attn_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_23",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer1_resid_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_24",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_attn",
      "layer": "layer_2",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_25",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_proj",
      "layer": "layer_2",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_26",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_fc",
      "layer": "layer_2",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_27",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_proj_mlp",
      "layer": "layer_2",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_28",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer2_ln_1",
      "layer": "layer_2",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_29",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer2_ln_2",
      "layer": "layer_2",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_30",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_31",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_32",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer2_attn_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_33",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer2_resid_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_34",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_attn",
      "layer": "layer_3",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_35",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_proj",
      "layer": "layer_3",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_36",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_fc",
      "layer": "layer_3",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_37",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_proj_mlp",
      "layer": "layer_3",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_38",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer3_ln_1",
      "layer": "layer_3",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_39",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer3_ln_2",
      "layer": "layer_3",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_40",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_41",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_42",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer3_attn_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_43",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer3_resid_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_44",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_attn",
      "layer": "layer_4",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_45",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_proj",
      "layer": "layer_4",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_46",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_fc",
      "layer": "layer_4",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_47",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_proj_mlp",
      "layer": "layer_4",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_48",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer4_ln_1",
      "layer": "layer_4",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_49",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer4_ln_2",
      "layer": "layer_4",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_50",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_51",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_52",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer4_attn_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_53",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer4_resid_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_54",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_attn",
      "layer": "layer_5",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_55",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_proj",
      "layer": "layer_5",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_56",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_fc",
      "layer": "layer_5",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_57",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_proj_mlp",
      "layer": "layer_5",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_58",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer5_ln_1",
      "layer": "layer_5",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_59",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer5_ln_2",
      "layer": "layer_5",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_60",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_61",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_62",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer5_attn_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_63",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer5_resid_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_64",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_attn",
      "layer": "layer_6",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_65",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_proj",
      "layer": "layer_6",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_66",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_fc",
      "layer": "layer_6",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_67",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_proj_mlp",
      "layer": "layer_6",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_68",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer6_ln_1",
      "layer": "layer_6",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_69",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer6_ln_2",
      "layer": "layer_6",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_70",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_71",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_72",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer6_attn_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_73",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer6_resid_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_74",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_attn",
      "layer": "layer_7",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_75",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_proj",
      "layer": "layer_7",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_76",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_fc",
      "layer": "layer_7",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_77",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_proj_mlp",
      "layer": "layer_7",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_78",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer7_ln_1",
      "layer": "layer_7",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_79",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer7_ln_2",
      "layer": "layer_7",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_80",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_81",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_82",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer7_attn_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_83",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer7_resid_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_84",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_attn",
      "layer": "layer_8",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_85",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_proj",
      "layer": "layer_8",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_86",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_fc",
      "layer": "layer_8",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_87",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_proj_mlp",
      "layer": "layer_8",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_88",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer8_ln_1",
      "layer": "layer_8",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_89",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer8_ln_2",
      "layer": "layer_8",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_90",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_91",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_92",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer8_attn_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_93",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer8_resid_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_94",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_attn",
      "layer": "layer_9",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_95",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_proj",
      "layer": "layer_9",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_96",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_fc",
      "layer": "layer_9",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_97",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_proj_mlp",
      "layer": "layer_9",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_98",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer9_ln_1",
      "layer": "layer_9",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_99",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer9_ln_2",
      "layer": "layer_9",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_100",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_101",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_102",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer9_attn_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_103",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer9_resid_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_104",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_attn",
      "layer": "layer_10",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_105",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_proj",
      "layer": "layer_10",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_106",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_fc",
      "layer": "layer_10",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_107",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_proj_mlp",
      "layer": "layer_10",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_108",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer10_ln_1",
      "layer": "layer_10",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_109",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer10_ln_2",
      "layer": "layer_10",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_110",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_111",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_112",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer10_attn_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_113",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer10_resid_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_114",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_attn",
      "layer": "layer_11",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_115",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_proj",
      "layer": "layer_11",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_116",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_fc",
      "layer": "layer_11",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_117",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_proj_mlp",
      "layer": "layer_11",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_118",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer11_ln_1",
      "layer": "layer_11",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_119",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer11_ln_2",
      "layer": "layer_11",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_120",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_121",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_122",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer11_attn_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_123",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer11_resid_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_124",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_c_attn",
      "layer": "layer_12",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_125",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_c_proj",
      "layer": "layer_12",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_126",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_c_fc",
      "layer": "layer_12",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_127",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_c_proj_mlp",
      "layer": "layer_12",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_128",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer12_ln_1",
      "layer": "layer_12",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_129",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer12_ln_2",
      "layer": "layer_12",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_130",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer12_attention_softmax",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_131",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer12_activation",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_132",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer12_attn_dropout",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_133",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer12_resid_dropout",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_134",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_c_attn",
      "layer": "layer_13",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_135",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_c_proj",
      "layer": "layer_13",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_136",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_c_fc",
      "layer": "layer_13",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_137",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_c_proj_mlp",
      "layer": "layer_13",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_138",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer13_ln_1",
      "layer": "layer_13",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_139",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer13_ln_2",
      "layer": "layer_13",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_140",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer13_attention_softmax",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_141",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer13_activation",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_142",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer13_attn_dropout",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_143",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer13_resid_dropout",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_144",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_c_attn",
      "layer": "layer_14",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_145",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_c_proj",
      "layer": "layer_14",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_146",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_c_fc",
      "layer": "layer_14",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_147",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_c_proj_mlp",
      "layer": "layer_14",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_148",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer14_ln_1",
      "layer": "layer_14",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_149",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer14_ln_2",
      "layer": "layer_14",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_150",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer14_attention_softmax",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_151",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer14_activation",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_152",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer14_attn_dropout",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_153",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer14_resid_dropout",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_154",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_c_attn",
      "layer": "layer_15",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_155",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_c_proj",
      "layer": "layer_15",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_156",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_c_fc",
      "layer": "layer_15",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_157",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_c_proj_mlp",
      "layer": "layer_15",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_158",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer15_ln_1",
      "layer": "layer_15",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_159",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer15_ln_2",
      "layer": "layer_15",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_160",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer15_attention_softmax",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_161",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer15_activation",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_162",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer15_attn_dropout",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_163",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer15_resid_dropout",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_164",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_c_attn",
      "layer": "layer_16",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_165",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_c_proj",
      "layer": "layer_16",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_166",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_c_fc",
      "layer": "layer_16",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_167",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_c_proj_mlp",
      "layer": "layer_16",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_168",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer16_ln_1",
      "layer": "layer_16",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_169",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer16_ln_2",
      "layer": "layer_16",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_170",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer16_attention_softmax",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_171",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer16_activation",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_172",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer16_attn_dropout",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_173",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer16_resid_dropout",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_174",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_c_attn",
      "layer": "layer_17",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_175",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_c_proj",
      "layer": "layer_17",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_176",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_c_fc",
      "layer": "layer_17",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_177",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_c_proj_mlp",
      "layer": "layer_17",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_178",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer17_ln_1",
      "layer": "layer_17",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_179",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer17_ln_2",
      "layer": "layer_17",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_180",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer17_attention_softmax",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_181",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer17_activation",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_182",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer17_attn_dropout",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_183",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer17_resid_dropout",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_184",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_c_attn",
      "layer": "layer_18",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_185",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_c_proj",
      "layer": "layer_18",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_186",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_c_fc",
      "layer": "layer_18",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_187",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_c_proj_mlp",
      "layer": "layer_18",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_188",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer18_ln_1",
      "layer": "layer_18",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_189",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer18_ln_2",
      "layer": "layer_18",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_190",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer18_attention_softmax",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_191",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer18_activation",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_192",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer18_attn_dropout",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_193",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer18_resid_dropout",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_194",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_c_attn",
      "layer": "layer_19",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_195",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_c_proj",
      "layer": "layer_19",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_196",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_c_fc",
      "layer": "layer_19",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_197",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_c_proj_mlp",
      "layer": "layer_19",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_198",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer19_ln_1",
      "layer": "layer_19",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_199",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer19_ln_2",
      "layer": "layer_19",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_200",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer19_attention_softmax",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_201",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer19_activation",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_202",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer19_attn_dropout",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_203",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer19_resid_dropout",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_204",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_c_attn",
      "layer": "layer_20",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_205",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_c_proj",
      "layer": "layer_20",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_206",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_c_fc",
      "layer": "layer_20",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_207",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_c_proj_mlp",
      "layer": "layer_20",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_208",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer20_ln_1",
      "layer": "layer_20",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_209",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer20_ln_2",
      "layer": "layer_20",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_210",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer20_attention_softmax",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_211",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer20_activation",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_212",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer20_attn_dropout",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_213",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer20_resid_dropout",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_214",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_c_attn",
      "layer": "layer_21",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_215",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_c_proj",
      "layer": "layer_21",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_216",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_c_fc",
      "layer": "layer_21",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_217",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_c_proj_mlp",
      "layer": "layer_21",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_218",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer21_ln_1",
      "layer": "layer_21",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_219",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer21_ln_2",
      "layer": "layer_21",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_220",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer21_attention_softmax",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_221",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer21_activation",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_222",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer21_attn_dropout",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_223",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer21_resid_dropout",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_224",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_c_attn",
      "layer": "layer_22",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_225",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_c_proj",
      "layer": "layer_22",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_226",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_c_fc",
      "layer": "layer_22",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_227",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_c_proj_mlp",
      "layer": "layer_22",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_228",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer22_ln_1",
      "layer": "layer_22",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_229",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer22_ln_2",
      "layer": "layer_22",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_230",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer22_attention_softmax",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_231",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer22_activation",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_232",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer22_attn_dropout",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_233",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer22_resid_dropout",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_234",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_c_attn",
      "layer": "layer_23",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_235",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_c_proj",
      "layer": "layer_23",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_236",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_c_fc",
      "layer": "layer_23",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_237",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_c_proj_mlp",
      "layer": "layer_23",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLOOM_560M_op_238",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer23_ln_1",
      "layer": "layer_23",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_239",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer23_ln_2",
      "layer": "layer_23",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_240",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer23_attention_softmax",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLOOM_560M_op_241",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer23_activation",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "BLOOM_560M_op_242",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer23_attn_dropout",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BLOOM_560M_op_243",
      "model_name": "BLOOM-560M",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer23_resid_dropout",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "GPT_2_op_1",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Embedding",
      "name": "wte",
      "layer": "global",
      "parameters": 589824,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_2",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Embedding",
      "name": "wpe",
      "layer": "global",
      "parameters": 589824,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_3",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "ln_f",
      "layer": "global",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_4",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_attn",
      "layer": "layer_0",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_5",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_proj",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_6",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_fc",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_7",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_proj_mlp",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_8",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer0_ln_1",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_9",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer0_ln_2",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_10",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_2_op_11",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "GPT_2_op_12",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer0_attn_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_13",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer0_resid_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_14",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_attn",
      "layer": "layer_1",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_15",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_proj",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_16",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_fc",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_17",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_proj_mlp",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_18",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer1_ln_1",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_19",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer1_ln_2",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_20",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_2_op_21",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "GPT_2_op_22",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer1_attn_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_23",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer1_resid_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_24",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_attn",
      "layer": "layer_2",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_25",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_proj",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_26",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_fc",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_27",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_proj_mlp",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_28",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer2_ln_1",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_29",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer2_ln_2",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_30",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_2_op_31",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "GPT_2_op_32",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer2_attn_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_33",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer2_resid_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_34",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_attn",
      "layer": "layer_3",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_35",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_proj",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_36",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_fc",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_37",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_proj_mlp",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_38",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer3_ln_1",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_39",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer3_ln_2",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_40",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_2_op_41",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "GPT_2_op_42",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer3_attn_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_43",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer3_resid_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_44",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_attn",
      "layer": "layer_4",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_45",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_proj",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_46",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_fc",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_47",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_proj_mlp",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_48",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer4_ln_1",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_49",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer4_ln_2",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_50",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_2_op_51",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "GPT_2_op_52",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer4_attn_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_53",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer4_resid_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_54",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_attn",
      "layer": "layer_5",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_55",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_proj",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_56",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_fc",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_57",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_proj_mlp",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_58",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer5_ln_1",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_59",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer5_ln_2",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_60",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_2_op_61",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "GPT_2_op_62",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer5_attn_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_63",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer5_resid_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_64",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_attn",
      "layer": "layer_6",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_65",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_proj",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_66",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_fc",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_67",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_proj_mlp",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_68",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer6_ln_1",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_69",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer6_ln_2",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_70",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_2_op_71",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "GPT_2_op_72",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer6_attn_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_73",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer6_resid_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_74",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_attn",
      "layer": "layer_7",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_75",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_proj",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_76",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_fc",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_77",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_proj_mlp",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_78",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer7_ln_1",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_79",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer7_ln_2",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_80",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_2_op_81",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "GPT_2_op_82",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer7_attn_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_83",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer7_resid_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_84",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_attn",
      "layer": "layer_8",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_85",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_proj",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_86",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_fc",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_87",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_proj_mlp",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_88",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer8_ln_1",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_89",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer8_ln_2",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_90",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_2_op_91",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "GPT_2_op_92",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer8_attn_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_93",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer8_resid_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_94",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_attn",
      "layer": "layer_9",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_95",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_proj",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_96",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_fc",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_97",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_proj_mlp",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_98",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer9_ln_1",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_99",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer9_ln_2",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_100",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_2_op_101",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "GPT_2_op_102",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer9_attn_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_103",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer9_resid_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_104",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_attn",
      "layer": "layer_10",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_105",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_proj",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_106",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_fc",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_107",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_proj_mlp",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_108",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer10_ln_1",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_109",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer10_ln_2",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_110",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_2_op_111",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "GPT_2_op_112",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer10_attn_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_113",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer10_resid_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_114",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_attn",
      "layer": "layer_11",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_115",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_proj",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_116",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_fc",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_117",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_proj_mlp",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_2_op_118",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer11_ln_1",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_119",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer11_ln_2",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_120",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_2_op_121",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "GPT_2_op_122",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer11_attn_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_2_op_123",
      "model_name": "GPT-2",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer11_resid_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "OPT_1.3B_op_1",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Embedding",
      "name": "wte",
      "layer": "global",
      "parameters": 4194304,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_2",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Embedding",
      "name": "wpe",
      "layer": "global",
      "parameters": 4194304,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_3",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "ln_f",
      "layer": "global",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_4",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_attn",
      "layer": "layer_0",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_5",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_proj",
      "layer": "layer_0",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_6",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_fc",
      "layer": "layer_0",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_7",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_proj_mlp",
      "layer": "layer_0",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_8",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer0_ln_1",
      "layer": "layer_0",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_9",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer0_ln_2",
      "layer": "layer_0",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_10",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_11",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_12",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer0_attn_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_13",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer0_resid_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_14",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_attn",
      "layer": "layer_1",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_15",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_proj",
      "layer": "layer_1",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_16",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_fc",
      "layer": "layer_1",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_17",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_proj_mlp",
      "layer": "layer_1",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_18",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer1_ln_1",
      "layer": "layer_1",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_19",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer1_ln_2",
      "layer": "layer_1",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_20",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_21",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_22",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer1_attn_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_23",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer1_resid_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_24",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_attn",
      "layer": "layer_2",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_25",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_proj",
      "layer": "layer_2",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_26",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_fc",
      "layer": "layer_2",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_27",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_proj_mlp",
      "layer": "layer_2",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_28",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer2_ln_1",
      "layer": "layer_2",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_29",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer2_ln_2",
      "layer": "layer_2",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_30",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_31",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_32",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer2_attn_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_33",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer2_resid_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_34",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_attn",
      "layer": "layer_3",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_35",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_proj",
      "layer": "layer_3",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_36",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_fc",
      "layer": "layer_3",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_37",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_proj_mlp",
      "layer": "layer_3",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_38",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer3_ln_1",
      "layer": "layer_3",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_39",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer3_ln_2",
      "layer": "layer_3",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_40",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_41",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_42",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer3_attn_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_43",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer3_resid_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_44",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_attn",
      "layer": "layer_4",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_45",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_proj",
      "layer": "layer_4",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_46",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_fc",
      "layer": "layer_4",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_47",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_proj_mlp",
      "layer": "layer_4",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_48",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer4_ln_1",
      "layer": "layer_4",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_49",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer4_ln_2",
      "layer": "layer_4",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_50",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_51",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_52",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer4_attn_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_53",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer4_resid_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_54",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_attn",
      "layer": "layer_5",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_55",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_proj",
      "layer": "layer_5",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_56",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_fc",
      "layer": "layer_5",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_57",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_proj_mlp",
      "layer": "layer_5",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_58",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer5_ln_1",
      "layer": "layer_5",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_59",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer5_ln_2",
      "layer": "layer_5",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_60",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_61",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_62",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer5_attn_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_63",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer5_resid_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_64",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_attn",
      "layer": "layer_6",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_65",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_proj",
      "layer": "layer_6",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_66",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_fc",
      "layer": "layer_6",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_67",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_proj_mlp",
      "layer": "layer_6",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_68",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer6_ln_1",
      "layer": "layer_6",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_69",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer6_ln_2",
      "layer": "layer_6",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_70",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_71",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_72",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer6_attn_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_73",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer6_resid_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_74",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_attn",
      "layer": "layer_7",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_75",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_proj",
      "layer": "layer_7",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_76",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_fc",
      "layer": "layer_7",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_77",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_proj_mlp",
      "layer": "layer_7",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_78",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer7_ln_1",
      "layer": "layer_7",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_79",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer7_ln_2",
      "layer": "layer_7",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_80",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_81",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_82",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer7_attn_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_83",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer7_resid_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_84",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_attn",
      "layer": "layer_8",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_85",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_proj",
      "layer": "layer_8",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_86",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_fc",
      "layer": "layer_8",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_87",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_proj_mlp",
      "layer": "layer_8",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_88",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer8_ln_1",
      "layer": "layer_8",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_89",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer8_ln_2",
      "layer": "layer_8",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_90",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_91",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_92",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer8_attn_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_93",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer8_resid_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_94",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_attn",
      "layer": "layer_9",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_95",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_proj",
      "layer": "layer_9",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_96",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_fc",
      "layer": "layer_9",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_97",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_proj_mlp",
      "layer": "layer_9",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_98",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer9_ln_1",
      "layer": "layer_9",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_99",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer9_ln_2",
      "layer": "layer_9",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_100",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_101",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_102",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer9_attn_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_103",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer9_resid_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_104",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_attn",
      "layer": "layer_10",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_105",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_proj",
      "layer": "layer_10",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_106",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_fc",
      "layer": "layer_10",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_107",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_proj_mlp",
      "layer": "layer_10",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_108",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer10_ln_1",
      "layer": "layer_10",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_109",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer10_ln_2",
      "layer": "layer_10",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_110",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_111",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_112",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer10_attn_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_113",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer10_resid_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_114",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_attn",
      "layer": "layer_11",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_115",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_proj",
      "layer": "layer_11",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_116",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_fc",
      "layer": "layer_11",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_117",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_proj_mlp",
      "layer": "layer_11",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_118",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer11_ln_1",
      "layer": "layer_11",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_119",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer11_ln_2",
      "layer": "layer_11",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_120",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_121",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_122",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer11_attn_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_123",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer11_resid_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_124",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_c_attn",
      "layer": "layer_12",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_125",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_c_proj",
      "layer": "layer_12",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_126",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_c_fc",
      "layer": "layer_12",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_127",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_c_proj_mlp",
      "layer": "layer_12",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_128",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer12_ln_1",
      "layer": "layer_12",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_129",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer12_ln_2",
      "layer": "layer_12",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_130",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer12_attention_softmax",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_131",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer12_activation",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_132",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer12_attn_dropout",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_133",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer12_resid_dropout",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_134",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_c_attn",
      "layer": "layer_13",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_135",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_c_proj",
      "layer": "layer_13",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_136",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_c_fc",
      "layer": "layer_13",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_137",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_c_proj_mlp",
      "layer": "layer_13",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_138",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer13_ln_1",
      "layer": "layer_13",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_139",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer13_ln_2",
      "layer": "layer_13",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_140",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer13_attention_softmax",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_141",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer13_activation",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_142",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer13_attn_dropout",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_143",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer13_resid_dropout",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_144",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_c_attn",
      "layer": "layer_14",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_145",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_c_proj",
      "layer": "layer_14",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_146",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_c_fc",
      "layer": "layer_14",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_147",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_c_proj_mlp",
      "layer": "layer_14",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_148",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer14_ln_1",
      "layer": "layer_14",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_149",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer14_ln_2",
      "layer": "layer_14",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_150",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer14_attention_softmax",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_151",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer14_activation",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_152",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer14_attn_dropout",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_153",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer14_resid_dropout",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_154",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_c_attn",
      "layer": "layer_15",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_155",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_c_proj",
      "layer": "layer_15",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_156",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_c_fc",
      "layer": "layer_15",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_157",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_c_proj_mlp",
      "layer": "layer_15",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_158",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer15_ln_1",
      "layer": "layer_15",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_159",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer15_ln_2",
      "layer": "layer_15",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_160",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer15_attention_softmax",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_161",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer15_activation",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_162",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer15_attn_dropout",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_163",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer15_resid_dropout",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_164",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_c_attn",
      "layer": "layer_16",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_165",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_c_proj",
      "layer": "layer_16",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_166",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_c_fc",
      "layer": "layer_16",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_167",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_c_proj_mlp",
      "layer": "layer_16",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_168",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer16_ln_1",
      "layer": "layer_16",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_169",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer16_ln_2",
      "layer": "layer_16",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_170",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer16_attention_softmax",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_171",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer16_activation",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_172",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer16_attn_dropout",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_173",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer16_resid_dropout",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_174",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_c_attn",
      "layer": "layer_17",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_175",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_c_proj",
      "layer": "layer_17",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_176",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_c_fc",
      "layer": "layer_17",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_177",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_c_proj_mlp",
      "layer": "layer_17",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_178",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer17_ln_1",
      "layer": "layer_17",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_179",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer17_ln_2",
      "layer": "layer_17",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_180",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer17_attention_softmax",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_181",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer17_activation",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_182",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer17_attn_dropout",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_183",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer17_resid_dropout",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_184",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_c_attn",
      "layer": "layer_18",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_185",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_c_proj",
      "layer": "layer_18",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_186",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_c_fc",
      "layer": "layer_18",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_187",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_c_proj_mlp",
      "layer": "layer_18",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_188",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer18_ln_1",
      "layer": "layer_18",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_189",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer18_ln_2",
      "layer": "layer_18",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_190",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer18_attention_softmax",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_191",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer18_activation",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_192",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer18_attn_dropout",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_193",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer18_resid_dropout",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_194",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_c_attn",
      "layer": "layer_19",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_195",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_c_proj",
      "layer": "layer_19",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_196",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_c_fc",
      "layer": "layer_19",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_197",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_c_proj_mlp",
      "layer": "layer_19",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_198",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer19_ln_1",
      "layer": "layer_19",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_199",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer19_ln_2",
      "layer": "layer_19",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_200",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer19_attention_softmax",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_201",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer19_activation",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_202",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer19_attn_dropout",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_203",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer19_resid_dropout",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_204",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_c_attn",
      "layer": "layer_20",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_205",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_c_proj",
      "layer": "layer_20",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_206",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_c_fc",
      "layer": "layer_20",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_207",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_c_proj_mlp",
      "layer": "layer_20",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_208",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer20_ln_1",
      "layer": "layer_20",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_209",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer20_ln_2",
      "layer": "layer_20",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_210",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer20_attention_softmax",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_211",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer20_activation",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_212",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer20_attn_dropout",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_213",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer20_resid_dropout",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_214",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_c_attn",
      "layer": "layer_21",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_215",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_c_proj",
      "layer": "layer_21",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_216",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_c_fc",
      "layer": "layer_21",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_217",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_c_proj_mlp",
      "layer": "layer_21",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_218",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer21_ln_1",
      "layer": "layer_21",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_219",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer21_ln_2",
      "layer": "layer_21",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_220",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer21_attention_softmax",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_221",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer21_activation",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_222",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer21_attn_dropout",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_223",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer21_resid_dropout",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_224",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_c_attn",
      "layer": "layer_22",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_225",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_c_proj",
      "layer": "layer_22",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_226",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_c_fc",
      "layer": "layer_22",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_227",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_c_proj_mlp",
      "layer": "layer_22",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_228",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer22_ln_1",
      "layer": "layer_22",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_229",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer22_ln_2",
      "layer": "layer_22",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_230",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer22_attention_softmax",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_231",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer22_activation",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_232",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer22_attn_dropout",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_233",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer22_resid_dropout",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_234",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_c_attn",
      "layer": "layer_23",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_235",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_c_proj",
      "layer": "layer_23",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_236",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_c_fc",
      "layer": "layer_23",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_237",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_c_proj_mlp",
      "layer": "layer_23",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "OPT_1.3B_op_238",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer23_ln_1",
      "layer": "layer_23",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_239",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer23_ln_2",
      "layer": "layer_23",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_240",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer23_attention_softmax",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "OPT_1.3B_op_241",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer23_activation",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "OPT_1.3B_op_242",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer23_attn_dropout",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "OPT_1.3B_op_243",
      "model_name": "OPT-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer23_resid_dropout",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Falcon_7B_op_1",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Embedding",
      "name": "embed_tokens",
      "layer": "global",
      "parameters": 295469056,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_2",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "norm",
      "layer": "global",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_3",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "lm_head",
      "layer": "global",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_4",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_q_proj",
      "layer": "layer_0",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_5",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_k_proj",
      "layer": "layer_0",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_6",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_v_proj",
      "layer": "layer_0",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_7",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_o_proj",
      "layer": "layer_0",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_8",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_gate_proj",
      "layer": "layer_0",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_9",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_up_proj",
      "layer": "layer_0",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_10",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_down_proj",
      "layer": "layer_0",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_11",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer0_input_layernorm",
      "layer": "layer_0",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_12",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer0_post_attention_layernorm",
      "layer": "layer_0",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_13",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_14",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_15",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer0_attention_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_16",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_q_proj",
      "layer": "layer_1",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_17",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_k_proj",
      "layer": "layer_1",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_18",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_v_proj",
      "layer": "layer_1",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_19",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_o_proj",
      "layer": "layer_1",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_20",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_gate_proj",
      "layer": "layer_1",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_21",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_up_proj",
      "layer": "layer_1",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_22",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_down_proj",
      "layer": "layer_1",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_23",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer1_input_layernorm",
      "layer": "layer_1",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_24",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer1_post_attention_layernorm",
      "layer": "layer_1",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_25",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_26",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_27",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer1_attention_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_28",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_q_proj",
      "layer": "layer_2",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_29",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_k_proj",
      "layer": "layer_2",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_30",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_v_proj",
      "layer": "layer_2",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_31",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_o_proj",
      "layer": "layer_2",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_32",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_gate_proj",
      "layer": "layer_2",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_33",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_up_proj",
      "layer": "layer_2",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_34",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_down_proj",
      "layer": "layer_2",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_35",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer2_input_layernorm",
      "layer": "layer_2",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_36",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer2_post_attention_layernorm",
      "layer": "layer_2",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_37",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_38",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_39",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer2_attention_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_40",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_q_proj",
      "layer": "layer_3",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_41",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_k_proj",
      "layer": "layer_3",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_42",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_v_proj",
      "layer": "layer_3",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_43",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_o_proj",
      "layer": "layer_3",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_44",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_gate_proj",
      "layer": "layer_3",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_45",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_up_proj",
      "layer": "layer_3",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_46",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_down_proj",
      "layer": "layer_3",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_47",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer3_input_layernorm",
      "layer": "layer_3",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_48",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer3_post_attention_layernorm",
      "layer": "layer_3",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_49",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_50",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_51",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer3_attention_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_52",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_q_proj",
      "layer": "layer_4",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_53",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_k_proj",
      "layer": "layer_4",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_54",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_v_proj",
      "layer": "layer_4",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_55",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_o_proj",
      "layer": "layer_4",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_56",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_gate_proj",
      "layer": "layer_4",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_57",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_up_proj",
      "layer": "layer_4",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_58",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_down_proj",
      "layer": "layer_4",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_59",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer4_input_layernorm",
      "layer": "layer_4",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_60",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer4_post_attention_layernorm",
      "layer": "layer_4",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_61",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_62",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_63",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer4_attention_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_64",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_q_proj",
      "layer": "layer_5",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_65",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_k_proj",
      "layer": "layer_5",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_66",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_v_proj",
      "layer": "layer_5",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_67",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_o_proj",
      "layer": "layer_5",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_68",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_gate_proj",
      "layer": "layer_5",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_69",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_up_proj",
      "layer": "layer_5",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_70",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_down_proj",
      "layer": "layer_5",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_71",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer5_input_layernorm",
      "layer": "layer_5",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_72",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer5_post_attention_layernorm",
      "layer": "layer_5",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_73",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_74",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_75",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer5_attention_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_76",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_q_proj",
      "layer": "layer_6",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_77",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_k_proj",
      "layer": "layer_6",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_78",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_v_proj",
      "layer": "layer_6",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_79",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_o_proj",
      "layer": "layer_6",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_80",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_gate_proj",
      "layer": "layer_6",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_81",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_up_proj",
      "layer": "layer_6",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_82",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_down_proj",
      "layer": "layer_6",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_83",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer6_input_layernorm",
      "layer": "layer_6",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_84",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer6_post_attention_layernorm",
      "layer": "layer_6",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_85",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_86",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_87",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer6_attention_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_88",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_q_proj",
      "layer": "layer_7",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_89",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_k_proj",
      "layer": "layer_7",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_90",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_v_proj",
      "layer": "layer_7",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_91",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_o_proj",
      "layer": "layer_7",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_92",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_gate_proj",
      "layer": "layer_7",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_93",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_up_proj",
      "layer": "layer_7",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_94",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_down_proj",
      "layer": "layer_7",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_95",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer7_input_layernorm",
      "layer": "layer_7",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_96",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer7_post_attention_layernorm",
      "layer": "layer_7",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_97",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_98",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_99",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer7_attention_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_100",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_q_proj",
      "layer": "layer_8",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_101",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_k_proj",
      "layer": "layer_8",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_102",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_v_proj",
      "layer": "layer_8",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_103",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_o_proj",
      "layer": "layer_8",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_104",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_gate_proj",
      "layer": "layer_8",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_105",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_up_proj",
      "layer": "layer_8",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_106",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_down_proj",
      "layer": "layer_8",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_107",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer8_input_layernorm",
      "layer": "layer_8",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_108",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer8_post_attention_layernorm",
      "layer": "layer_8",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_109",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_110",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_111",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer8_attention_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_112",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_q_proj",
      "layer": "layer_9",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_113",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_k_proj",
      "layer": "layer_9",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_114",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_v_proj",
      "layer": "layer_9",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_115",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_o_proj",
      "layer": "layer_9",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_116",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_gate_proj",
      "layer": "layer_9",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_117",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_up_proj",
      "layer": "layer_9",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_118",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_down_proj",
      "layer": "layer_9",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_119",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer9_input_layernorm",
      "layer": "layer_9",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_120",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer9_post_attention_layernorm",
      "layer": "layer_9",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_121",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_122",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_123",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer9_attention_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_124",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_q_proj",
      "layer": "layer_10",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_125",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_k_proj",
      "layer": "layer_10",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_126",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_v_proj",
      "layer": "layer_10",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_127",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_o_proj",
      "layer": "layer_10",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_128",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_gate_proj",
      "layer": "layer_10",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_129",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_up_proj",
      "layer": "layer_10",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_130",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_down_proj",
      "layer": "layer_10",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_131",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer10_input_layernorm",
      "layer": "layer_10",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_132",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer10_post_attention_layernorm",
      "layer": "layer_10",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_133",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_134",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_135",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer10_attention_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_136",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_q_proj",
      "layer": "layer_11",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_137",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_k_proj",
      "layer": "layer_11",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_138",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_v_proj",
      "layer": "layer_11",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_139",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_o_proj",
      "layer": "layer_11",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_140",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_gate_proj",
      "layer": "layer_11",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_141",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_up_proj",
      "layer": "layer_11",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_142",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_down_proj",
      "layer": "layer_11",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_143",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer11_input_layernorm",
      "layer": "layer_11",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_144",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer11_post_attention_layernorm",
      "layer": "layer_11",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_145",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_146",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_147",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer11_attention_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_148",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_q_proj",
      "layer": "layer_12",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_149",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_k_proj",
      "layer": "layer_12",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_150",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_v_proj",
      "layer": "layer_12",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_151",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_o_proj",
      "layer": "layer_12",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_152",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_gate_proj",
      "layer": "layer_12",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_153",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_up_proj",
      "layer": "layer_12",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_154",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_down_proj",
      "layer": "layer_12",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_155",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer12_input_layernorm",
      "layer": "layer_12",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_156",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer12_post_attention_layernorm",
      "layer": "layer_12",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_157",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer12_attention_softmax",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_158",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer12_activation",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_159",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer12_attention_dropout",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_160",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_q_proj",
      "layer": "layer_13",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_161",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_k_proj",
      "layer": "layer_13",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_162",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_v_proj",
      "layer": "layer_13",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_163",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_o_proj",
      "layer": "layer_13",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_164",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_gate_proj",
      "layer": "layer_13",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_165",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_up_proj",
      "layer": "layer_13",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_166",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_down_proj",
      "layer": "layer_13",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_167",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer13_input_layernorm",
      "layer": "layer_13",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_168",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer13_post_attention_layernorm",
      "layer": "layer_13",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_169",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer13_attention_softmax",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_170",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer13_activation",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_171",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer13_attention_dropout",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_172",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_q_proj",
      "layer": "layer_14",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_173",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_k_proj",
      "layer": "layer_14",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_174",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_v_proj",
      "layer": "layer_14",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_175",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_o_proj",
      "layer": "layer_14",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_176",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_gate_proj",
      "layer": "layer_14",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_177",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_up_proj",
      "layer": "layer_14",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_178",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_down_proj",
      "layer": "layer_14",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_179",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer14_input_layernorm",
      "layer": "layer_14",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_180",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer14_post_attention_layernorm",
      "layer": "layer_14",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_181",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer14_attention_softmax",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_182",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer14_activation",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_183",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer14_attention_dropout",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_184",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_q_proj",
      "layer": "layer_15",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_185",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_k_proj",
      "layer": "layer_15",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_186",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_v_proj",
      "layer": "layer_15",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_187",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_o_proj",
      "layer": "layer_15",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_188",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_gate_proj",
      "layer": "layer_15",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_189",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_up_proj",
      "layer": "layer_15",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_190",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_down_proj",
      "layer": "layer_15",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_191",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer15_input_layernorm",
      "layer": "layer_15",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_192",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer15_post_attention_layernorm",
      "layer": "layer_15",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_193",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer15_attention_softmax",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_194",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer15_activation",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_195",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer15_attention_dropout",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_196",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_q_proj",
      "layer": "layer_16",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_197",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_k_proj",
      "layer": "layer_16",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_198",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_v_proj",
      "layer": "layer_16",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_199",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_o_proj",
      "layer": "layer_16",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_200",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_gate_proj",
      "layer": "layer_16",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_201",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_up_proj",
      "layer": "layer_16",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_202",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_down_proj",
      "layer": "layer_16",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_203",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer16_input_layernorm",
      "layer": "layer_16",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_204",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer16_post_attention_layernorm",
      "layer": "layer_16",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_205",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer16_attention_softmax",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_206",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer16_activation",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_207",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer16_attention_dropout",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_208",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_q_proj",
      "layer": "layer_17",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_209",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_k_proj",
      "layer": "layer_17",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_210",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_v_proj",
      "layer": "layer_17",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_211",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_o_proj",
      "layer": "layer_17",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_212",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_gate_proj",
      "layer": "layer_17",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_213",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_up_proj",
      "layer": "layer_17",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_214",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_down_proj",
      "layer": "layer_17",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_215",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer17_input_layernorm",
      "layer": "layer_17",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_216",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer17_post_attention_layernorm",
      "layer": "layer_17",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_217",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer17_attention_softmax",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_218",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer17_activation",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_219",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer17_attention_dropout",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_220",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_q_proj",
      "layer": "layer_18",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_221",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_k_proj",
      "layer": "layer_18",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_222",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_v_proj",
      "layer": "layer_18",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_223",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_o_proj",
      "layer": "layer_18",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_224",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_gate_proj",
      "layer": "layer_18",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_225",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_up_proj",
      "layer": "layer_18",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_226",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_down_proj",
      "layer": "layer_18",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_227",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer18_input_layernorm",
      "layer": "layer_18",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_228",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer18_post_attention_layernorm",
      "layer": "layer_18",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_229",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer18_attention_softmax",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_230",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer18_activation",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_231",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer18_attention_dropout",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_232",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_q_proj",
      "layer": "layer_19",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_233",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_k_proj",
      "layer": "layer_19",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_234",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_v_proj",
      "layer": "layer_19",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_235",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_o_proj",
      "layer": "layer_19",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_236",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_gate_proj",
      "layer": "layer_19",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_237",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_up_proj",
      "layer": "layer_19",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_238",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_down_proj",
      "layer": "layer_19",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_239",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer19_input_layernorm",
      "layer": "layer_19",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_240",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer19_post_attention_layernorm",
      "layer": "layer_19",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_241",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer19_attention_softmax",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_242",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer19_activation",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_243",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer19_attention_dropout",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_244",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_q_proj",
      "layer": "layer_20",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_245",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_k_proj",
      "layer": "layer_20",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_246",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_v_proj",
      "layer": "layer_20",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_247",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_o_proj",
      "layer": "layer_20",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_248",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_gate_proj",
      "layer": "layer_20",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_249",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_up_proj",
      "layer": "layer_20",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_250",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_down_proj",
      "layer": "layer_20",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_251",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer20_input_layernorm",
      "layer": "layer_20",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_252",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer20_post_attention_layernorm",
      "layer": "layer_20",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_253",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer20_attention_softmax",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_254",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer20_activation",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_255",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer20_attention_dropout",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_256",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_q_proj",
      "layer": "layer_21",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_257",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_k_proj",
      "layer": "layer_21",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_258",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_v_proj",
      "layer": "layer_21",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_259",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_o_proj",
      "layer": "layer_21",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_260",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_gate_proj",
      "layer": "layer_21",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_261",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_up_proj",
      "layer": "layer_21",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_262",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_down_proj",
      "layer": "layer_21",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_263",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer21_input_layernorm",
      "layer": "layer_21",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_264",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer21_post_attention_layernorm",
      "layer": "layer_21",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_265",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer21_attention_softmax",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_266",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer21_activation",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_267",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer21_attention_dropout",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_268",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_q_proj",
      "layer": "layer_22",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_269",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_k_proj",
      "layer": "layer_22",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_270",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_v_proj",
      "layer": "layer_22",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_271",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_o_proj",
      "layer": "layer_22",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_272",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_gate_proj",
      "layer": "layer_22",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_273",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_up_proj",
      "layer": "layer_22",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_274",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_down_proj",
      "layer": "layer_22",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_275",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer22_input_layernorm",
      "layer": "layer_22",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_276",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer22_post_attention_layernorm",
      "layer": "layer_22",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_277",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer22_attention_softmax",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_278",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer22_activation",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_279",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer22_attention_dropout",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_280",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_q_proj",
      "layer": "layer_23",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_281",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_k_proj",
      "layer": "layer_23",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_282",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_v_proj",
      "layer": "layer_23",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_283",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_o_proj",
      "layer": "layer_23",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_284",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_gate_proj",
      "layer": "layer_23",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_285",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_up_proj",
      "layer": "layer_23",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_286",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_down_proj",
      "layer": "layer_23",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_287",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer23_input_layernorm",
      "layer": "layer_23",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_288",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer23_post_attention_layernorm",
      "layer": "layer_23",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_289",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer23_attention_softmax",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_290",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer23_activation",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_291",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer23_attention_dropout",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_292",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_q_proj",
      "layer": "layer_24",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_293",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_k_proj",
      "layer": "layer_24",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_294",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_v_proj",
      "layer": "layer_24",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_295",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_o_proj",
      "layer": "layer_24",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_296",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_gate_proj",
      "layer": "layer_24",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_297",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_up_proj",
      "layer": "layer_24",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_298",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_down_proj",
      "layer": "layer_24",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_299",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer24_input_layernorm",
      "layer": "layer_24",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_300",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer24_post_attention_layernorm",
      "layer": "layer_24",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_301",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer24_attention_softmax",
      "layer": "layer_24",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_302",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer24_activation",
      "layer": "layer_24",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_303",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer24_attention_dropout",
      "layer": "layer_24",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_304",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_q_proj",
      "layer": "layer_25",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_305",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_k_proj",
      "layer": "layer_25",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_306",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_v_proj",
      "layer": "layer_25",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_307",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_o_proj",
      "layer": "layer_25",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_308",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_gate_proj",
      "layer": "layer_25",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_309",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_up_proj",
      "layer": "layer_25",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_310",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_down_proj",
      "layer": "layer_25",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_311",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer25_input_layernorm",
      "layer": "layer_25",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_312",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer25_post_attention_layernorm",
      "layer": "layer_25",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_313",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer25_attention_softmax",
      "layer": "layer_25",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_314",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer25_activation",
      "layer": "layer_25",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_315",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer25_attention_dropout",
      "layer": "layer_25",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_316",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_q_proj",
      "layer": "layer_26",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_317",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_k_proj",
      "layer": "layer_26",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_318",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_v_proj",
      "layer": "layer_26",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_319",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_o_proj",
      "layer": "layer_26",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_320",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_gate_proj",
      "layer": "layer_26",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_321",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_up_proj",
      "layer": "layer_26",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_322",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_down_proj",
      "layer": "layer_26",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_323",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer26_input_layernorm",
      "layer": "layer_26",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_324",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer26_post_attention_layernorm",
      "layer": "layer_26",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_325",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer26_attention_softmax",
      "layer": "layer_26",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_326",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer26_activation",
      "layer": "layer_26",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_327",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer26_attention_dropout",
      "layer": "layer_26",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_328",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_q_proj",
      "layer": "layer_27",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_329",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_k_proj",
      "layer": "layer_27",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_330",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_v_proj",
      "layer": "layer_27",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_331",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_o_proj",
      "layer": "layer_27",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_332",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_gate_proj",
      "layer": "layer_27",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_333",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_up_proj",
      "layer": "layer_27",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_334",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_down_proj",
      "layer": "layer_27",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_335",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer27_input_layernorm",
      "layer": "layer_27",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_336",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer27_post_attention_layernorm",
      "layer": "layer_27",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_337",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer27_attention_softmax",
      "layer": "layer_27",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_338",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer27_activation",
      "layer": "layer_27",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_339",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer27_attention_dropout",
      "layer": "layer_27",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_340",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_q_proj",
      "layer": "layer_28",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_341",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_k_proj",
      "layer": "layer_28",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_342",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_v_proj",
      "layer": "layer_28",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_343",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_o_proj",
      "layer": "layer_28",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_344",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_gate_proj",
      "layer": "layer_28",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_345",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_up_proj",
      "layer": "layer_28",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_346",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_down_proj",
      "layer": "layer_28",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_347",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer28_input_layernorm",
      "layer": "layer_28",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_348",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer28_post_attention_layernorm",
      "layer": "layer_28",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_349",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer28_attention_softmax",
      "layer": "layer_28",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_350",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer28_activation",
      "layer": "layer_28",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_351",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer28_attention_dropout",
      "layer": "layer_28",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_352",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_q_proj",
      "layer": "layer_29",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_353",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_k_proj",
      "layer": "layer_29",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_354",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_v_proj",
      "layer": "layer_29",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_355",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_o_proj",
      "layer": "layer_29",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_356",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_gate_proj",
      "layer": "layer_29",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_357",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_up_proj",
      "layer": "layer_29",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_358",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_down_proj",
      "layer": "layer_29",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_359",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer29_input_layernorm",
      "layer": "layer_29",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_360",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer29_post_attention_layernorm",
      "layer": "layer_29",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_361",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer29_attention_softmax",
      "layer": "layer_29",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_362",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer29_activation",
      "layer": "layer_29",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_363",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer29_attention_dropout",
      "layer": "layer_29",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_364",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_q_proj",
      "layer": "layer_30",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_365",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_k_proj",
      "layer": "layer_30",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_366",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_v_proj",
      "layer": "layer_30",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_367",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_o_proj",
      "layer": "layer_30",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_368",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_gate_proj",
      "layer": "layer_30",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_369",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_up_proj",
      "layer": "layer_30",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_370",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_down_proj",
      "layer": "layer_30",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_371",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer30_input_layernorm",
      "layer": "layer_30",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_372",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer30_post_attention_layernorm",
      "layer": "layer_30",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_373",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer30_attention_softmax",
      "layer": "layer_30",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_374",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer30_activation",
      "layer": "layer_30",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_375",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer30_attention_dropout",
      "layer": "layer_30",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_376",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_q_proj",
      "layer": "layer_31",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_377",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_k_proj",
      "layer": "layer_31",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_378",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_v_proj",
      "layer": "layer_31",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_379",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_o_proj",
      "layer": "layer_31",
      "parameters": 20647936,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_380",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_gate_proj",
      "layer": "layer_31",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_381",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_up_proj",
      "layer": "layer_31",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_382",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_down_proj",
      "layer": "layer_31",
      "parameters": 82591744,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Falcon_7B_op_383",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer31_input_layernorm",
      "layer": "layer_31",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_384",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer31_post_attention_layernorm",
      "layer": "layer_31",
      "parameters": 4544,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "Falcon_7B_op_385",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer31_attention_softmax",
      "layer": "layer_31",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Falcon_7B_op_386",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer31_activation",
      "layer": "layer_31",
      "parameters": 0,
      "input_shape": "[batch, seq, 18176]",
      "output_shape": "[batch, seq, 18176]"
    },
    {
      "op_id": "Falcon_7B_op_387",
      "model_name": "Falcon-7B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer31_attention_dropout",
      "layer": "layer_31",
      "parameters": 0,
      "input_shape": "[batch, seq, 4544]",
      "output_shape": "[batch, seq, 4544]"
    },
    {
      "op_id": "StableLM_3B_op_1",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Embedding",
      "name": "embed_tokens",
      "layer": "global",
      "parameters": 128778240,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_2",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "norm",
      "layer": "global",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_3",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "lm_head",
      "layer": "global",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_4",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_q_proj",
      "layer": "layer_0",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_5",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_k_proj",
      "layer": "layer_0",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_6",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_v_proj",
      "layer": "layer_0",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_7",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_o_proj",
      "layer": "layer_0",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_8",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_gate_proj",
      "layer": "layer_0",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_9",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_up_proj",
      "layer": "layer_0",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_10",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_down_proj",
      "layer": "layer_0",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_11",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer0_input_layernorm",
      "layer": "layer_0",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_12",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer0_post_attention_layernorm",
      "layer": "layer_0",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_13",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_14",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_15",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer0_attention_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_16",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_q_proj",
      "layer": "layer_1",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_17",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_k_proj",
      "layer": "layer_1",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_18",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_v_proj",
      "layer": "layer_1",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_19",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_o_proj",
      "layer": "layer_1",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_20",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_gate_proj",
      "layer": "layer_1",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_21",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_up_proj",
      "layer": "layer_1",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_22",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_down_proj",
      "layer": "layer_1",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_23",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer1_input_layernorm",
      "layer": "layer_1",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_24",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer1_post_attention_layernorm",
      "layer": "layer_1",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_25",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_26",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_27",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer1_attention_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_28",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_q_proj",
      "layer": "layer_2",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_29",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_k_proj",
      "layer": "layer_2",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_30",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_v_proj",
      "layer": "layer_2",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_31",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_o_proj",
      "layer": "layer_2",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_32",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_gate_proj",
      "layer": "layer_2",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_33",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_up_proj",
      "layer": "layer_2",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_34",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_down_proj",
      "layer": "layer_2",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_35",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer2_input_layernorm",
      "layer": "layer_2",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_36",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer2_post_attention_layernorm",
      "layer": "layer_2",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_37",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_38",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_39",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer2_attention_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_40",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_q_proj",
      "layer": "layer_3",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_41",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_k_proj",
      "layer": "layer_3",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_42",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_v_proj",
      "layer": "layer_3",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_43",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_o_proj",
      "layer": "layer_3",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_44",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_gate_proj",
      "layer": "layer_3",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_45",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_up_proj",
      "layer": "layer_3",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_46",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_down_proj",
      "layer": "layer_3",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_47",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer3_input_layernorm",
      "layer": "layer_3",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_48",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer3_post_attention_layernorm",
      "layer": "layer_3",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_49",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_50",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_51",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer3_attention_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_52",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_q_proj",
      "layer": "layer_4",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_53",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_k_proj",
      "layer": "layer_4",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_54",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_v_proj",
      "layer": "layer_4",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_55",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_o_proj",
      "layer": "layer_4",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_56",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_gate_proj",
      "layer": "layer_4",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_57",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_up_proj",
      "layer": "layer_4",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_58",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_down_proj",
      "layer": "layer_4",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_59",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer4_input_layernorm",
      "layer": "layer_4",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_60",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer4_post_attention_layernorm",
      "layer": "layer_4",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_61",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_62",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_63",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer4_attention_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_64",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_q_proj",
      "layer": "layer_5",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_65",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_k_proj",
      "layer": "layer_5",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_66",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_v_proj",
      "layer": "layer_5",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_67",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_o_proj",
      "layer": "layer_5",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_68",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_gate_proj",
      "layer": "layer_5",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_69",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_up_proj",
      "layer": "layer_5",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_70",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_down_proj",
      "layer": "layer_5",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_71",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer5_input_layernorm",
      "layer": "layer_5",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_72",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer5_post_attention_layernorm",
      "layer": "layer_5",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_73",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_74",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_75",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer5_attention_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_76",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_q_proj",
      "layer": "layer_6",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_77",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_k_proj",
      "layer": "layer_6",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_78",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_v_proj",
      "layer": "layer_6",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_79",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_o_proj",
      "layer": "layer_6",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_80",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_gate_proj",
      "layer": "layer_6",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_81",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_up_proj",
      "layer": "layer_6",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_82",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_down_proj",
      "layer": "layer_6",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_83",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer6_input_layernorm",
      "layer": "layer_6",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_84",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer6_post_attention_layernorm",
      "layer": "layer_6",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_85",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_86",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_87",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer6_attention_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_88",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_q_proj",
      "layer": "layer_7",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_89",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_k_proj",
      "layer": "layer_7",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_90",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_v_proj",
      "layer": "layer_7",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_91",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_o_proj",
      "layer": "layer_7",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_92",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_gate_proj",
      "layer": "layer_7",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_93",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_up_proj",
      "layer": "layer_7",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_94",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_down_proj",
      "layer": "layer_7",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_95",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer7_input_layernorm",
      "layer": "layer_7",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_96",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer7_post_attention_layernorm",
      "layer": "layer_7",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_97",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_98",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_99",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer7_attention_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_100",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_q_proj",
      "layer": "layer_8",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_101",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_k_proj",
      "layer": "layer_8",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_102",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_v_proj",
      "layer": "layer_8",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_103",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_o_proj",
      "layer": "layer_8",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_104",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_gate_proj",
      "layer": "layer_8",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_105",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_up_proj",
      "layer": "layer_8",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_106",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_down_proj",
      "layer": "layer_8",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_107",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer8_input_layernorm",
      "layer": "layer_8",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_108",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer8_post_attention_layernorm",
      "layer": "layer_8",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_109",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_110",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_111",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer8_attention_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_112",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_q_proj",
      "layer": "layer_9",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_113",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_k_proj",
      "layer": "layer_9",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_114",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_v_proj",
      "layer": "layer_9",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_115",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_o_proj",
      "layer": "layer_9",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_116",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_gate_proj",
      "layer": "layer_9",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_117",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_up_proj",
      "layer": "layer_9",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_118",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_down_proj",
      "layer": "layer_9",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_119",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer9_input_layernorm",
      "layer": "layer_9",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_120",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer9_post_attention_layernorm",
      "layer": "layer_9",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_121",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_122",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_123",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer9_attention_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_124",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_q_proj",
      "layer": "layer_10",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_125",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_k_proj",
      "layer": "layer_10",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_126",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_v_proj",
      "layer": "layer_10",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_127",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_o_proj",
      "layer": "layer_10",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_128",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_gate_proj",
      "layer": "layer_10",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_129",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_up_proj",
      "layer": "layer_10",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_130",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_down_proj",
      "layer": "layer_10",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_131",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer10_input_layernorm",
      "layer": "layer_10",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_132",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer10_post_attention_layernorm",
      "layer": "layer_10",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_133",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_134",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_135",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer10_attention_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_136",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_q_proj",
      "layer": "layer_11",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_137",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_k_proj",
      "layer": "layer_11",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_138",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_v_proj",
      "layer": "layer_11",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_139",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_o_proj",
      "layer": "layer_11",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_140",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_gate_proj",
      "layer": "layer_11",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_141",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_up_proj",
      "layer": "layer_11",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_142",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_down_proj",
      "layer": "layer_11",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_143",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer11_input_layernorm",
      "layer": "layer_11",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_144",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer11_post_attention_layernorm",
      "layer": "layer_11",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_145",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_146",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_147",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer11_attention_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_148",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_q_proj",
      "layer": "layer_12",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_149",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_k_proj",
      "layer": "layer_12",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_150",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_v_proj",
      "layer": "layer_12",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_151",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_o_proj",
      "layer": "layer_12",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_152",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_gate_proj",
      "layer": "layer_12",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_153",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_up_proj",
      "layer": "layer_12",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_154",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_down_proj",
      "layer": "layer_12",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_155",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer12_input_layernorm",
      "layer": "layer_12",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_156",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer12_post_attention_layernorm",
      "layer": "layer_12",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_157",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer12_attention_softmax",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_158",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer12_activation",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_159",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer12_attention_dropout",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_160",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_q_proj",
      "layer": "layer_13",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_161",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_k_proj",
      "layer": "layer_13",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_162",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_v_proj",
      "layer": "layer_13",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_163",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_o_proj",
      "layer": "layer_13",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_164",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_gate_proj",
      "layer": "layer_13",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_165",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_up_proj",
      "layer": "layer_13",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_166",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_down_proj",
      "layer": "layer_13",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_167",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer13_input_layernorm",
      "layer": "layer_13",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_168",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer13_post_attention_layernorm",
      "layer": "layer_13",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_169",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer13_attention_softmax",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_170",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer13_activation",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_171",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer13_attention_dropout",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_172",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_q_proj",
      "layer": "layer_14",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_173",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_k_proj",
      "layer": "layer_14",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_174",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_v_proj",
      "layer": "layer_14",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_175",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_o_proj",
      "layer": "layer_14",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_176",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_gate_proj",
      "layer": "layer_14",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_177",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_up_proj",
      "layer": "layer_14",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_178",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_down_proj",
      "layer": "layer_14",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_179",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer14_input_layernorm",
      "layer": "layer_14",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_180",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer14_post_attention_layernorm",
      "layer": "layer_14",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_181",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer14_attention_softmax",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_182",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer14_activation",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_183",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer14_attention_dropout",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_184",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_q_proj",
      "layer": "layer_15",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_185",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_k_proj",
      "layer": "layer_15",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_186",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_v_proj",
      "layer": "layer_15",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_187",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_o_proj",
      "layer": "layer_15",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_188",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_gate_proj",
      "layer": "layer_15",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_189",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_up_proj",
      "layer": "layer_15",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_190",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_down_proj",
      "layer": "layer_15",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_191",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer15_input_layernorm",
      "layer": "layer_15",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_192",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer15_post_attention_layernorm",
      "layer": "layer_15",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_193",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer15_attention_softmax",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_194",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer15_activation",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_195",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer15_attention_dropout",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_196",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_q_proj",
      "layer": "layer_16",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_197",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_k_proj",
      "layer": "layer_16",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_198",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_v_proj",
      "layer": "layer_16",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_199",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_o_proj",
      "layer": "layer_16",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_200",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_gate_proj",
      "layer": "layer_16",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_201",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_up_proj",
      "layer": "layer_16",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_202",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_down_proj",
      "layer": "layer_16",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_203",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer16_input_layernorm",
      "layer": "layer_16",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_204",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer16_post_attention_layernorm",
      "layer": "layer_16",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_205",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer16_attention_softmax",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_206",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer16_activation",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_207",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer16_attention_dropout",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_208",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_q_proj",
      "layer": "layer_17",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_209",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_k_proj",
      "layer": "layer_17",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_210",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_v_proj",
      "layer": "layer_17",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_211",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_o_proj",
      "layer": "layer_17",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_212",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_gate_proj",
      "layer": "layer_17",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_213",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_up_proj",
      "layer": "layer_17",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_214",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_down_proj",
      "layer": "layer_17",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_215",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer17_input_layernorm",
      "layer": "layer_17",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_216",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer17_post_attention_layernorm",
      "layer": "layer_17",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_217",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer17_attention_softmax",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_218",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer17_activation",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_219",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer17_attention_dropout",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_220",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_q_proj",
      "layer": "layer_18",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_221",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_k_proj",
      "layer": "layer_18",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_222",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_v_proj",
      "layer": "layer_18",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_223",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_o_proj",
      "layer": "layer_18",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_224",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_gate_proj",
      "layer": "layer_18",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_225",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_up_proj",
      "layer": "layer_18",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_226",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_down_proj",
      "layer": "layer_18",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_227",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer18_input_layernorm",
      "layer": "layer_18",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_228",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer18_post_attention_layernorm",
      "layer": "layer_18",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_229",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer18_attention_softmax",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_230",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer18_activation",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_231",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer18_attention_dropout",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_232",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_q_proj",
      "layer": "layer_19",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_233",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_k_proj",
      "layer": "layer_19",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_234",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_v_proj",
      "layer": "layer_19",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_235",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_o_proj",
      "layer": "layer_19",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_236",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_gate_proj",
      "layer": "layer_19",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_237",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_up_proj",
      "layer": "layer_19",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_238",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_down_proj",
      "layer": "layer_19",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_239",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer19_input_layernorm",
      "layer": "layer_19",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_240",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer19_post_attention_layernorm",
      "layer": "layer_19",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_241",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer19_attention_softmax",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_242",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer19_activation",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_243",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer19_attention_dropout",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_244",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_q_proj",
      "layer": "layer_20",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_245",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_k_proj",
      "layer": "layer_20",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_246",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_v_proj",
      "layer": "layer_20",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_247",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_o_proj",
      "layer": "layer_20",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_248",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_gate_proj",
      "layer": "layer_20",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_249",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_up_proj",
      "layer": "layer_20",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_250",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_down_proj",
      "layer": "layer_20",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_251",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer20_input_layernorm",
      "layer": "layer_20",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_252",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer20_post_attention_layernorm",
      "layer": "layer_20",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_253",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer20_attention_softmax",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_254",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer20_activation",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_255",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer20_attention_dropout",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_256",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_q_proj",
      "layer": "layer_21",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_257",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_k_proj",
      "layer": "layer_21",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_258",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_v_proj",
      "layer": "layer_21",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_259",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_o_proj",
      "layer": "layer_21",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_260",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_gate_proj",
      "layer": "layer_21",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_261",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_up_proj",
      "layer": "layer_21",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_262",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_down_proj",
      "layer": "layer_21",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_263",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer21_input_layernorm",
      "layer": "layer_21",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_264",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer21_post_attention_layernorm",
      "layer": "layer_21",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_265",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer21_attention_softmax",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_266",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer21_activation",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_267",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer21_attention_dropout",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_268",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_q_proj",
      "layer": "layer_22",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_269",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_k_proj",
      "layer": "layer_22",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_270",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_v_proj",
      "layer": "layer_22",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_271",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_o_proj",
      "layer": "layer_22",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_272",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_gate_proj",
      "layer": "layer_22",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_273",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_up_proj",
      "layer": "layer_22",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_274",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_down_proj",
      "layer": "layer_22",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_275",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer22_input_layernorm",
      "layer": "layer_22",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_276",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer22_post_attention_layernorm",
      "layer": "layer_22",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_277",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer22_attention_softmax",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_278",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer22_activation",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_279",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer22_attention_dropout",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_280",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_q_proj",
      "layer": "layer_23",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_281",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_k_proj",
      "layer": "layer_23",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_282",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_v_proj",
      "layer": "layer_23",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_283",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_o_proj",
      "layer": "layer_23",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_284",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_gate_proj",
      "layer": "layer_23",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_285",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_up_proj",
      "layer": "layer_23",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_286",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_down_proj",
      "layer": "layer_23",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_287",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer23_input_layernorm",
      "layer": "layer_23",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_288",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer23_post_attention_layernorm",
      "layer": "layer_23",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_289",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer23_attention_softmax",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_290",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer23_activation",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_291",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer23_attention_dropout",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_292",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_q_proj",
      "layer": "layer_24",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_293",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_k_proj",
      "layer": "layer_24",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_294",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_v_proj",
      "layer": "layer_24",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_295",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_o_proj",
      "layer": "layer_24",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_296",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_gate_proj",
      "layer": "layer_24",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_297",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_up_proj",
      "layer": "layer_24",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_298",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer24_down_proj",
      "layer": "layer_24",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_299",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer24_input_layernorm",
      "layer": "layer_24",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_300",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer24_post_attention_layernorm",
      "layer": "layer_24",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_301",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer24_attention_softmax",
      "layer": "layer_24",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_302",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer24_activation",
      "layer": "layer_24",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_303",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer24_attention_dropout",
      "layer": "layer_24",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_304",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_q_proj",
      "layer": "layer_25",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_305",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_k_proj",
      "layer": "layer_25",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_306",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_v_proj",
      "layer": "layer_25",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_307",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_o_proj",
      "layer": "layer_25",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_308",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_gate_proj",
      "layer": "layer_25",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_309",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_up_proj",
      "layer": "layer_25",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_310",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer25_down_proj",
      "layer": "layer_25",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_311",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer25_input_layernorm",
      "layer": "layer_25",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_312",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer25_post_attention_layernorm",
      "layer": "layer_25",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_313",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer25_attention_softmax",
      "layer": "layer_25",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_314",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer25_activation",
      "layer": "layer_25",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_315",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer25_attention_dropout",
      "layer": "layer_25",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_316",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_q_proj",
      "layer": "layer_26",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_317",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_k_proj",
      "layer": "layer_26",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_318",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_v_proj",
      "layer": "layer_26",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_319",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_o_proj",
      "layer": "layer_26",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_320",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_gate_proj",
      "layer": "layer_26",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_321",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_up_proj",
      "layer": "layer_26",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_322",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer26_down_proj",
      "layer": "layer_26",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_323",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer26_input_layernorm",
      "layer": "layer_26",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_324",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer26_post_attention_layernorm",
      "layer": "layer_26",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_325",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer26_attention_softmax",
      "layer": "layer_26",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_326",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer26_activation",
      "layer": "layer_26",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_327",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer26_attention_dropout",
      "layer": "layer_26",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_328",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_q_proj",
      "layer": "layer_27",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_329",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_k_proj",
      "layer": "layer_27",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_330",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_v_proj",
      "layer": "layer_27",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_331",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_o_proj",
      "layer": "layer_27",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_332",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_gate_proj",
      "layer": "layer_27",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_333",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_up_proj",
      "layer": "layer_27",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_334",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer27_down_proj",
      "layer": "layer_27",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_335",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer27_input_layernorm",
      "layer": "layer_27",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_336",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer27_post_attention_layernorm",
      "layer": "layer_27",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_337",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer27_attention_softmax",
      "layer": "layer_27",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_338",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer27_activation",
      "layer": "layer_27",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_339",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer27_attention_dropout",
      "layer": "layer_27",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_340",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_q_proj",
      "layer": "layer_28",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_341",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_k_proj",
      "layer": "layer_28",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_342",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_v_proj",
      "layer": "layer_28",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_343",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_o_proj",
      "layer": "layer_28",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_344",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_gate_proj",
      "layer": "layer_28",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_345",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_up_proj",
      "layer": "layer_28",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_346",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer28_down_proj",
      "layer": "layer_28",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_347",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer28_input_layernorm",
      "layer": "layer_28",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_348",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer28_post_attention_layernorm",
      "layer": "layer_28",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_349",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer28_attention_softmax",
      "layer": "layer_28",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_350",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer28_activation",
      "layer": "layer_28",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_351",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer28_attention_dropout",
      "layer": "layer_28",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_352",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_q_proj",
      "layer": "layer_29",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_353",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_k_proj",
      "layer": "layer_29",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_354",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_v_proj",
      "layer": "layer_29",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_355",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_o_proj",
      "layer": "layer_29",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_356",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_gate_proj",
      "layer": "layer_29",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_357",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_up_proj",
      "layer": "layer_29",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_358",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer29_down_proj",
      "layer": "layer_29",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_359",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer29_input_layernorm",
      "layer": "layer_29",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_360",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer29_post_attention_layernorm",
      "layer": "layer_29",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_361",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer29_attention_softmax",
      "layer": "layer_29",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_362",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer29_activation",
      "layer": "layer_29",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_363",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer29_attention_dropout",
      "layer": "layer_29",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_364",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_q_proj",
      "layer": "layer_30",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_365",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_k_proj",
      "layer": "layer_30",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_366",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_v_proj",
      "layer": "layer_30",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_367",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_o_proj",
      "layer": "layer_30",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_368",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_gate_proj",
      "layer": "layer_30",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_369",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_up_proj",
      "layer": "layer_30",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_370",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer30_down_proj",
      "layer": "layer_30",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_371",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer30_input_layernorm",
      "layer": "layer_30",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_372",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer30_post_attention_layernorm",
      "layer": "layer_30",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_373",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer30_attention_softmax",
      "layer": "layer_30",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_374",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer30_activation",
      "layer": "layer_30",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_375",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer30_attention_dropout",
      "layer": "layer_30",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_376",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_q_proj",
      "layer": "layer_31",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_377",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_k_proj",
      "layer": "layer_31",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_378",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_v_proj",
      "layer": "layer_31",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_379",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_o_proj",
      "layer": "layer_31",
      "parameters": 6553600,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_380",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_gate_proj",
      "layer": "layer_31",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_381",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_up_proj",
      "layer": "layer_31",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_382",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer31_down_proj",
      "layer": "layer_31",
      "parameters": 17694720,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "StableLM_3B_op_383",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer31_input_layernorm",
      "layer": "layer_31",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_384",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer31_post_attention_layernorm",
      "layer": "layer_31",
      "parameters": 2560,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "StableLM_3B_op_385",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer31_attention_softmax",
      "layer": "layer_31",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "StableLM_3B_op_386",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer31_activation",
      "layer": "layer_31",
      "parameters": 0,
      "input_shape": "[batch, seq, 6912]",
      "output_shape": "[batch, seq, 6912]"
    },
    {
      "op_id": "StableLM_3B_op_387",
      "model_name": "StableLM-3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer31_attention_dropout",
      "layer": "layer_31",
      "parameters": 0,
      "input_shape": "[batch, seq, 2560]",
      "output_shape": "[batch, seq, 2560]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_1",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Embedding",
      "name": "embed_tokens",
      "layer": "global",
      "parameters": 65536000,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_2",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "norm",
      "layer": "global",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_3",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "lm_head",
      "layer": "global",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_4",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_q_proj",
      "layer": "layer_0",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_5",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_k_proj",
      "layer": "layer_0",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_6",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_v_proj",
      "layer": "layer_0",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_7",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_o_proj",
      "layer": "layer_0",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_8",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_gate_proj",
      "layer": "layer_0",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_9",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_up_proj",
      "layer": "layer_0",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_10",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_down_proj",
      "layer": "layer_0",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_11",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer0_input_layernorm",
      "layer": "layer_0",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_12",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer0_post_attention_layernorm",
      "layer": "layer_0",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_13",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_14",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_15",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer0_attention_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_16",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_q_proj",
      "layer": "layer_1",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_17",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_k_proj",
      "layer": "layer_1",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_18",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_v_proj",
      "layer": "layer_1",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_19",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_o_proj",
      "layer": "layer_1",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_20",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_gate_proj",
      "layer": "layer_1",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_21",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_up_proj",
      "layer": "layer_1",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_22",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_down_proj",
      "layer": "layer_1",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_23",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer1_input_layernorm",
      "layer": "layer_1",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_24",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer1_post_attention_layernorm",
      "layer": "layer_1",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_25",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_26",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_27",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer1_attention_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_28",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_q_proj",
      "layer": "layer_2",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_29",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_k_proj",
      "layer": "layer_2",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_30",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_v_proj",
      "layer": "layer_2",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_31",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_o_proj",
      "layer": "layer_2",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_32",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_gate_proj",
      "layer": "layer_2",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_33",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_up_proj",
      "layer": "layer_2",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_34",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_down_proj",
      "layer": "layer_2",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_35",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer2_input_layernorm",
      "layer": "layer_2",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_36",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer2_post_attention_layernorm",
      "layer": "layer_2",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_37",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_38",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_39",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer2_attention_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_40",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_q_proj",
      "layer": "layer_3",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_41",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_k_proj",
      "layer": "layer_3",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_42",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_v_proj",
      "layer": "layer_3",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_43",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_o_proj",
      "layer": "layer_3",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_44",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_gate_proj",
      "layer": "layer_3",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_45",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_up_proj",
      "layer": "layer_3",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_46",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_down_proj",
      "layer": "layer_3",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_47",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer3_input_layernorm",
      "layer": "layer_3",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_48",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer3_post_attention_layernorm",
      "layer": "layer_3",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_49",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_50",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_51",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer3_attention_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_52",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_q_proj",
      "layer": "layer_4",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_53",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_k_proj",
      "layer": "layer_4",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_54",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_v_proj",
      "layer": "layer_4",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_55",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_o_proj",
      "layer": "layer_4",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_56",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_gate_proj",
      "layer": "layer_4",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_57",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_up_proj",
      "layer": "layer_4",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_58",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_down_proj",
      "layer": "layer_4",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_59",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer4_input_layernorm",
      "layer": "layer_4",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_60",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer4_post_attention_layernorm",
      "layer": "layer_4",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_61",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_62",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_63",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer4_attention_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_64",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_q_proj",
      "layer": "layer_5",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_65",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_k_proj",
      "layer": "layer_5",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_66",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_v_proj",
      "layer": "layer_5",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_67",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_o_proj",
      "layer": "layer_5",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_68",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_gate_proj",
      "layer": "layer_5",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_69",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_up_proj",
      "layer": "layer_5",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_70",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_down_proj",
      "layer": "layer_5",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_71",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer5_input_layernorm",
      "layer": "layer_5",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_72",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer5_post_attention_layernorm",
      "layer": "layer_5",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_73",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_74",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_75",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer5_attention_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_76",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_q_proj",
      "layer": "layer_6",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_77",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_k_proj",
      "layer": "layer_6",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_78",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_v_proj",
      "layer": "layer_6",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_79",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_o_proj",
      "layer": "layer_6",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_80",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_gate_proj",
      "layer": "layer_6",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_81",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_up_proj",
      "layer": "layer_6",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_82",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_down_proj",
      "layer": "layer_6",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_83",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer6_input_layernorm",
      "layer": "layer_6",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_84",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer6_post_attention_layernorm",
      "layer": "layer_6",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_85",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_86",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_87",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer6_attention_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_88",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_q_proj",
      "layer": "layer_7",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_89",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_k_proj",
      "layer": "layer_7",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_90",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_v_proj",
      "layer": "layer_7",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_91",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_o_proj",
      "layer": "layer_7",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_92",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_gate_proj",
      "layer": "layer_7",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_93",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_up_proj",
      "layer": "layer_7",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_94",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_down_proj",
      "layer": "layer_7",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_95",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer7_input_layernorm",
      "layer": "layer_7",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_96",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer7_post_attention_layernorm",
      "layer": "layer_7",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_97",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_98",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_99",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer7_attention_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_100",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_q_proj",
      "layer": "layer_8",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_101",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_k_proj",
      "layer": "layer_8",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_102",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_v_proj",
      "layer": "layer_8",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_103",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_o_proj",
      "layer": "layer_8",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_104",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_gate_proj",
      "layer": "layer_8",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_105",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_up_proj",
      "layer": "layer_8",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_106",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_down_proj",
      "layer": "layer_8",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_107",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer8_input_layernorm",
      "layer": "layer_8",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_108",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer8_post_attention_layernorm",
      "layer": "layer_8",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_109",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_110",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_111",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer8_attention_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_112",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_q_proj",
      "layer": "layer_9",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_113",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_k_proj",
      "layer": "layer_9",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_114",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_v_proj",
      "layer": "layer_9",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_115",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_o_proj",
      "layer": "layer_9",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_116",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_gate_proj",
      "layer": "layer_9",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_117",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_up_proj",
      "layer": "layer_9",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_118",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_down_proj",
      "layer": "layer_9",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_119",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer9_input_layernorm",
      "layer": "layer_9",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_120",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer9_post_attention_layernorm",
      "layer": "layer_9",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_121",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_122",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_123",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer9_attention_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_124",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_q_proj",
      "layer": "layer_10",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_125",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_k_proj",
      "layer": "layer_10",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_126",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_v_proj",
      "layer": "layer_10",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_127",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_o_proj",
      "layer": "layer_10",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_128",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_gate_proj",
      "layer": "layer_10",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_129",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_up_proj",
      "layer": "layer_10",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_130",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_down_proj",
      "layer": "layer_10",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_131",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer10_input_layernorm",
      "layer": "layer_10",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_132",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer10_post_attention_layernorm",
      "layer": "layer_10",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_133",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_134",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_135",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer10_attention_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_136",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_q_proj",
      "layer": "layer_11",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_137",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_k_proj",
      "layer": "layer_11",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_138",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_v_proj",
      "layer": "layer_11",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_139",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_o_proj",
      "layer": "layer_11",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_140",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_gate_proj",
      "layer": "layer_11",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_141",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_up_proj",
      "layer": "layer_11",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_142",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_down_proj",
      "layer": "layer_11",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_143",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer11_input_layernorm",
      "layer": "layer_11",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_144",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer11_post_attention_layernorm",
      "layer": "layer_11",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_145",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_146",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_147",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer11_attention_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_148",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_q_proj",
      "layer": "layer_12",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_149",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_k_proj",
      "layer": "layer_12",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_150",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_v_proj",
      "layer": "layer_12",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_151",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_o_proj",
      "layer": "layer_12",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_152",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_gate_proj",
      "layer": "layer_12",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_153",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_up_proj",
      "layer": "layer_12",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_154",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_down_proj",
      "layer": "layer_12",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_155",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer12_input_layernorm",
      "layer": "layer_12",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_156",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer12_post_attention_layernorm",
      "layer": "layer_12",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_157",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer12_attention_softmax",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_158",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer12_activation",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_159",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer12_attention_dropout",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_160",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_q_proj",
      "layer": "layer_13",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_161",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_k_proj",
      "layer": "layer_13",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_162",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_v_proj",
      "layer": "layer_13",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_163",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_o_proj",
      "layer": "layer_13",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_164",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_gate_proj",
      "layer": "layer_13",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_165",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_up_proj",
      "layer": "layer_13",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_166",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_down_proj",
      "layer": "layer_13",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_167",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer13_input_layernorm",
      "layer": "layer_13",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_168",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer13_post_attention_layernorm",
      "layer": "layer_13",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_169",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer13_attention_softmax",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_170",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer13_activation",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_171",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer13_attention_dropout",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_172",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_q_proj",
      "layer": "layer_14",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_173",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_k_proj",
      "layer": "layer_14",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_174",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_v_proj",
      "layer": "layer_14",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_175",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_o_proj",
      "layer": "layer_14",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_176",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_gate_proj",
      "layer": "layer_14",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_177",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_up_proj",
      "layer": "layer_14",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_178",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_down_proj",
      "layer": "layer_14",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_179",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer14_input_layernorm",
      "layer": "layer_14",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_180",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer14_post_attention_layernorm",
      "layer": "layer_14",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_181",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer14_attention_softmax",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_182",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer14_activation",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_183",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer14_attention_dropout",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_184",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_q_proj",
      "layer": "layer_15",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_185",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_k_proj",
      "layer": "layer_15",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_186",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_v_proj",
      "layer": "layer_15",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_187",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_o_proj",
      "layer": "layer_15",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_188",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_gate_proj",
      "layer": "layer_15",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_189",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_up_proj",
      "layer": "layer_15",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_190",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_down_proj",
      "layer": "layer_15",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_191",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer15_input_layernorm",
      "layer": "layer_15",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_192",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer15_post_attention_layernorm",
      "layer": "layer_15",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_193",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer15_attention_softmax",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_194",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer15_activation",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_195",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer15_attention_dropout",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_196",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_q_proj",
      "layer": "layer_16",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_197",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_k_proj",
      "layer": "layer_16",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_198",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_v_proj",
      "layer": "layer_16",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_199",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_o_proj",
      "layer": "layer_16",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_200",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_gate_proj",
      "layer": "layer_16",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_201",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_up_proj",
      "layer": "layer_16",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_202",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_down_proj",
      "layer": "layer_16",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_203",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer16_input_layernorm",
      "layer": "layer_16",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_204",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer16_post_attention_layernorm",
      "layer": "layer_16",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_205",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer16_attention_softmax",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_206",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer16_activation",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_207",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer16_attention_dropout",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_208",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_q_proj",
      "layer": "layer_17",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_209",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_k_proj",
      "layer": "layer_17",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_210",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_v_proj",
      "layer": "layer_17",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_211",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_o_proj",
      "layer": "layer_17",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_212",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_gate_proj",
      "layer": "layer_17",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_213",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_up_proj",
      "layer": "layer_17",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_214",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_down_proj",
      "layer": "layer_17",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_215",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer17_input_layernorm",
      "layer": "layer_17",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_216",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer17_post_attention_layernorm",
      "layer": "layer_17",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_217",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer17_attention_softmax",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_218",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer17_activation",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_219",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer17_attention_dropout",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_220",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_q_proj",
      "layer": "layer_18",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_221",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_k_proj",
      "layer": "layer_18",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_222",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_v_proj",
      "layer": "layer_18",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_223",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_o_proj",
      "layer": "layer_18",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_224",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_gate_proj",
      "layer": "layer_18",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_225",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_up_proj",
      "layer": "layer_18",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_226",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_down_proj",
      "layer": "layer_18",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_227",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer18_input_layernorm",
      "layer": "layer_18",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_228",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer18_post_attention_layernorm",
      "layer": "layer_18",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_229",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer18_attention_softmax",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_230",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer18_activation",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_231",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer18_attention_dropout",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_232",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_q_proj",
      "layer": "layer_19",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_233",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_k_proj",
      "layer": "layer_19",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_234",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_v_proj",
      "layer": "layer_19",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_235",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_o_proj",
      "layer": "layer_19",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_236",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_gate_proj",
      "layer": "layer_19",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_237",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_up_proj",
      "layer": "layer_19",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_238",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_down_proj",
      "layer": "layer_19",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_239",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer19_input_layernorm",
      "layer": "layer_19",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_240",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer19_post_attention_layernorm",
      "layer": "layer_19",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_241",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer19_attention_softmax",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_242",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer19_activation",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_243",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer19_attention_dropout",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_244",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_q_proj",
      "layer": "layer_20",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_245",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_k_proj",
      "layer": "layer_20",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_246",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_v_proj",
      "layer": "layer_20",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_247",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_o_proj",
      "layer": "layer_20",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_248",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_gate_proj",
      "layer": "layer_20",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_249",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_up_proj",
      "layer": "layer_20",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_250",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_down_proj",
      "layer": "layer_20",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_251",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer20_input_layernorm",
      "layer": "layer_20",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_252",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer20_post_attention_layernorm",
      "layer": "layer_20",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_253",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer20_attention_softmax",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_254",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer20_activation",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_255",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer20_attention_dropout",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_256",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_q_proj",
      "layer": "layer_21",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_257",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_k_proj",
      "layer": "layer_21",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_258",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_v_proj",
      "layer": "layer_21",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_259",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_o_proj",
      "layer": "layer_21",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_260",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_gate_proj",
      "layer": "layer_21",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_261",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_up_proj",
      "layer": "layer_21",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_262",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_down_proj",
      "layer": "layer_21",
      "parameters": 11534336,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_263",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer21_input_layernorm",
      "layer": "layer_21",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_264",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "RMSNorm",
      "name": "layer21_post_attention_layernorm",
      "layer": "layer_21",
      "parameters": 2048,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_265",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer21_attention_softmax",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_266",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "SiLU",
      "name": "layer21_activation",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 5632]",
      "output_shape": "[batch, seq, 5632]"
    },
    {
      "op_id": "TinyLlama_1.1B_op_267",
      "model_name": "TinyLlama-1.1B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer21_attention_dropout",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_1",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Embedding",
      "name": "wte",
      "layer": "global",
      "parameters": 4194304,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_2",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Embedding",
      "name": "wpe",
      "layer": "global",
      "parameters": 4194304,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_3",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "ln_f",
      "layer": "global",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_4",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_attn",
      "layer": "layer_0",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_5",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_proj",
      "layer": "layer_0",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_6",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_fc",
      "layer": "layer_0",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_7",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_proj_mlp",
      "layer": "layer_0",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_8",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer0_ln_1",
      "layer": "layer_0",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_9",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer0_ln_2",
      "layer": "layer_0",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_10",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_11",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_12",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer0_attn_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_13",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer0_resid_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_14",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_attn",
      "layer": "layer_1",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_15",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_proj",
      "layer": "layer_1",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_16",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_fc",
      "layer": "layer_1",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_17",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_proj_mlp",
      "layer": "layer_1",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_18",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer1_ln_1",
      "layer": "layer_1",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_19",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer1_ln_2",
      "layer": "layer_1",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_20",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_21",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_22",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer1_attn_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_23",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer1_resid_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_24",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_attn",
      "layer": "layer_2",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_25",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_proj",
      "layer": "layer_2",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_26",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_fc",
      "layer": "layer_2",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_27",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_proj_mlp",
      "layer": "layer_2",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_28",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer2_ln_1",
      "layer": "layer_2",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_29",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer2_ln_2",
      "layer": "layer_2",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_30",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_31",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_32",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer2_attn_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_33",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer2_resid_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_34",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_attn",
      "layer": "layer_3",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_35",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_proj",
      "layer": "layer_3",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_36",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_fc",
      "layer": "layer_3",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_37",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_proj_mlp",
      "layer": "layer_3",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_38",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer3_ln_1",
      "layer": "layer_3",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_39",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer3_ln_2",
      "layer": "layer_3",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_40",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_41",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_42",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer3_attn_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_43",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer3_resid_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_44",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_attn",
      "layer": "layer_4",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_45",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_proj",
      "layer": "layer_4",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_46",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_fc",
      "layer": "layer_4",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_47",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_proj_mlp",
      "layer": "layer_4",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_48",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer4_ln_1",
      "layer": "layer_4",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_49",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer4_ln_2",
      "layer": "layer_4",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_50",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_51",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_52",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer4_attn_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_53",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer4_resid_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_54",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_attn",
      "layer": "layer_5",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_55",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_proj",
      "layer": "layer_5",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_56",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_fc",
      "layer": "layer_5",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_57",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_proj_mlp",
      "layer": "layer_5",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_58",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer5_ln_1",
      "layer": "layer_5",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_59",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer5_ln_2",
      "layer": "layer_5",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_60",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_61",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_62",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer5_attn_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_63",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer5_resid_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_64",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_attn",
      "layer": "layer_6",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_65",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_proj",
      "layer": "layer_6",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_66",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_fc",
      "layer": "layer_6",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_67",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_proj_mlp",
      "layer": "layer_6",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_68",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer6_ln_1",
      "layer": "layer_6",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_69",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer6_ln_2",
      "layer": "layer_6",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_70",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_71",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_72",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer6_attn_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_73",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer6_resid_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_74",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_attn",
      "layer": "layer_7",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_75",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_proj",
      "layer": "layer_7",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_76",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_fc",
      "layer": "layer_7",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_77",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_proj_mlp",
      "layer": "layer_7",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_78",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer7_ln_1",
      "layer": "layer_7",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_79",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer7_ln_2",
      "layer": "layer_7",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_80",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_81",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_82",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer7_attn_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_83",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer7_resid_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_84",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_attn",
      "layer": "layer_8",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_85",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_proj",
      "layer": "layer_8",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_86",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_fc",
      "layer": "layer_8",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_87",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_proj_mlp",
      "layer": "layer_8",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_88",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer8_ln_1",
      "layer": "layer_8",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_89",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer8_ln_2",
      "layer": "layer_8",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_90",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_91",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_92",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer8_attn_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_93",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer8_resid_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_94",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_attn",
      "layer": "layer_9",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_95",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_proj",
      "layer": "layer_9",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_96",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_fc",
      "layer": "layer_9",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_97",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_proj_mlp",
      "layer": "layer_9",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_98",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer9_ln_1",
      "layer": "layer_9",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_99",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer9_ln_2",
      "layer": "layer_9",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_100",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_101",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_102",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer9_attn_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_103",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer9_resid_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_104",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_attn",
      "layer": "layer_10",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_105",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_proj",
      "layer": "layer_10",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_106",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_fc",
      "layer": "layer_10",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_107",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_proj_mlp",
      "layer": "layer_10",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_108",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer10_ln_1",
      "layer": "layer_10",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_109",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer10_ln_2",
      "layer": "layer_10",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_110",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_111",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_112",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer10_attn_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_113",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer10_resid_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_114",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_attn",
      "layer": "layer_11",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_115",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_proj",
      "layer": "layer_11",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_116",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_fc",
      "layer": "layer_11",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_117",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_proj_mlp",
      "layer": "layer_11",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_118",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer11_ln_1",
      "layer": "layer_11",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_119",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer11_ln_2",
      "layer": "layer_11",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_120",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_121",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_122",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer11_attn_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_123",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer11_resid_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_124",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_c_attn",
      "layer": "layer_12",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_125",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_c_proj",
      "layer": "layer_12",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_126",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_c_fc",
      "layer": "layer_12",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_127",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_c_proj_mlp",
      "layer": "layer_12",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_128",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer12_ln_1",
      "layer": "layer_12",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_129",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer12_ln_2",
      "layer": "layer_12",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_130",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer12_attention_softmax",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_131",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer12_activation",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_132",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer12_attn_dropout",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_133",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer12_resid_dropout",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_134",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_c_attn",
      "layer": "layer_13",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_135",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_c_proj",
      "layer": "layer_13",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_136",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_c_fc",
      "layer": "layer_13",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_137",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_c_proj_mlp",
      "layer": "layer_13",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_138",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer13_ln_1",
      "layer": "layer_13",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_139",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer13_ln_2",
      "layer": "layer_13",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_140",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer13_attention_softmax",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_141",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer13_activation",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_142",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer13_attn_dropout",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_143",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer13_resid_dropout",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_144",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_c_attn",
      "layer": "layer_14",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_145",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_c_proj",
      "layer": "layer_14",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_146",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_c_fc",
      "layer": "layer_14",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_147",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_c_proj_mlp",
      "layer": "layer_14",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_148",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer14_ln_1",
      "layer": "layer_14",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_149",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer14_ln_2",
      "layer": "layer_14",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_150",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer14_attention_softmax",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_151",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer14_activation",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_152",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer14_attn_dropout",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_153",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer14_resid_dropout",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_154",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_c_attn",
      "layer": "layer_15",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_155",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_c_proj",
      "layer": "layer_15",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_156",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_c_fc",
      "layer": "layer_15",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_157",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_c_proj_mlp",
      "layer": "layer_15",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_158",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer15_ln_1",
      "layer": "layer_15",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_159",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer15_ln_2",
      "layer": "layer_15",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_160",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer15_attention_softmax",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_161",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer15_activation",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_162",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer15_attn_dropout",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_163",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer15_resid_dropout",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_164",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_c_attn",
      "layer": "layer_16",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_165",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_c_proj",
      "layer": "layer_16",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_166",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_c_fc",
      "layer": "layer_16",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_167",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_c_proj_mlp",
      "layer": "layer_16",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_168",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer16_ln_1",
      "layer": "layer_16",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_169",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer16_ln_2",
      "layer": "layer_16",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_170",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer16_attention_softmax",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_171",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer16_activation",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_172",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer16_attn_dropout",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_173",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer16_resid_dropout",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_174",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_c_attn",
      "layer": "layer_17",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_175",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_c_proj",
      "layer": "layer_17",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_176",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_c_fc",
      "layer": "layer_17",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_177",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_c_proj_mlp",
      "layer": "layer_17",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_178",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer17_ln_1",
      "layer": "layer_17",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_179",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer17_ln_2",
      "layer": "layer_17",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_180",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer17_attention_softmax",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_181",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer17_activation",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_182",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer17_attn_dropout",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_183",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer17_resid_dropout",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_184",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_c_attn",
      "layer": "layer_18",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_185",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_c_proj",
      "layer": "layer_18",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_186",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_c_fc",
      "layer": "layer_18",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_187",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_c_proj_mlp",
      "layer": "layer_18",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_188",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer18_ln_1",
      "layer": "layer_18",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_189",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer18_ln_2",
      "layer": "layer_18",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_190",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer18_attention_softmax",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_191",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer18_activation",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_192",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer18_attn_dropout",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_193",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer18_resid_dropout",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_194",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_c_attn",
      "layer": "layer_19",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_195",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_c_proj",
      "layer": "layer_19",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_196",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_c_fc",
      "layer": "layer_19",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_197",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_c_proj_mlp",
      "layer": "layer_19",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_198",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer19_ln_1",
      "layer": "layer_19",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_199",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer19_ln_2",
      "layer": "layer_19",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_200",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer19_attention_softmax",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_201",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer19_activation",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_202",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer19_attn_dropout",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_203",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer19_resid_dropout",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_204",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_c_attn",
      "layer": "layer_20",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_205",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_c_proj",
      "layer": "layer_20",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_206",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_c_fc",
      "layer": "layer_20",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_207",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_c_proj_mlp",
      "layer": "layer_20",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_208",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer20_ln_1",
      "layer": "layer_20",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_209",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer20_ln_2",
      "layer": "layer_20",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_210",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer20_attention_softmax",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_211",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer20_activation",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_212",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer20_attn_dropout",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_213",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer20_resid_dropout",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_214",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_c_attn",
      "layer": "layer_21",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_215",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_c_proj",
      "layer": "layer_21",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_216",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_c_fc",
      "layer": "layer_21",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_217",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_c_proj_mlp",
      "layer": "layer_21",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_218",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer21_ln_1",
      "layer": "layer_21",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_219",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer21_ln_2",
      "layer": "layer_21",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_220",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer21_attention_softmax",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_221",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer21_activation",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_222",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer21_attn_dropout",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_223",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer21_resid_dropout",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_224",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_c_attn",
      "layer": "layer_22",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_225",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_c_proj",
      "layer": "layer_22",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_226",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_c_fc",
      "layer": "layer_22",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_227",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_c_proj_mlp",
      "layer": "layer_22",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_228",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer22_ln_1",
      "layer": "layer_22",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_229",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer22_ln_2",
      "layer": "layer_22",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_230",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer22_attention_softmax",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_231",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer22_activation",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_232",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer22_attn_dropout",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_233",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer22_resid_dropout",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_234",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_c_attn",
      "layer": "layer_23",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_235",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_c_proj",
      "layer": "layer_23",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_236",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_c_fc",
      "layer": "layer_23",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_237",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_c_proj_mlp",
      "layer": "layer_23",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Pythia_1.4B_op_238",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer23_ln_1",
      "layer": "layer_23",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_239",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer23_ln_2",
      "layer": "layer_23",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_240",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer23_attention_softmax",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Pythia_1.4B_op_241",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer23_activation",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "Pythia_1.4B_op_242",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer23_attn_dropout",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Pythia_1.4B_op_243",
      "model_name": "Pythia-1.4B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer23_resid_dropout",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "ResNet_50_op_1",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "conv1",
      "layer": "global",
      "parameters": 9408,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_2",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "bn1",
      "layer": "global",
      "parameters": 256,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, H, W]"
    },
    {
      "op_id": "ResNet_50_op_3",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "ReLU",
      "name": "relu",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, H, W]"
    },
    {
      "op_id": "ResNet_50_op_4",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "MaxPool2d",
      "name": "maxpool",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, H/2, W/2]"
    },
    {
      "op_id": "ResNet_50_op_5",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "AdaptiveAvgPool2d",
      "name": "avgpool",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, 1, 1]"
    },
    {
      "op_id": "ResNet_50_op_6",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Linear",
      "name": "fc",
      "layer": "global",
      "parameters": 2048000,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ResNet_50_op_7",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block1_conv1",
      "layer": "stage1_block1",
      "parameters": 8192,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_8",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block1_conv2",
      "layer": "stage1_block1",
      "parameters": 147456,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_9",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block1_conv3",
      "layer": "stage1_block1",
      "parameters": 65536,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_10",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block1_bn1",
      "layer": "stage1_block1",
      "parameters": 512,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "ResNet_50_op_11",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block1_bn2",
      "layer": "stage1_block1",
      "parameters": 512,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "ResNet_50_op_12",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block1_bn3",
      "layer": "stage1_block1",
      "parameters": 2048,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "ResNet_50_op_13",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage1_block1_relu",
      "layer": "stage1_block1",
      "parameters": 0,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "ResNet_50_op_14",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block2_conv1",
      "layer": "stage1_block2",
      "parameters": 8192,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_15",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block2_conv2",
      "layer": "stage1_block2",
      "parameters": 147456,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_16",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block2_conv3",
      "layer": "stage1_block2",
      "parameters": 65536,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_17",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block2_bn1",
      "layer": "stage1_block2",
      "parameters": 512,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "ResNet_50_op_18",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block2_bn2",
      "layer": "stage1_block2",
      "parameters": 512,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "ResNet_50_op_19",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block2_bn3",
      "layer": "stage1_block2",
      "parameters": 2048,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "ResNet_50_op_20",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage1_block2_relu",
      "layer": "stage1_block2",
      "parameters": 0,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "ResNet_50_op_21",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block3_conv1",
      "layer": "stage1_block3",
      "parameters": 8192,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_22",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block3_conv2",
      "layer": "stage1_block3",
      "parameters": 147456,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_23",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block3_conv3",
      "layer": "stage1_block3",
      "parameters": 65536,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_24",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block3_bn1",
      "layer": "stage1_block3",
      "parameters": 512,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "ResNet_50_op_25",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block3_bn2",
      "layer": "stage1_block3",
      "parameters": 512,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "ResNet_50_op_26",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block3_bn3",
      "layer": "stage1_block3",
      "parameters": 2048,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "ResNet_50_op_27",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage1_block3_relu",
      "layer": "stage1_block3",
      "parameters": 0,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "ResNet_50_op_28",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block1_conv1",
      "layer": "stage2_block1",
      "parameters": 32768,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_29",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block1_conv2",
      "layer": "stage2_block1",
      "parameters": 589824,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_30",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block1_conv3",
      "layer": "stage2_block1",
      "parameters": 262144,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_31",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block1_bn1",
      "layer": "stage2_block1",
      "parameters": 1024,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ResNet_50_op_32",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block1_bn2",
      "layer": "stage2_block1",
      "parameters": 1024,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ResNet_50_op_33",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block1_bn3",
      "layer": "stage2_block1",
      "parameters": 4096,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ResNet_50_op_34",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage2_block1_relu",
      "layer": "stage2_block1",
      "parameters": 0,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ResNet_50_op_35",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block2_conv1",
      "layer": "stage2_block2",
      "parameters": 32768,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_36",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block2_conv2",
      "layer": "stage2_block2",
      "parameters": 589824,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_37",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block2_conv3",
      "layer": "stage2_block2",
      "parameters": 262144,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_38",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block2_bn1",
      "layer": "stage2_block2",
      "parameters": 1024,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ResNet_50_op_39",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block2_bn2",
      "layer": "stage2_block2",
      "parameters": 1024,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ResNet_50_op_40",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block2_bn3",
      "layer": "stage2_block2",
      "parameters": 4096,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ResNet_50_op_41",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage2_block2_relu",
      "layer": "stage2_block2",
      "parameters": 0,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ResNet_50_op_42",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block3_conv1",
      "layer": "stage2_block3",
      "parameters": 32768,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_43",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block3_conv2",
      "layer": "stage2_block3",
      "parameters": 589824,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_44",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block3_conv3",
      "layer": "stage2_block3",
      "parameters": 262144,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_45",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block3_bn1",
      "layer": "stage2_block3",
      "parameters": 1024,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ResNet_50_op_46",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block3_bn2",
      "layer": "stage2_block3",
      "parameters": 1024,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ResNet_50_op_47",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block3_bn3",
      "layer": "stage2_block3",
      "parameters": 4096,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ResNet_50_op_48",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage2_block3_relu",
      "layer": "stage2_block3",
      "parameters": 0,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ResNet_50_op_49",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block4_conv1",
      "layer": "stage2_block4",
      "parameters": 32768,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_50",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block4_conv2",
      "layer": "stage2_block4",
      "parameters": 589824,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_51",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block4_conv3",
      "layer": "stage2_block4",
      "parameters": 262144,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_52",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block4_bn1",
      "layer": "stage2_block4",
      "parameters": 1024,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ResNet_50_op_53",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block4_bn2",
      "layer": "stage2_block4",
      "parameters": 1024,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ResNet_50_op_54",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block4_bn3",
      "layer": "stage2_block4",
      "parameters": 4096,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ResNet_50_op_55",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage2_block4_relu",
      "layer": "stage2_block4",
      "parameters": 0,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ResNet_50_op_56",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block1_conv1",
      "layer": "stage3_block1",
      "parameters": 131072,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_57",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block1_conv2",
      "layer": "stage3_block1",
      "parameters": 2359296,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_58",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block1_conv3",
      "layer": "stage3_block1",
      "parameters": 1048576,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_59",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block1_bn1",
      "layer": "stage3_block1",
      "parameters": 2048,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_60",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block1_bn2",
      "layer": "stage3_block1",
      "parameters": 2048,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_61",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block1_bn3",
      "layer": "stage3_block1",
      "parameters": 8192,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_62",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block1_relu",
      "layer": "stage3_block1",
      "parameters": 0,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_63",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block2_conv1",
      "layer": "stage3_block2",
      "parameters": 131072,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_64",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block2_conv2",
      "layer": "stage3_block2",
      "parameters": 2359296,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_65",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block2_conv3",
      "layer": "stage3_block2",
      "parameters": 1048576,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_66",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block2_bn1",
      "layer": "stage3_block2",
      "parameters": 2048,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_67",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block2_bn2",
      "layer": "stage3_block2",
      "parameters": 2048,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_68",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block2_bn3",
      "layer": "stage3_block2",
      "parameters": 8192,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_69",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block2_relu",
      "layer": "stage3_block2",
      "parameters": 0,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_70",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block3_conv1",
      "layer": "stage3_block3",
      "parameters": 131072,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_71",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block3_conv2",
      "layer": "stage3_block3",
      "parameters": 2359296,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_72",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block3_conv3",
      "layer": "stage3_block3",
      "parameters": 1048576,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_73",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block3_bn1",
      "layer": "stage3_block3",
      "parameters": 2048,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_74",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block3_bn2",
      "layer": "stage3_block3",
      "parameters": 2048,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_75",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block3_bn3",
      "layer": "stage3_block3",
      "parameters": 8192,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_76",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block3_relu",
      "layer": "stage3_block3",
      "parameters": 0,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_77",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block4_conv1",
      "layer": "stage3_block4",
      "parameters": 131072,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_78",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block4_conv2",
      "layer": "stage3_block4",
      "parameters": 2359296,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_79",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block4_conv3",
      "layer": "stage3_block4",
      "parameters": 1048576,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_80",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block4_bn1",
      "layer": "stage3_block4",
      "parameters": 2048,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_81",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block4_bn2",
      "layer": "stage3_block4",
      "parameters": 2048,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_82",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block4_bn3",
      "layer": "stage3_block4",
      "parameters": 8192,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_83",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block4_relu",
      "layer": "stage3_block4",
      "parameters": 0,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_84",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block5_conv1",
      "layer": "stage3_block5",
      "parameters": 131072,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_85",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block5_conv2",
      "layer": "stage3_block5",
      "parameters": 2359296,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_86",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block5_conv3",
      "layer": "stage3_block5",
      "parameters": 1048576,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_87",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block5_bn1",
      "layer": "stage3_block5",
      "parameters": 2048,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_88",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block5_bn2",
      "layer": "stage3_block5",
      "parameters": 2048,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_89",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block5_bn3",
      "layer": "stage3_block5",
      "parameters": 8192,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_90",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block5_relu",
      "layer": "stage3_block5",
      "parameters": 0,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_91",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block6_conv1",
      "layer": "stage3_block6",
      "parameters": 131072,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_92",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block6_conv2",
      "layer": "stage3_block6",
      "parameters": 2359296,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_93",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block6_conv3",
      "layer": "stage3_block6",
      "parameters": 1048576,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_94",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block6_bn1",
      "layer": "stage3_block6",
      "parameters": 2048,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_95",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block6_bn2",
      "layer": "stage3_block6",
      "parameters": 2048,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_96",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block6_bn3",
      "layer": "stage3_block6",
      "parameters": 8192,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_97",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block6_relu",
      "layer": "stage3_block6",
      "parameters": 0,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ResNet_50_op_98",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block1_conv1",
      "layer": "stage4_block1",
      "parameters": 262144,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_99",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block1_conv2",
      "layer": "stage4_block1",
      "parameters": 2359296,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_100",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block1_conv3",
      "layer": "stage4_block1",
      "parameters": 1048576,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_101",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block1_bn1",
      "layer": "stage4_block1",
      "parameters": 2048,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ResNet_50_op_102",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block1_bn2",
      "layer": "stage4_block1",
      "parameters": 2048,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ResNet_50_op_103",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block1_bn3",
      "layer": "stage4_block1",
      "parameters": 8192,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ResNet_50_op_104",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage4_block1_relu",
      "layer": "stage4_block1",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ResNet_50_op_105",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block2_conv1",
      "layer": "stage4_block2",
      "parameters": 262144,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_106",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block2_conv2",
      "layer": "stage4_block2",
      "parameters": 2359296,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_107",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block2_conv3",
      "layer": "stage4_block2",
      "parameters": 1048576,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_108",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block2_bn1",
      "layer": "stage4_block2",
      "parameters": 2048,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ResNet_50_op_109",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block2_bn2",
      "layer": "stage4_block2",
      "parameters": 2048,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ResNet_50_op_110",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block2_bn3",
      "layer": "stage4_block2",
      "parameters": 8192,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ResNet_50_op_111",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage4_block2_relu",
      "layer": "stage4_block2",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ResNet_50_op_112",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block3_conv1",
      "layer": "stage4_block3",
      "parameters": 262144,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_113",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block3_conv2",
      "layer": "stage4_block3",
      "parameters": 2359296,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_114",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block3_conv3",
      "layer": "stage4_block3",
      "parameters": 1048576,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ResNet_50_op_115",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block3_bn1",
      "layer": "stage4_block3",
      "parameters": 2048,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ResNet_50_op_116",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block3_bn2",
      "layer": "stage4_block3",
      "parameters": 2048,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ResNet_50_op_117",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block3_bn3",
      "layer": "stage4_block3",
      "parameters": 8192,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ResNet_50_op_118",
      "model_name": "ResNet-50",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage4_block3_relu",
      "layer": "stage4_block3",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ViT_Base_op_1",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "patch_embed",
      "layer": "global",
      "parameters": 2073600000000,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ViT_Base_op_2",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "norm",
      "layer": "global",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_3",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "head",
      "layer": "global",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_4",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_qkv",
      "layer": "layer_0",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_5",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_proj",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_6",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_fc1",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_7",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_fc2",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_8",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer0_norm1",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_9",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer0_norm2",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_10",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ViT_Base_op_11",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ViT_Base_op_12",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer0_attn_drop",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_13",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer0_proj_drop",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_14",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_qkv",
      "layer": "layer_1",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_15",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_proj",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_16",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_fc1",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_17",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_fc2",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_18",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer1_norm1",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_19",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer1_norm2",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_20",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ViT_Base_op_21",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ViT_Base_op_22",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer1_attn_drop",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_23",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer1_proj_drop",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_24",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_qkv",
      "layer": "layer_2",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_25",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_proj",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_26",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_fc1",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_27",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_fc2",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_28",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer2_norm1",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_29",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer2_norm2",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_30",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ViT_Base_op_31",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ViT_Base_op_32",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer2_attn_drop",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_33",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer2_proj_drop",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_34",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_qkv",
      "layer": "layer_3",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_35",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_proj",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_36",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_fc1",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_37",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_fc2",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_38",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer3_norm1",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_39",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer3_norm2",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_40",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ViT_Base_op_41",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ViT_Base_op_42",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer3_attn_drop",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_43",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer3_proj_drop",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_44",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_qkv",
      "layer": "layer_4",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_45",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_proj",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_46",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_fc1",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_47",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_fc2",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_48",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer4_norm1",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_49",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer4_norm2",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_50",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ViT_Base_op_51",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ViT_Base_op_52",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer4_attn_drop",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_53",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer4_proj_drop",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_54",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_qkv",
      "layer": "layer_5",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_55",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_proj",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_56",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_fc1",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_57",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_fc2",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_58",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer5_norm1",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_59",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer5_norm2",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_60",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ViT_Base_op_61",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ViT_Base_op_62",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer5_attn_drop",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_63",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer5_proj_drop",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_64",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_qkv",
      "layer": "layer_6",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_65",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_proj",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_66",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_fc1",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_67",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_fc2",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_68",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer6_norm1",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_69",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer6_norm2",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_70",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ViT_Base_op_71",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ViT_Base_op_72",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer6_attn_drop",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_73",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer6_proj_drop",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_74",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_qkv",
      "layer": "layer_7",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_75",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_proj",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_76",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_fc1",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_77",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_fc2",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_78",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer7_norm1",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_79",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer7_norm2",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_80",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ViT_Base_op_81",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ViT_Base_op_82",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer7_attn_drop",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_83",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer7_proj_drop",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_84",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_qkv",
      "layer": "layer_8",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_85",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_proj",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_86",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_fc1",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_87",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_fc2",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_88",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer8_norm1",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_89",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer8_norm2",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_90",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ViT_Base_op_91",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ViT_Base_op_92",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer8_attn_drop",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_93",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer8_proj_drop",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_94",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_qkv",
      "layer": "layer_9",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_95",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_proj",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_96",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_fc1",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_97",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_fc2",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_98",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer9_norm1",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_99",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer9_norm2",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_100",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ViT_Base_op_101",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ViT_Base_op_102",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer9_attn_drop",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_103",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer9_proj_drop",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_104",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_qkv",
      "layer": "layer_10",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_105",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_proj",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_106",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_fc1",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_107",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_fc2",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_108",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer10_norm1",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_109",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer10_norm2",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_110",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ViT_Base_op_111",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ViT_Base_op_112",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer10_attn_drop",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_113",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer10_proj_drop",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_114",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_qkv",
      "layer": "layer_11",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_115",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_proj",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_116",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_fc1",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_117",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_fc2",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ViT_Base_op_118",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer11_norm1",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_119",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer11_norm2",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_120",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ViT_Base_op_121",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ViT_Base_op_122",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer11_attn_drop",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ViT_Base_op_123",
      "model_name": "ViT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer11_proj_drop",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Swin_Base_op_1",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "patch_embed",
      "layer": "global",
      "parameters": 4608,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "Swin_Base_op_2",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "norm",
      "layer": "global",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_3",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "head",
      "layer": "global",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_4",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_qkv",
      "layer": "layer_0",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_5",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_proj",
      "layer": "layer_0",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_6",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_fc1",
      "layer": "layer_0",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_7",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_fc2",
      "layer": "layer_0",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_8",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer0_norm1",
      "layer": "layer_0",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_9",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer0_norm2",
      "layer": "layer_0",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_10",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_11",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_12",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer0_attn_drop",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_13",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer0_proj_drop",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_14",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_qkv",
      "layer": "layer_1",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_15",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_proj",
      "layer": "layer_1",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_16",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_fc1",
      "layer": "layer_1",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_17",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_fc2",
      "layer": "layer_1",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_18",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer1_norm1",
      "layer": "layer_1",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_19",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer1_norm2",
      "layer": "layer_1",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_20",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_21",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_22",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer1_attn_drop",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_23",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer1_proj_drop",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_24",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_qkv",
      "layer": "layer_2",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_25",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_proj",
      "layer": "layer_2",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_26",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_fc1",
      "layer": "layer_2",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_27",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_fc2",
      "layer": "layer_2",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_28",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer2_norm1",
      "layer": "layer_2",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_29",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer2_norm2",
      "layer": "layer_2",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_30",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_31",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_32",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer2_attn_drop",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_33",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer2_proj_drop",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_34",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_qkv",
      "layer": "layer_3",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_35",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_proj",
      "layer": "layer_3",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_36",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_fc1",
      "layer": "layer_3",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_37",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_fc2",
      "layer": "layer_3",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_38",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer3_norm1",
      "layer": "layer_3",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_39",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer3_norm2",
      "layer": "layer_3",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_40",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_41",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_42",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer3_attn_drop",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_43",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer3_proj_drop",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_44",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_qkv",
      "layer": "layer_4",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_45",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_proj",
      "layer": "layer_4",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_46",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_fc1",
      "layer": "layer_4",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_47",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_fc2",
      "layer": "layer_4",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_48",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer4_norm1",
      "layer": "layer_4",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_49",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer4_norm2",
      "layer": "layer_4",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_50",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_51",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_52",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer4_attn_drop",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_53",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer4_proj_drop",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_54",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_qkv",
      "layer": "layer_5",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_55",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_proj",
      "layer": "layer_5",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_56",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_fc1",
      "layer": "layer_5",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_57",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_fc2",
      "layer": "layer_5",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_58",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer5_norm1",
      "layer": "layer_5",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_59",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer5_norm2",
      "layer": "layer_5",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_60",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_61",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_62",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer5_attn_drop",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_63",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer5_proj_drop",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_64",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_qkv",
      "layer": "layer_6",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_65",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_proj",
      "layer": "layer_6",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_66",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_fc1",
      "layer": "layer_6",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_67",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_fc2",
      "layer": "layer_6",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_68",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer6_norm1",
      "layer": "layer_6",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_69",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer6_norm2",
      "layer": "layer_6",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_70",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_71",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_72",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer6_attn_drop",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_73",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer6_proj_drop",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_74",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_qkv",
      "layer": "layer_7",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_75",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_proj",
      "layer": "layer_7",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_76",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_fc1",
      "layer": "layer_7",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_77",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_fc2",
      "layer": "layer_7",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_78",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer7_norm1",
      "layer": "layer_7",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_79",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer7_norm2",
      "layer": "layer_7",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_80",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_81",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_82",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer7_attn_drop",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_83",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer7_proj_drop",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_84",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_qkv",
      "layer": "layer_8",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_85",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_proj",
      "layer": "layer_8",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_86",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_fc1",
      "layer": "layer_8",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_87",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_fc2",
      "layer": "layer_8",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_88",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer8_norm1",
      "layer": "layer_8",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_89",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer8_norm2",
      "layer": "layer_8",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_90",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_91",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_92",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer8_attn_drop",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_93",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer8_proj_drop",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_94",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_qkv",
      "layer": "layer_9",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_95",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_proj",
      "layer": "layer_9",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_96",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_fc1",
      "layer": "layer_9",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_97",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_fc2",
      "layer": "layer_9",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_98",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer9_norm1",
      "layer": "layer_9",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_99",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer9_norm2",
      "layer": "layer_9",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_100",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_101",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_102",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer9_attn_drop",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_103",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer9_proj_drop",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_104",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_qkv",
      "layer": "layer_10",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_105",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_proj",
      "layer": "layer_10",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_106",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_fc1",
      "layer": "layer_10",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_107",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_fc2",
      "layer": "layer_10",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_108",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer10_norm1",
      "layer": "layer_10",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_109",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer10_norm2",
      "layer": "layer_10",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_110",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_111",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_112",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer10_attn_drop",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_113",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer10_proj_drop",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_114",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_qkv",
      "layer": "layer_11",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_115",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_proj",
      "layer": "layer_11",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_116",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_fc1",
      "layer": "layer_11",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_117",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_fc2",
      "layer": "layer_11",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_118",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer11_norm1",
      "layer": "layer_11",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_119",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer11_norm2",
      "layer": "layer_11",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_120",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_121",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_122",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer11_attn_drop",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_123",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer11_proj_drop",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_124",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer12_qkv",
      "layer": "layer_12",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_125",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer12_proj",
      "layer": "layer_12",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_126",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer12_fc1",
      "layer": "layer_12",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_127",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer12_fc2",
      "layer": "layer_12",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_128",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer12_norm1",
      "layer": "layer_12",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_129",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer12_norm2",
      "layer": "layer_12",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_130",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer12_attention_softmax",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_131",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer12_activation",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_132",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer12_attn_drop",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_133",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer12_proj_drop",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_134",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer13_qkv",
      "layer": "layer_13",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_135",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer13_proj",
      "layer": "layer_13",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_136",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer13_fc1",
      "layer": "layer_13",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_137",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer13_fc2",
      "layer": "layer_13",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_138",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer13_norm1",
      "layer": "layer_13",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_139",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer13_norm2",
      "layer": "layer_13",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_140",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer13_attention_softmax",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_141",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer13_activation",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_142",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer13_attn_drop",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_143",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer13_proj_drop",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_144",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer14_qkv",
      "layer": "layer_14",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_145",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer14_proj",
      "layer": "layer_14",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_146",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer14_fc1",
      "layer": "layer_14",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_147",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer14_fc2",
      "layer": "layer_14",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_148",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer14_norm1",
      "layer": "layer_14",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_149",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer14_norm2",
      "layer": "layer_14",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_150",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer14_attention_softmax",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_151",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer14_activation",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_152",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer14_attn_drop",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_153",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer14_proj_drop",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_154",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer15_qkv",
      "layer": "layer_15",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_155",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer15_proj",
      "layer": "layer_15",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_156",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer15_fc1",
      "layer": "layer_15",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_157",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer15_fc2",
      "layer": "layer_15",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_158",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer15_norm1",
      "layer": "layer_15",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_159",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer15_norm2",
      "layer": "layer_15",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_160",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer15_attention_softmax",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_161",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer15_activation",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_162",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer15_attn_drop",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_163",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer15_proj_drop",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_164",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer16_qkv",
      "layer": "layer_16",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_165",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer16_proj",
      "layer": "layer_16",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_166",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer16_fc1",
      "layer": "layer_16",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_167",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer16_fc2",
      "layer": "layer_16",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_168",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer16_norm1",
      "layer": "layer_16",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_169",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer16_norm2",
      "layer": "layer_16",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_170",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer16_attention_softmax",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_171",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer16_activation",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_172",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer16_attn_drop",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_173",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer16_proj_drop",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_174",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer17_qkv",
      "layer": "layer_17",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_175",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer17_proj",
      "layer": "layer_17",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_176",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer17_fc1",
      "layer": "layer_17",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_177",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer17_fc2",
      "layer": "layer_17",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_178",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer17_norm1",
      "layer": "layer_17",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_179",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer17_norm2",
      "layer": "layer_17",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_180",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer17_attention_softmax",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_181",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer17_activation",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_182",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer17_attn_drop",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_183",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer17_proj_drop",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_184",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer18_qkv",
      "layer": "layer_18",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_185",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer18_proj",
      "layer": "layer_18",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_186",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer18_fc1",
      "layer": "layer_18",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_187",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer18_fc2",
      "layer": "layer_18",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_188",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer18_norm1",
      "layer": "layer_18",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_189",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer18_norm2",
      "layer": "layer_18",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_190",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer18_attention_softmax",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_191",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer18_activation",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_192",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer18_attn_drop",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_193",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer18_proj_drop",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_194",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer19_qkv",
      "layer": "layer_19",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_195",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer19_proj",
      "layer": "layer_19",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_196",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer19_fc1",
      "layer": "layer_19",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_197",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer19_fc2",
      "layer": "layer_19",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_198",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer19_norm1",
      "layer": "layer_19",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_199",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer19_norm2",
      "layer": "layer_19",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_200",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer19_attention_softmax",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_201",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer19_activation",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_202",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer19_attn_drop",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_203",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer19_proj_drop",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_204",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer20_qkv",
      "layer": "layer_20",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_205",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer20_proj",
      "layer": "layer_20",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_206",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer20_fc1",
      "layer": "layer_20",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_207",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer20_fc2",
      "layer": "layer_20",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_208",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer20_norm1",
      "layer": "layer_20",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_209",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer20_norm2",
      "layer": "layer_20",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_210",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer20_attention_softmax",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_211",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer20_activation",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_212",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer20_attn_drop",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_213",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer20_proj_drop",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_214",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer21_qkv",
      "layer": "layer_21",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_215",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer21_proj",
      "layer": "layer_21",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_216",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer21_fc1",
      "layer": "layer_21",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_217",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer21_fc2",
      "layer": "layer_21",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_218",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer21_norm1",
      "layer": "layer_21",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_219",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer21_norm2",
      "layer": "layer_21",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_220",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer21_attention_softmax",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_221",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer21_activation",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_222",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer21_attn_drop",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_223",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer21_proj_drop",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_224",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer22_qkv",
      "layer": "layer_22",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_225",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer22_proj",
      "layer": "layer_22",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_226",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer22_fc1",
      "layer": "layer_22",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_227",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer22_fc2",
      "layer": "layer_22",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_228",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer22_norm1",
      "layer": "layer_22",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_229",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer22_norm2",
      "layer": "layer_22",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_230",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer22_attention_softmax",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_231",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer22_activation",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_232",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer22_attn_drop",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_233",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer22_proj_drop",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_234",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer23_qkv",
      "layer": "layer_23",
      "parameters": 3145728,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_235",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer23_proj",
      "layer": "layer_23",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_236",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer23_fc1",
      "layer": "layer_23",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_237",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer23_fc2",
      "layer": "layer_23",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Swin_Base_op_238",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer23_norm1",
      "layer": "layer_23",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_239",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer23_norm2",
      "layer": "layer_23",
      "parameters": 2048,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_240",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer23_attention_softmax",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Swin_Base_op_241",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer23_activation",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 4096]",
      "output_shape": "[batch, seq, 4096]"
    },
    {
      "op_id": "Swin_Base_op_242",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer23_attn_drop",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "Swin_Base_op_243",
      "model_name": "Swin-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer23_proj_drop",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "DINOv2_Base_op_1",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "patch_embed",
      "layer": "global",
      "parameters": 2073600000000,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "DINOv2_Base_op_2",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "norm",
      "layer": "global",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_3",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "head",
      "layer": "global",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_4",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_qkv",
      "layer": "layer_0",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_5",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_proj",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_6",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_fc1",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_7",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_fc2",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_8",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer0_norm1",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_9",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer0_norm2",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_10",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DINOv2_Base_op_11",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DINOv2_Base_op_12",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer0_attn_drop",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_13",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer0_proj_drop",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_14",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_qkv",
      "layer": "layer_1",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_15",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_proj",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_16",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_fc1",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_17",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_fc2",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_18",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer1_norm1",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_19",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer1_norm2",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_20",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DINOv2_Base_op_21",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DINOv2_Base_op_22",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer1_attn_drop",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_23",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer1_proj_drop",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_24",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_qkv",
      "layer": "layer_2",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_25",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_proj",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_26",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_fc1",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_27",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_fc2",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_28",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer2_norm1",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_29",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer2_norm2",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_30",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DINOv2_Base_op_31",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DINOv2_Base_op_32",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer2_attn_drop",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_33",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer2_proj_drop",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_34",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_qkv",
      "layer": "layer_3",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_35",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_proj",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_36",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_fc1",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_37",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_fc2",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_38",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer3_norm1",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_39",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer3_norm2",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_40",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DINOv2_Base_op_41",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DINOv2_Base_op_42",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer3_attn_drop",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_43",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer3_proj_drop",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_44",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_qkv",
      "layer": "layer_4",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_45",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_proj",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_46",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_fc1",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_47",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_fc2",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_48",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer4_norm1",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_49",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer4_norm2",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_50",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DINOv2_Base_op_51",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DINOv2_Base_op_52",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer4_attn_drop",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_53",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer4_proj_drop",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_54",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_qkv",
      "layer": "layer_5",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_55",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_proj",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_56",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_fc1",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_57",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_fc2",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_58",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer5_norm1",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_59",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer5_norm2",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_60",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DINOv2_Base_op_61",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DINOv2_Base_op_62",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer5_attn_drop",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_63",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer5_proj_drop",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_64",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_qkv",
      "layer": "layer_6",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_65",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_proj",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_66",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_fc1",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_67",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_fc2",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_68",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer6_norm1",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_69",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer6_norm2",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_70",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DINOv2_Base_op_71",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DINOv2_Base_op_72",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer6_attn_drop",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_73",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer6_proj_drop",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_74",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_qkv",
      "layer": "layer_7",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_75",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_proj",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_76",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_fc1",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_77",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_fc2",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_78",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer7_norm1",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_79",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer7_norm2",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_80",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DINOv2_Base_op_81",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DINOv2_Base_op_82",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer7_attn_drop",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_83",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer7_proj_drop",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_84",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_qkv",
      "layer": "layer_8",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_85",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_proj",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_86",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_fc1",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_87",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_fc2",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_88",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer8_norm1",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_89",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer8_norm2",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_90",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DINOv2_Base_op_91",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DINOv2_Base_op_92",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer8_attn_drop",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_93",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer8_proj_drop",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_94",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_qkv",
      "layer": "layer_9",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_95",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_proj",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_96",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_fc1",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_97",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_fc2",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_98",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer9_norm1",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_99",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer9_norm2",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_100",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DINOv2_Base_op_101",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DINOv2_Base_op_102",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer9_attn_drop",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_103",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer9_proj_drop",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_104",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_qkv",
      "layer": "layer_10",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_105",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_proj",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_106",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_fc1",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_107",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_fc2",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_108",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer10_norm1",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_109",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer10_norm2",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_110",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DINOv2_Base_op_111",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DINOv2_Base_op_112",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer10_attn_drop",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_113",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer10_proj_drop",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_114",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_qkv",
      "layer": "layer_11",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_115",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_proj",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_116",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_fc1",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_117",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_fc2",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DINOv2_Base_op_118",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer11_norm1",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_119",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer11_norm2",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_120",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DINOv2_Base_op_121",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DINOv2_Base_op_122",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer11_attn_drop",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DINOv2_Base_op_123",
      "model_name": "DINOv2-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer11_proj_drop",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "MobileNet_V2_op_1",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "conv_stem",
      "layer": "global",
      "parameters": 864,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_2",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "bn1",
      "layer": "global",
      "parameters": 128,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_3",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "conv_head",
      "layer": "global",
      "parameters": 409600,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_4",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "bn2",
      "layer": "global",
      "parameters": 5120,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_5",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "AdaptiveAvgPool2d",
      "name": "avgpool",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, 1, 1]"
    },
    {
      "op_id": "MobileNet_V2_op_6",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Linear",
      "name": "classifier",
      "layer": "global",
      "parameters": 1280000,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "MobileNet_V2_op_7",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "relu6",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_8",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block1_expand_conv",
      "layer": "stage1_block1",
      "parameters": 1536,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_9",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block1_depthwise_conv",
      "layer": "stage1_block1",
      "parameters": 864,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_10",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block1_project_conv",
      "layer": "stage1_block1",
      "parameters": 2304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_11",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block1_bn1",
      "layer": "stage1_block1",
      "parameters": 384,
      "input_shape": "[batch, 16, H, W]",
      "output_shape": "[batch, 16, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_12",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block1_bn2",
      "layer": "stage1_block1",
      "parameters": 384,
      "input_shape": "[batch, 16, H, W]",
      "output_shape": "[batch, 16, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_13",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block1_bn3",
      "layer": "stage1_block1",
      "parameters": 96,
      "input_shape": "[batch, 16, H, W]",
      "output_shape": "[batch, 16, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_14",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage1_block1_relu6",
      "layer": "stage1_block1",
      "parameters": 0,
      "input_shape": "[batch, 16, H, W]",
      "output_shape": "[batch, 16, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_15",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block1_expand_conv",
      "layer": "stage2_block1",
      "parameters": 3456,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_16",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block1_depthwise_conv",
      "layer": "stage2_block1",
      "parameters": 1296,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_17",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block1_project_conv",
      "layer": "stage2_block1",
      "parameters": 4608,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_18",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block1_bn1",
      "layer": "stage2_block1",
      "parameters": 576,
      "input_shape": "[batch, 24, H, W]",
      "output_shape": "[batch, 24, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_19",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block1_bn2",
      "layer": "stage2_block1",
      "parameters": 576,
      "input_shape": "[batch, 24, H, W]",
      "output_shape": "[batch, 24, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_20",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block1_bn3",
      "layer": "stage2_block1",
      "parameters": 128,
      "input_shape": "[batch, 24, H, W]",
      "output_shape": "[batch, 24, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_21",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage2_block1_relu6",
      "layer": "stage2_block1",
      "parameters": 0,
      "input_shape": "[batch, 24, H, W]",
      "output_shape": "[batch, 24, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_22",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block2_expand_conv",
      "layer": "stage2_block2",
      "parameters": 3456,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_23",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block2_depthwise_conv",
      "layer": "stage2_block2",
      "parameters": 1296,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_24",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block2_project_conv",
      "layer": "stage2_block2",
      "parameters": 4608,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_25",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block2_bn1",
      "layer": "stage2_block2",
      "parameters": 576,
      "input_shape": "[batch, 24, H, W]",
      "output_shape": "[batch, 24, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_26",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block2_bn2",
      "layer": "stage2_block2",
      "parameters": 576,
      "input_shape": "[batch, 24, H, W]",
      "output_shape": "[batch, 24, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_27",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block2_bn3",
      "layer": "stage2_block2",
      "parameters": 128,
      "input_shape": "[batch, 24, H, W]",
      "output_shape": "[batch, 24, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_28",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage2_block2_relu6",
      "layer": "stage2_block2",
      "parameters": 0,
      "input_shape": "[batch, 24, H, W]",
      "output_shape": "[batch, 24, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_29",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block1_expand_conv",
      "layer": "stage3_block1",
      "parameters": 6144,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_30",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block1_depthwise_conv",
      "layer": "stage3_block1",
      "parameters": 1728,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_31",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block1_project_conv",
      "layer": "stage3_block1",
      "parameters": 12288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_32",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block1_bn1",
      "layer": "stage3_block1",
      "parameters": 768,
      "input_shape": "[batch, 32, H, W]",
      "output_shape": "[batch, 32, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_33",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block1_bn2",
      "layer": "stage3_block1",
      "parameters": 768,
      "input_shape": "[batch, 32, H, W]",
      "output_shape": "[batch, 32, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_34",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block1_bn3",
      "layer": "stage3_block1",
      "parameters": 256,
      "input_shape": "[batch, 32, H, W]",
      "output_shape": "[batch, 32, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_35",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage3_block1_relu6",
      "layer": "stage3_block1",
      "parameters": 0,
      "input_shape": "[batch, 32, H, W]",
      "output_shape": "[batch, 32, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_36",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block2_expand_conv",
      "layer": "stage3_block2",
      "parameters": 6144,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_37",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block2_depthwise_conv",
      "layer": "stage3_block2",
      "parameters": 1728,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_38",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block2_project_conv",
      "layer": "stage3_block2",
      "parameters": 12288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_39",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block2_bn1",
      "layer": "stage3_block2",
      "parameters": 768,
      "input_shape": "[batch, 32, H, W]",
      "output_shape": "[batch, 32, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_40",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block2_bn2",
      "layer": "stage3_block2",
      "parameters": 768,
      "input_shape": "[batch, 32, H, W]",
      "output_shape": "[batch, 32, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_41",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block2_bn3",
      "layer": "stage3_block2",
      "parameters": 256,
      "input_shape": "[batch, 32, H, W]",
      "output_shape": "[batch, 32, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_42",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage3_block2_relu6",
      "layer": "stage3_block2",
      "parameters": 0,
      "input_shape": "[batch, 32, H, W]",
      "output_shape": "[batch, 32, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_43",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block3_expand_conv",
      "layer": "stage3_block3",
      "parameters": 6144,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_44",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block3_depthwise_conv",
      "layer": "stage3_block3",
      "parameters": 1728,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_45",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block3_project_conv",
      "layer": "stage3_block3",
      "parameters": 12288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_46",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block3_bn1",
      "layer": "stage3_block3",
      "parameters": 768,
      "input_shape": "[batch, 32, H, W]",
      "output_shape": "[batch, 32, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_47",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block3_bn2",
      "layer": "stage3_block3",
      "parameters": 768,
      "input_shape": "[batch, 32, H, W]",
      "output_shape": "[batch, 32, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_48",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block3_bn3",
      "layer": "stage3_block3",
      "parameters": 256,
      "input_shape": "[batch, 32, H, W]",
      "output_shape": "[batch, 32, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_49",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage3_block3_relu6",
      "layer": "stage3_block3",
      "parameters": 0,
      "input_shape": "[batch, 32, H, W]",
      "output_shape": "[batch, 32, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_50",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block1_expand_conv",
      "layer": "stage4_block1",
      "parameters": 24576,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_51",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block1_depthwise_conv",
      "layer": "stage4_block1",
      "parameters": 3456,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_52",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block1_project_conv",
      "layer": "stage4_block1",
      "parameters": 36864,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_53",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block1_bn1",
      "layer": "stage4_block1",
      "parameters": 1536,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_54",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block1_bn2",
      "layer": "stage4_block1",
      "parameters": 1536,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_55",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block1_bn3",
      "layer": "stage4_block1",
      "parameters": 384,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_56",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage4_block1_relu6",
      "layer": "stage4_block1",
      "parameters": 0,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_57",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block2_expand_conv",
      "layer": "stage4_block2",
      "parameters": 24576,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_58",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block2_depthwise_conv",
      "layer": "stage4_block2",
      "parameters": 3456,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_59",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block2_project_conv",
      "layer": "stage4_block2",
      "parameters": 36864,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_60",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block2_bn1",
      "layer": "stage4_block2",
      "parameters": 1536,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_61",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block2_bn2",
      "layer": "stage4_block2",
      "parameters": 1536,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_62",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block2_bn3",
      "layer": "stage4_block2",
      "parameters": 384,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_63",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage4_block2_relu6",
      "layer": "stage4_block2",
      "parameters": 0,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_64",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block3_expand_conv",
      "layer": "stage4_block3",
      "parameters": 24576,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_65",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block3_depthwise_conv",
      "layer": "stage4_block3",
      "parameters": 3456,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_66",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block3_project_conv",
      "layer": "stage4_block3",
      "parameters": 36864,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_67",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block3_bn1",
      "layer": "stage4_block3",
      "parameters": 1536,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_68",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block3_bn2",
      "layer": "stage4_block3",
      "parameters": 1536,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_69",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block3_bn3",
      "layer": "stage4_block3",
      "parameters": 384,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_70",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage4_block3_relu6",
      "layer": "stage4_block3",
      "parameters": 0,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_71",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block4_expand_conv",
      "layer": "stage4_block4",
      "parameters": 24576,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_72",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block4_depthwise_conv",
      "layer": "stage4_block4",
      "parameters": 3456,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_73",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block4_project_conv",
      "layer": "stage4_block4",
      "parameters": 36864,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_74",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block4_bn1",
      "layer": "stage4_block4",
      "parameters": 1536,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_75",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block4_bn2",
      "layer": "stage4_block4",
      "parameters": 1536,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_76",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block4_bn3",
      "layer": "stage4_block4",
      "parameters": 384,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_77",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage4_block4_relu6",
      "layer": "stage4_block4",
      "parameters": 0,
      "input_shape": "[batch, 64, H, W]",
      "output_shape": "[batch, 64, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_78",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage5_block1_expand_conv",
      "layer": "stage5_block1",
      "parameters": 55296,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_79",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage5_block1_depthwise_conv",
      "layer": "stage5_block1",
      "parameters": 5184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_80",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage5_block1_project_conv",
      "layer": "stage5_block1",
      "parameters": 92160,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_81",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage5_block1_bn1",
      "layer": "stage5_block1",
      "parameters": 2304,
      "input_shape": "[batch, 96, H, W]",
      "output_shape": "[batch, 96, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_82",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage5_block1_bn2",
      "layer": "stage5_block1",
      "parameters": 2304,
      "input_shape": "[batch, 96, H, W]",
      "output_shape": "[batch, 96, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_83",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage5_block1_bn3",
      "layer": "stage5_block1",
      "parameters": 640,
      "input_shape": "[batch, 96, H, W]",
      "output_shape": "[batch, 96, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_84",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage5_block1_relu6",
      "layer": "stage5_block1",
      "parameters": 0,
      "input_shape": "[batch, 96, H, W]",
      "output_shape": "[batch, 96, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_85",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage5_block2_expand_conv",
      "layer": "stage5_block2",
      "parameters": 55296,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_86",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage5_block2_depthwise_conv",
      "layer": "stage5_block2",
      "parameters": 5184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_87",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage5_block2_project_conv",
      "layer": "stage5_block2",
      "parameters": 92160,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_88",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage5_block2_bn1",
      "layer": "stage5_block2",
      "parameters": 2304,
      "input_shape": "[batch, 96, H, W]",
      "output_shape": "[batch, 96, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_89",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage5_block2_bn2",
      "layer": "stage5_block2",
      "parameters": 2304,
      "input_shape": "[batch, 96, H, W]",
      "output_shape": "[batch, 96, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_90",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage5_block2_bn3",
      "layer": "stage5_block2",
      "parameters": 640,
      "input_shape": "[batch, 96, H, W]",
      "output_shape": "[batch, 96, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_91",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage5_block2_relu6",
      "layer": "stage5_block2",
      "parameters": 0,
      "input_shape": "[batch, 96, H, W]",
      "output_shape": "[batch, 96, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_92",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage5_block3_expand_conv",
      "layer": "stage5_block3",
      "parameters": 55296,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_93",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage5_block3_depthwise_conv",
      "layer": "stage5_block3",
      "parameters": 5184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_94",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage5_block3_project_conv",
      "layer": "stage5_block3",
      "parameters": 92160,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_95",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage5_block3_bn1",
      "layer": "stage5_block3",
      "parameters": 2304,
      "input_shape": "[batch, 96, H, W]",
      "output_shape": "[batch, 96, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_96",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage5_block3_bn2",
      "layer": "stage5_block3",
      "parameters": 2304,
      "input_shape": "[batch, 96, H, W]",
      "output_shape": "[batch, 96, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_97",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage5_block3_bn3",
      "layer": "stage5_block3",
      "parameters": 640,
      "input_shape": "[batch, 96, H, W]",
      "output_shape": "[batch, 96, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_98",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage5_block3_relu6",
      "layer": "stage5_block3",
      "parameters": 0,
      "input_shape": "[batch, 96, H, W]",
      "output_shape": "[batch, 96, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_99",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block1_expand_conv",
      "layer": "stage6_block1",
      "parameters": 153600,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_100",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block1_depthwise_conv",
      "layer": "stage6_block1",
      "parameters": 8640,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_101",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block1_project_conv",
      "layer": "stage6_block1",
      "parameters": 307200,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_102",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block1_bn1",
      "layer": "stage6_block1",
      "parameters": 3840,
      "input_shape": "[batch, 160, H, W]",
      "output_shape": "[batch, 160, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_103",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block1_bn2",
      "layer": "stage6_block1",
      "parameters": 3840,
      "input_shape": "[batch, 160, H, W]",
      "output_shape": "[batch, 160, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_104",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block1_bn3",
      "layer": "stage6_block1",
      "parameters": 1280,
      "input_shape": "[batch, 160, H, W]",
      "output_shape": "[batch, 160, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_105",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage6_block1_relu6",
      "layer": "stage6_block1",
      "parameters": 0,
      "input_shape": "[batch, 160, H, W]",
      "output_shape": "[batch, 160, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_106",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block2_expand_conv",
      "layer": "stage6_block2",
      "parameters": 153600,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_107",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block2_depthwise_conv",
      "layer": "stage6_block2",
      "parameters": 8640,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_108",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block2_project_conv",
      "layer": "stage6_block2",
      "parameters": 307200,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_109",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block2_bn1",
      "layer": "stage6_block2",
      "parameters": 3840,
      "input_shape": "[batch, 160, H, W]",
      "output_shape": "[batch, 160, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_110",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block2_bn2",
      "layer": "stage6_block2",
      "parameters": 3840,
      "input_shape": "[batch, 160, H, W]",
      "output_shape": "[batch, 160, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_111",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block2_bn3",
      "layer": "stage6_block2",
      "parameters": 1280,
      "input_shape": "[batch, 160, H, W]",
      "output_shape": "[batch, 160, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_112",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage6_block2_relu6",
      "layer": "stage6_block2",
      "parameters": 0,
      "input_shape": "[batch, 160, H, W]",
      "output_shape": "[batch, 160, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_113",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block3_expand_conv",
      "layer": "stage6_block3",
      "parameters": 153600,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_114",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block3_depthwise_conv",
      "layer": "stage6_block3",
      "parameters": 8640,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_115",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block3_project_conv",
      "layer": "stage6_block3",
      "parameters": 307200,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_116",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block3_bn1",
      "layer": "stage6_block3",
      "parameters": 3840,
      "input_shape": "[batch, 160, H, W]",
      "output_shape": "[batch, 160, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_117",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block3_bn2",
      "layer": "stage6_block3",
      "parameters": 3840,
      "input_shape": "[batch, 160, H, W]",
      "output_shape": "[batch, 160, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_118",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block3_bn3",
      "layer": "stage6_block3",
      "parameters": 1280,
      "input_shape": "[batch, 160, H, W]",
      "output_shape": "[batch, 160, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_119",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage6_block3_relu6",
      "layer": "stage6_block3",
      "parameters": 0,
      "input_shape": "[batch, 160, H, W]",
      "output_shape": "[batch, 160, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_120",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage7_block1_expand_conv",
      "layer": "stage7_block1",
      "parameters": 614400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_121",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage7_block1_depthwise_conv",
      "layer": "stage7_block1",
      "parameters": 17280,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_122",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage7_block1_project_conv",
      "layer": "stage7_block1",
      "parameters": 614400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "MobileNet_V2_op_123",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage7_block1_bn1",
      "layer": "stage7_block1",
      "parameters": 7680,
      "input_shape": "[batch, 320, H, W]",
      "output_shape": "[batch, 320, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_124",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage7_block1_bn2",
      "layer": "stage7_block1",
      "parameters": 7680,
      "input_shape": "[batch, 320, H, W]",
      "output_shape": "[batch, 320, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_125",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage7_block1_bn3",
      "layer": "stage7_block1",
      "parameters": 1280,
      "input_shape": "[batch, 320, H, W]",
      "output_shape": "[batch, 320, H, W]"
    },
    {
      "op_id": "MobileNet_V2_op_126",
      "model_name": "MobileNet-V2",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage7_block1_relu6",
      "layer": "stage7_block1",
      "parameters": 0,
      "input_shape": "[batch, 320, H, W]",
      "output_shape": "[batch, 320, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_1",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "conv_stem",
      "layer": "global",
      "parameters": 864,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_2",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "bn1",
      "layer": "global",
      "parameters": 128,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_3",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "conv_head",
      "layer": "global",
      "parameters": 409600,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_4",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "bn2",
      "layer": "global",
      "parameters": 5120,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_5",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "AdaptiveAvgPool2d",
      "name": "avgpool",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, 1, 1]"
    },
    {
      "op_id": "EfficientNet_B0_op_6",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Linear",
      "name": "classifier",
      "layer": "global",
      "parameters": 1280000,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "EfficientNet_B0_op_7",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "relu6",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_8",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block1_expand_conv",
      "layer": "stage1_block1",
      "parameters": 1536,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_9",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block1_depthwise_conv",
      "layer": "stage1_block1",
      "parameters": 864,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_10",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block1_project_conv",
      "layer": "stage1_block1",
      "parameters": 2304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_11",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block1_bn1",
      "layer": "stage1_block1",
      "parameters": 384,
      "input_shape": "[batch, 16, H, W]",
      "output_shape": "[batch, 16, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_12",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block1_bn2",
      "layer": "stage1_block1",
      "parameters": 384,
      "input_shape": "[batch, 16, H, W]",
      "output_shape": "[batch, 16, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_13",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block1_bn3",
      "layer": "stage1_block1",
      "parameters": 96,
      "input_shape": "[batch, 16, H, W]",
      "output_shape": "[batch, 16, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_14",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage1_block1_relu6",
      "layer": "stage1_block1",
      "parameters": 0,
      "input_shape": "[batch, 16, H, W]",
      "output_shape": "[batch, 16, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_15",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block1_expand_conv",
      "layer": "stage2_block1",
      "parameters": 3456,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_16",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block1_depthwise_conv",
      "layer": "stage2_block1",
      "parameters": 1296,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_17",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block1_project_conv",
      "layer": "stage2_block1",
      "parameters": 5760,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_18",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block1_bn1",
      "layer": "stage2_block1",
      "parameters": 576,
      "input_shape": "[batch, 24, H, W]",
      "output_shape": "[batch, 24, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_19",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block1_bn2",
      "layer": "stage2_block1",
      "parameters": 576,
      "input_shape": "[batch, 24, H, W]",
      "output_shape": "[batch, 24, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_20",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block1_bn3",
      "layer": "stage2_block1",
      "parameters": 160,
      "input_shape": "[batch, 24, H, W]",
      "output_shape": "[batch, 24, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_21",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage2_block1_relu6",
      "layer": "stage2_block1",
      "parameters": 0,
      "input_shape": "[batch, 24, H, W]",
      "output_shape": "[batch, 24, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_22",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block2_expand_conv",
      "layer": "stage2_block2",
      "parameters": 3456,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_23",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block2_depthwise_conv",
      "layer": "stage2_block2",
      "parameters": 1296,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_24",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block2_project_conv",
      "layer": "stage2_block2",
      "parameters": 5760,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_25",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block2_bn1",
      "layer": "stage2_block2",
      "parameters": 576,
      "input_shape": "[batch, 24, H, W]",
      "output_shape": "[batch, 24, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_26",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block2_bn2",
      "layer": "stage2_block2",
      "parameters": 576,
      "input_shape": "[batch, 24, H, W]",
      "output_shape": "[batch, 24, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_27",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block2_bn3",
      "layer": "stage2_block2",
      "parameters": 160,
      "input_shape": "[batch, 24, H, W]",
      "output_shape": "[batch, 24, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_28",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage2_block2_relu6",
      "layer": "stage2_block2",
      "parameters": 0,
      "input_shape": "[batch, 24, H, W]",
      "output_shape": "[batch, 24, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_29",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block1_expand_conv",
      "layer": "stage3_block1",
      "parameters": 9600,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_30",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block1_depthwise_conv",
      "layer": "stage3_block1",
      "parameters": 2160,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_31",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block1_project_conv",
      "layer": "stage3_block1",
      "parameters": 19200,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_32",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block1_bn1",
      "layer": "stage3_block1",
      "parameters": 960,
      "input_shape": "[batch, 40, H, W]",
      "output_shape": "[batch, 40, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_33",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block1_bn2",
      "layer": "stage3_block1",
      "parameters": 960,
      "input_shape": "[batch, 40, H, W]",
      "output_shape": "[batch, 40, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_34",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block1_bn3",
      "layer": "stage3_block1",
      "parameters": 320,
      "input_shape": "[batch, 40, H, W]",
      "output_shape": "[batch, 40, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_35",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage3_block1_relu6",
      "layer": "stage3_block1",
      "parameters": 0,
      "input_shape": "[batch, 40, H, W]",
      "output_shape": "[batch, 40, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_36",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block2_expand_conv",
      "layer": "stage3_block2",
      "parameters": 9600,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_37",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block2_depthwise_conv",
      "layer": "stage3_block2",
      "parameters": 2160,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_38",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block2_project_conv",
      "layer": "stage3_block2",
      "parameters": 19200,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_39",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block2_bn1",
      "layer": "stage3_block2",
      "parameters": 960,
      "input_shape": "[batch, 40, H, W]",
      "output_shape": "[batch, 40, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_40",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block2_bn2",
      "layer": "stage3_block2",
      "parameters": 960,
      "input_shape": "[batch, 40, H, W]",
      "output_shape": "[batch, 40, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_41",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block2_bn3",
      "layer": "stage3_block2",
      "parameters": 320,
      "input_shape": "[batch, 40, H, W]",
      "output_shape": "[batch, 40, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_42",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage3_block2_relu6",
      "layer": "stage3_block2",
      "parameters": 0,
      "input_shape": "[batch, 40, H, W]",
      "output_shape": "[batch, 40, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_43",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block1_expand_conv",
      "layer": "stage4_block1",
      "parameters": 38400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_44",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block1_depthwise_conv",
      "layer": "stage4_block1",
      "parameters": 4320,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_45",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block1_project_conv",
      "layer": "stage4_block1",
      "parameters": 53760,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_46",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block1_bn1",
      "layer": "stage4_block1",
      "parameters": 1920,
      "input_shape": "[batch, 80, H, W]",
      "output_shape": "[batch, 80, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_47",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block1_bn2",
      "layer": "stage4_block1",
      "parameters": 1920,
      "input_shape": "[batch, 80, H, W]",
      "output_shape": "[batch, 80, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_48",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block1_bn3",
      "layer": "stage4_block1",
      "parameters": 448,
      "input_shape": "[batch, 80, H, W]",
      "output_shape": "[batch, 80, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_49",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage4_block1_relu6",
      "layer": "stage4_block1",
      "parameters": 0,
      "input_shape": "[batch, 80, H, W]",
      "output_shape": "[batch, 80, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_50",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block2_expand_conv",
      "layer": "stage4_block2",
      "parameters": 38400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_51",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block2_depthwise_conv",
      "layer": "stage4_block2",
      "parameters": 4320,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_52",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block2_project_conv",
      "layer": "stage4_block2",
      "parameters": 53760,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_53",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block2_bn1",
      "layer": "stage4_block2",
      "parameters": 1920,
      "input_shape": "[batch, 80, H, W]",
      "output_shape": "[batch, 80, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_54",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block2_bn2",
      "layer": "stage4_block2",
      "parameters": 1920,
      "input_shape": "[batch, 80, H, W]",
      "output_shape": "[batch, 80, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_55",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block2_bn3",
      "layer": "stage4_block2",
      "parameters": 448,
      "input_shape": "[batch, 80, H, W]",
      "output_shape": "[batch, 80, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_56",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage4_block2_relu6",
      "layer": "stage4_block2",
      "parameters": 0,
      "input_shape": "[batch, 80, H, W]",
      "output_shape": "[batch, 80, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_57",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block3_expand_conv",
      "layer": "stage4_block3",
      "parameters": 38400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_58",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block3_depthwise_conv",
      "layer": "stage4_block3",
      "parameters": 4320,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_59",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block3_project_conv",
      "layer": "stage4_block3",
      "parameters": 53760,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_60",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block3_bn1",
      "layer": "stage4_block3",
      "parameters": 1920,
      "input_shape": "[batch, 80, H, W]",
      "output_shape": "[batch, 80, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_61",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block3_bn2",
      "layer": "stage4_block3",
      "parameters": 1920,
      "input_shape": "[batch, 80, H, W]",
      "output_shape": "[batch, 80, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_62",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block3_bn3",
      "layer": "stage4_block3",
      "parameters": 448,
      "input_shape": "[batch, 80, H, W]",
      "output_shape": "[batch, 80, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_63",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage4_block3_relu6",
      "layer": "stage4_block3",
      "parameters": 0,
      "input_shape": "[batch, 80, H, W]",
      "output_shape": "[batch, 80, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_64",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage5_block1_expand_conv",
      "layer": "stage5_block1",
      "parameters": 75264,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_65",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage5_block1_depthwise_conv",
      "layer": "stage5_block1",
      "parameters": 6048,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_66",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage5_block1_project_conv",
      "layer": "stage5_block1",
      "parameters": 129024,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_67",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage5_block1_bn1",
      "layer": "stage5_block1",
      "parameters": 2688,
      "input_shape": "[batch, 112, H, W]",
      "output_shape": "[batch, 112, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_68",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage5_block1_bn2",
      "layer": "stage5_block1",
      "parameters": 2688,
      "input_shape": "[batch, 112, H, W]",
      "output_shape": "[batch, 112, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_69",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage5_block1_bn3",
      "layer": "stage5_block1",
      "parameters": 768,
      "input_shape": "[batch, 112, H, W]",
      "output_shape": "[batch, 112, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_70",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage5_block1_relu6",
      "layer": "stage5_block1",
      "parameters": 0,
      "input_shape": "[batch, 112, H, W]",
      "output_shape": "[batch, 112, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_71",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage5_block2_expand_conv",
      "layer": "stage5_block2",
      "parameters": 75264,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_72",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage5_block2_depthwise_conv",
      "layer": "stage5_block2",
      "parameters": 6048,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_73",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage5_block2_project_conv",
      "layer": "stage5_block2",
      "parameters": 129024,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_74",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage5_block2_bn1",
      "layer": "stage5_block2",
      "parameters": 2688,
      "input_shape": "[batch, 112, H, W]",
      "output_shape": "[batch, 112, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_75",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage5_block2_bn2",
      "layer": "stage5_block2",
      "parameters": 2688,
      "input_shape": "[batch, 112, H, W]",
      "output_shape": "[batch, 112, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_76",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage5_block2_bn3",
      "layer": "stage5_block2",
      "parameters": 768,
      "input_shape": "[batch, 112, H, W]",
      "output_shape": "[batch, 112, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_77",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage5_block2_relu6",
      "layer": "stage5_block2",
      "parameters": 0,
      "input_shape": "[batch, 112, H, W]",
      "output_shape": "[batch, 112, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_78",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage5_block3_expand_conv",
      "layer": "stage5_block3",
      "parameters": 75264,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_79",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage5_block3_depthwise_conv",
      "layer": "stage5_block3",
      "parameters": 6048,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_80",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage5_block3_project_conv",
      "layer": "stage5_block3",
      "parameters": 129024,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_81",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage5_block3_bn1",
      "layer": "stage5_block3",
      "parameters": 2688,
      "input_shape": "[batch, 112, H, W]",
      "output_shape": "[batch, 112, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_82",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage5_block3_bn2",
      "layer": "stage5_block3",
      "parameters": 2688,
      "input_shape": "[batch, 112, H, W]",
      "output_shape": "[batch, 112, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_83",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage5_block3_bn3",
      "layer": "stage5_block3",
      "parameters": 768,
      "input_shape": "[batch, 112, H, W]",
      "output_shape": "[batch, 112, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_84",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage5_block3_relu6",
      "layer": "stage5_block3",
      "parameters": 0,
      "input_shape": "[batch, 112, H, W]",
      "output_shape": "[batch, 112, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_85",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block1_expand_conv",
      "layer": "stage6_block1",
      "parameters": 221184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_86",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block1_depthwise_conv",
      "layer": "stage6_block1",
      "parameters": 10368,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_87",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block1_project_conv",
      "layer": "stage6_block1",
      "parameters": 368640,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_88",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block1_bn1",
      "layer": "stage6_block1",
      "parameters": 4608,
      "input_shape": "[batch, 192, H, W]",
      "output_shape": "[batch, 192, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_89",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block1_bn2",
      "layer": "stage6_block1",
      "parameters": 4608,
      "input_shape": "[batch, 192, H, W]",
      "output_shape": "[batch, 192, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_90",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block1_bn3",
      "layer": "stage6_block1",
      "parameters": 1280,
      "input_shape": "[batch, 192, H, W]",
      "output_shape": "[batch, 192, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_91",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage6_block1_relu6",
      "layer": "stage6_block1",
      "parameters": 0,
      "input_shape": "[batch, 192, H, W]",
      "output_shape": "[batch, 192, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_92",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block2_expand_conv",
      "layer": "stage6_block2",
      "parameters": 221184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_93",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block2_depthwise_conv",
      "layer": "stage6_block2",
      "parameters": 10368,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_94",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block2_project_conv",
      "layer": "stage6_block2",
      "parameters": 368640,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_95",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block2_bn1",
      "layer": "stage6_block2",
      "parameters": 4608,
      "input_shape": "[batch, 192, H, W]",
      "output_shape": "[batch, 192, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_96",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block2_bn2",
      "layer": "stage6_block2",
      "parameters": 4608,
      "input_shape": "[batch, 192, H, W]",
      "output_shape": "[batch, 192, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_97",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block2_bn3",
      "layer": "stage6_block2",
      "parameters": 1280,
      "input_shape": "[batch, 192, H, W]",
      "output_shape": "[batch, 192, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_98",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage6_block2_relu6",
      "layer": "stage6_block2",
      "parameters": 0,
      "input_shape": "[batch, 192, H, W]",
      "output_shape": "[batch, 192, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_99",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block3_expand_conv",
      "layer": "stage6_block3",
      "parameters": 221184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_100",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block3_depthwise_conv",
      "layer": "stage6_block3",
      "parameters": 10368,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_101",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block3_project_conv",
      "layer": "stage6_block3",
      "parameters": 368640,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_102",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block3_bn1",
      "layer": "stage6_block3",
      "parameters": 4608,
      "input_shape": "[batch, 192, H, W]",
      "output_shape": "[batch, 192, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_103",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block3_bn2",
      "layer": "stage6_block3",
      "parameters": 4608,
      "input_shape": "[batch, 192, H, W]",
      "output_shape": "[batch, 192, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_104",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block3_bn3",
      "layer": "stage6_block3",
      "parameters": 1280,
      "input_shape": "[batch, 192, H, W]",
      "output_shape": "[batch, 192, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_105",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage6_block3_relu6",
      "layer": "stage6_block3",
      "parameters": 0,
      "input_shape": "[batch, 192, H, W]",
      "output_shape": "[batch, 192, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_106",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block4_expand_conv",
      "layer": "stage6_block4",
      "parameters": 221184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_107",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block4_depthwise_conv",
      "layer": "stage6_block4",
      "parameters": 10368,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_108",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage6_block4_project_conv",
      "layer": "stage6_block4",
      "parameters": 368640,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_109",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block4_bn1",
      "layer": "stage6_block4",
      "parameters": 4608,
      "input_shape": "[batch, 192, H, W]",
      "output_shape": "[batch, 192, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_110",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block4_bn2",
      "layer": "stage6_block4",
      "parameters": 4608,
      "input_shape": "[batch, 192, H, W]",
      "output_shape": "[batch, 192, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_111",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage6_block4_bn3",
      "layer": "stage6_block4",
      "parameters": 1280,
      "input_shape": "[batch, 192, H, W]",
      "output_shape": "[batch, 192, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_112",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage6_block4_relu6",
      "layer": "stage6_block4",
      "parameters": 0,
      "input_shape": "[batch, 192, H, W]",
      "output_shape": "[batch, 192, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_113",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage7_block1_expand_conv",
      "layer": "stage7_block1",
      "parameters": 614400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_114",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage7_block1_depthwise_conv",
      "layer": "stage7_block1",
      "parameters": 17280,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_115",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage7_block1_project_conv",
      "layer": "stage7_block1",
      "parameters": 614400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "EfficientNet_B0_op_116",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage7_block1_bn1",
      "layer": "stage7_block1",
      "parameters": 7680,
      "input_shape": "[batch, 320, H, W]",
      "output_shape": "[batch, 320, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_117",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage7_block1_bn2",
      "layer": "stage7_block1",
      "parameters": 7680,
      "input_shape": "[batch, 320, H, W]",
      "output_shape": "[batch, 320, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_118",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage7_block1_bn3",
      "layer": "stage7_block1",
      "parameters": 1280,
      "input_shape": "[batch, 320, H, W]",
      "output_shape": "[batch, 320, H, W]"
    },
    {
      "op_id": "EfficientNet_B0_op_119",
      "model_name": "EfficientNet-B0",
      "model_category": "CV",
      "type": "ReLU6",
      "name": "stage7_block1_relu6",
      "layer": "stage7_block1",
      "parameters": 0,
      "input_shape": "[batch, 320, H, W]",
      "output_shape": "[batch, 320, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_1",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "conv1",
      "layer": "global",
      "parameters": 9408,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_2",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "bn1",
      "layer": "global",
      "parameters": 256,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_3",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "relu",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_4",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "MaxPool2d",
      "name": "maxpool",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, H/2, W/2]"
    },
    {
      "op_id": "ConvNeXt_Base_op_5",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "AdaptiveAvgPool2d",
      "name": "avgpool",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, 1, 1]"
    },
    {
      "op_id": "ConvNeXt_Base_op_6",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "fc",
      "layer": "global",
      "parameters": 2048000,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ConvNeXt_Base_op_7",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block1_conv1",
      "layer": "stage1_block1",
      "parameters": 32768,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_8",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block1_conv2",
      "layer": "stage1_block1",
      "parameters": 589824,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_9",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block1_conv3",
      "layer": "stage1_block1",
      "parameters": 262144,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_10",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block1_bn1",
      "layer": "stage1_block1",
      "parameters": 1024,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_11",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block1_bn2",
      "layer": "stage1_block1",
      "parameters": 1024,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_12",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block1_bn3",
      "layer": "stage1_block1",
      "parameters": 4096,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_13",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage1_block1_relu",
      "layer": "stage1_block1",
      "parameters": 0,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_14",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block2_conv1",
      "layer": "stage1_block2",
      "parameters": 32768,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_15",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block2_conv2",
      "layer": "stage1_block2",
      "parameters": 589824,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_16",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block2_conv3",
      "layer": "stage1_block2",
      "parameters": 262144,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_17",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block2_bn1",
      "layer": "stage1_block2",
      "parameters": 1024,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_18",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block2_bn2",
      "layer": "stage1_block2",
      "parameters": 1024,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_19",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block2_bn3",
      "layer": "stage1_block2",
      "parameters": 4096,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_20",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage1_block2_relu",
      "layer": "stage1_block2",
      "parameters": 0,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_21",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block3_conv1",
      "layer": "stage1_block3",
      "parameters": 32768,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_22",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block3_conv2",
      "layer": "stage1_block3",
      "parameters": 589824,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_23",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block3_conv3",
      "layer": "stage1_block3",
      "parameters": 262144,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_24",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block3_bn1",
      "layer": "stage1_block3",
      "parameters": 1024,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_25",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block3_bn2",
      "layer": "stage1_block3",
      "parameters": 1024,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_26",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block3_bn3",
      "layer": "stage1_block3",
      "parameters": 4096,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_27",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage1_block3_relu",
      "layer": "stage1_block3",
      "parameters": 0,
      "input_shape": "[batch, 128, H, W]",
      "output_shape": "[batch, 128, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_28",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block1_conv1",
      "layer": "stage2_block1",
      "parameters": 131072,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_29",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block1_conv2",
      "layer": "stage2_block1",
      "parameters": 2359296,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_30",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block1_conv3",
      "layer": "stage2_block1",
      "parameters": 1048576,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_31",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block1_bn1",
      "layer": "stage2_block1",
      "parameters": 2048,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_32",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block1_bn2",
      "layer": "stage2_block1",
      "parameters": 2048,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_33",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block1_bn3",
      "layer": "stage2_block1",
      "parameters": 8192,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_34",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage2_block1_relu",
      "layer": "stage2_block1",
      "parameters": 0,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_35",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block2_conv1",
      "layer": "stage2_block2",
      "parameters": 131072,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_36",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block2_conv2",
      "layer": "stage2_block2",
      "parameters": 2359296,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_37",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block2_conv3",
      "layer": "stage2_block2",
      "parameters": 1048576,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_38",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block2_bn1",
      "layer": "stage2_block2",
      "parameters": 2048,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_39",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block2_bn2",
      "layer": "stage2_block2",
      "parameters": 2048,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_40",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block2_bn3",
      "layer": "stage2_block2",
      "parameters": 8192,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_41",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage2_block2_relu",
      "layer": "stage2_block2",
      "parameters": 0,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_42",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block3_conv1",
      "layer": "stage2_block3",
      "parameters": 131072,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_43",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block3_conv2",
      "layer": "stage2_block3",
      "parameters": 2359296,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_44",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block3_conv3",
      "layer": "stage2_block3",
      "parameters": 1048576,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_45",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block3_bn1",
      "layer": "stage2_block3",
      "parameters": 2048,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_46",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block3_bn2",
      "layer": "stage2_block3",
      "parameters": 2048,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_47",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block3_bn3",
      "layer": "stage2_block3",
      "parameters": 8192,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_48",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage2_block3_relu",
      "layer": "stage2_block3",
      "parameters": 0,
      "input_shape": "[batch, 256, H, W]",
      "output_shape": "[batch, 256, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_49",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block1_conv1",
      "layer": "stage3_block1",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_50",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block1_conv2",
      "layer": "stage3_block1",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_51",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block1_conv3",
      "layer": "stage3_block1",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_52",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block1_bn1",
      "layer": "stage3_block1",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_53",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block1_bn2",
      "layer": "stage3_block1",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_54",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block1_bn3",
      "layer": "stage3_block1",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_55",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block1_relu",
      "layer": "stage3_block1",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_56",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block2_conv1",
      "layer": "stage3_block2",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_57",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block2_conv2",
      "layer": "stage3_block2",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_58",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block2_conv3",
      "layer": "stage3_block2",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_59",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block2_bn1",
      "layer": "stage3_block2",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_60",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block2_bn2",
      "layer": "stage3_block2",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_61",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block2_bn3",
      "layer": "stage3_block2",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_62",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block2_relu",
      "layer": "stage3_block2",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_63",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block3_conv1",
      "layer": "stage3_block3",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_64",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block3_conv2",
      "layer": "stage3_block3",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_65",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block3_conv3",
      "layer": "stage3_block3",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_66",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block3_bn1",
      "layer": "stage3_block3",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_67",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block3_bn2",
      "layer": "stage3_block3",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_68",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block3_bn3",
      "layer": "stage3_block3",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_69",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block3_relu",
      "layer": "stage3_block3",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_70",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block4_conv1",
      "layer": "stage3_block4",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_71",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block4_conv2",
      "layer": "stage3_block4",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_72",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block4_conv3",
      "layer": "stage3_block4",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_73",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block4_bn1",
      "layer": "stage3_block4",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_74",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block4_bn2",
      "layer": "stage3_block4",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_75",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block4_bn3",
      "layer": "stage3_block4",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_76",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block4_relu",
      "layer": "stage3_block4",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_77",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block5_conv1",
      "layer": "stage3_block5",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_78",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block5_conv2",
      "layer": "stage3_block5",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_79",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block5_conv3",
      "layer": "stage3_block5",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_80",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block5_bn1",
      "layer": "stage3_block5",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_81",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block5_bn2",
      "layer": "stage3_block5",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_82",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block5_bn3",
      "layer": "stage3_block5",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_83",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block5_relu",
      "layer": "stage3_block5",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_84",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block6_conv1",
      "layer": "stage3_block6",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_85",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block6_conv2",
      "layer": "stage3_block6",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_86",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block6_conv3",
      "layer": "stage3_block6",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_87",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block6_bn1",
      "layer": "stage3_block6",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_88",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block6_bn2",
      "layer": "stage3_block6",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_89",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block6_bn3",
      "layer": "stage3_block6",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_90",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block6_relu",
      "layer": "stage3_block6",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_91",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block7_conv1",
      "layer": "stage3_block7",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_92",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block7_conv2",
      "layer": "stage3_block7",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_93",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block7_conv3",
      "layer": "stage3_block7",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_94",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block7_bn1",
      "layer": "stage3_block7",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_95",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block7_bn2",
      "layer": "stage3_block7",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_96",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block7_bn3",
      "layer": "stage3_block7",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_97",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block7_relu",
      "layer": "stage3_block7",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_98",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block8_conv1",
      "layer": "stage3_block8",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_99",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block8_conv2",
      "layer": "stage3_block8",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_100",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block8_conv3",
      "layer": "stage3_block8",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_101",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block8_bn1",
      "layer": "stage3_block8",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_102",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block8_bn2",
      "layer": "stage3_block8",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_103",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block8_bn3",
      "layer": "stage3_block8",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_104",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block8_relu",
      "layer": "stage3_block8",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_105",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block9_conv1",
      "layer": "stage3_block9",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_106",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block9_conv2",
      "layer": "stage3_block9",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_107",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block9_conv3",
      "layer": "stage3_block9",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_108",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block9_bn1",
      "layer": "stage3_block9",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_109",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block9_bn2",
      "layer": "stage3_block9",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_110",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block9_bn3",
      "layer": "stage3_block9",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_111",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block9_relu",
      "layer": "stage3_block9",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_112",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block10_conv1",
      "layer": "stage3_block10",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_113",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block10_conv2",
      "layer": "stage3_block10",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_114",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block10_conv3",
      "layer": "stage3_block10",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_115",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block10_bn1",
      "layer": "stage3_block10",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_116",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block10_bn2",
      "layer": "stage3_block10",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_117",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block10_bn3",
      "layer": "stage3_block10",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_118",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block10_relu",
      "layer": "stage3_block10",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_119",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block11_conv1",
      "layer": "stage3_block11",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_120",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block11_conv2",
      "layer": "stage3_block11",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_121",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block11_conv3",
      "layer": "stage3_block11",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_122",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block11_bn1",
      "layer": "stage3_block11",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_123",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block11_bn2",
      "layer": "stage3_block11",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_124",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block11_bn3",
      "layer": "stage3_block11",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_125",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block11_relu",
      "layer": "stage3_block11",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_126",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block12_conv1",
      "layer": "stage3_block12",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_127",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block12_conv2",
      "layer": "stage3_block12",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_128",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block12_conv3",
      "layer": "stage3_block12",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_129",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block12_bn1",
      "layer": "stage3_block12",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_130",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block12_bn2",
      "layer": "stage3_block12",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_131",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block12_bn3",
      "layer": "stage3_block12",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_132",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block12_relu",
      "layer": "stage3_block12",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_133",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block13_conv1",
      "layer": "stage3_block13",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_134",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block13_conv2",
      "layer": "stage3_block13",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_135",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block13_conv3",
      "layer": "stage3_block13",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_136",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block13_bn1",
      "layer": "stage3_block13",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_137",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block13_bn2",
      "layer": "stage3_block13",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_138",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block13_bn3",
      "layer": "stage3_block13",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_139",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block13_relu",
      "layer": "stage3_block13",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_140",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block14_conv1",
      "layer": "stage3_block14",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_141",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block14_conv2",
      "layer": "stage3_block14",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_142",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block14_conv3",
      "layer": "stage3_block14",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_143",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block14_bn1",
      "layer": "stage3_block14",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_144",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block14_bn2",
      "layer": "stage3_block14",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_145",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block14_bn3",
      "layer": "stage3_block14",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_146",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block14_relu",
      "layer": "stage3_block14",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_147",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block15_conv1",
      "layer": "stage3_block15",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_148",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block15_conv2",
      "layer": "stage3_block15",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_149",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block15_conv3",
      "layer": "stage3_block15",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_150",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block15_bn1",
      "layer": "stage3_block15",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_151",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block15_bn2",
      "layer": "stage3_block15",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_152",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block15_bn3",
      "layer": "stage3_block15",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_153",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block15_relu",
      "layer": "stage3_block15",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_154",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block16_conv1",
      "layer": "stage3_block16",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_155",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block16_conv2",
      "layer": "stage3_block16",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_156",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block16_conv3",
      "layer": "stage3_block16",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_157",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block16_bn1",
      "layer": "stage3_block16",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_158",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block16_bn2",
      "layer": "stage3_block16",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_159",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block16_bn3",
      "layer": "stage3_block16",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_160",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block16_relu",
      "layer": "stage3_block16",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_161",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block17_conv1",
      "layer": "stage3_block17",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_162",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block17_conv2",
      "layer": "stage3_block17",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_163",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block17_conv3",
      "layer": "stage3_block17",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_164",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block17_bn1",
      "layer": "stage3_block17",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_165",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block17_bn2",
      "layer": "stage3_block17",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_166",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block17_bn3",
      "layer": "stage3_block17",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_167",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block17_relu",
      "layer": "stage3_block17",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_168",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block18_conv1",
      "layer": "stage3_block18",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_169",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block18_conv2",
      "layer": "stage3_block18",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_170",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block18_conv3",
      "layer": "stage3_block18",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_171",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block18_bn1",
      "layer": "stage3_block18",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_172",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block18_bn2",
      "layer": "stage3_block18",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_173",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block18_bn3",
      "layer": "stage3_block18",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_174",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block18_relu",
      "layer": "stage3_block18",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_175",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block19_conv1",
      "layer": "stage3_block19",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_176",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block19_conv2",
      "layer": "stage3_block19",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_177",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block19_conv3",
      "layer": "stage3_block19",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_178",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block19_bn1",
      "layer": "stage3_block19",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_179",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block19_bn2",
      "layer": "stage3_block19",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_180",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block19_bn3",
      "layer": "stage3_block19",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_181",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block19_relu",
      "layer": "stage3_block19",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_182",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block20_conv1",
      "layer": "stage3_block20",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_183",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block20_conv2",
      "layer": "stage3_block20",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_184",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block20_conv3",
      "layer": "stage3_block20",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_185",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block20_bn1",
      "layer": "stage3_block20",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_186",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block20_bn2",
      "layer": "stage3_block20",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_187",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block20_bn3",
      "layer": "stage3_block20",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_188",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block20_relu",
      "layer": "stage3_block20",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_189",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block21_conv1",
      "layer": "stage3_block21",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_190",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block21_conv2",
      "layer": "stage3_block21",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_191",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block21_conv3",
      "layer": "stage3_block21",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_192",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block21_bn1",
      "layer": "stage3_block21",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_193",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block21_bn2",
      "layer": "stage3_block21",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_194",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block21_bn3",
      "layer": "stage3_block21",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_195",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block21_relu",
      "layer": "stage3_block21",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_196",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block22_conv1",
      "layer": "stage3_block22",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_197",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block22_conv2",
      "layer": "stage3_block22",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_198",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block22_conv3",
      "layer": "stage3_block22",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_199",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block22_bn1",
      "layer": "stage3_block22",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_200",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block22_bn2",
      "layer": "stage3_block22",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_201",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block22_bn3",
      "layer": "stage3_block22",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_202",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block22_relu",
      "layer": "stage3_block22",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_203",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block23_conv1",
      "layer": "stage3_block23",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_204",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block23_conv2",
      "layer": "stage3_block23",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_205",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block23_conv3",
      "layer": "stage3_block23",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_206",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block23_bn1",
      "layer": "stage3_block23",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_207",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block23_bn2",
      "layer": "stage3_block23",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_208",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block23_bn3",
      "layer": "stage3_block23",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_209",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block23_relu",
      "layer": "stage3_block23",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_210",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block24_conv1",
      "layer": "stage3_block24",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_211",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block24_conv2",
      "layer": "stage3_block24",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_212",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block24_conv3",
      "layer": "stage3_block24",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_213",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block24_bn1",
      "layer": "stage3_block24",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_214",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block24_bn2",
      "layer": "stage3_block24",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_215",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block24_bn3",
      "layer": "stage3_block24",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_216",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block24_relu",
      "layer": "stage3_block24",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_217",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block25_conv1",
      "layer": "stage3_block25",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_218",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block25_conv2",
      "layer": "stage3_block25",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_219",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block25_conv3",
      "layer": "stage3_block25",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_220",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block25_bn1",
      "layer": "stage3_block25",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_221",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block25_bn2",
      "layer": "stage3_block25",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_222",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block25_bn3",
      "layer": "stage3_block25",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_223",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block25_relu",
      "layer": "stage3_block25",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_224",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block26_conv1",
      "layer": "stage3_block26",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_225",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block26_conv2",
      "layer": "stage3_block26",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_226",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block26_conv3",
      "layer": "stage3_block26",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_227",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block26_bn1",
      "layer": "stage3_block26",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_228",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block26_bn2",
      "layer": "stage3_block26",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_229",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block26_bn3",
      "layer": "stage3_block26",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_230",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block26_relu",
      "layer": "stage3_block26",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_231",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block27_conv1",
      "layer": "stage3_block27",
      "parameters": 524288,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_232",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block27_conv2",
      "layer": "stage3_block27",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_233",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block27_conv3",
      "layer": "stage3_block27",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_234",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block27_bn1",
      "layer": "stage3_block27",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_235",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block27_bn2",
      "layer": "stage3_block27",
      "parameters": 4096,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_236",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block27_bn3",
      "layer": "stage3_block27",
      "parameters": 16384,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_237",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block27_relu",
      "layer": "stage3_block27",
      "parameters": 0,
      "input_shape": "[batch, 512, H, W]",
      "output_shape": "[batch, 512, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_238",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block1_conv1",
      "layer": "stage4_block1",
      "parameters": 1048576,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_239",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block1_conv2",
      "layer": "stage4_block1",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_240",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block1_conv3",
      "layer": "stage4_block1",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_241",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block1_bn1",
      "layer": "stage4_block1",
      "parameters": 4096,
      "input_shape": "[batch, 1024, H, W]",
      "output_shape": "[batch, 1024, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_242",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block1_bn2",
      "layer": "stage4_block1",
      "parameters": 4096,
      "input_shape": "[batch, 1024, H, W]",
      "output_shape": "[batch, 1024, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_243",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block1_bn3",
      "layer": "stage4_block1",
      "parameters": 16384,
      "input_shape": "[batch, 1024, H, W]",
      "output_shape": "[batch, 1024, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_244",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage4_block1_relu",
      "layer": "stage4_block1",
      "parameters": 0,
      "input_shape": "[batch, 1024, H, W]",
      "output_shape": "[batch, 1024, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_245",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block2_conv1",
      "layer": "stage4_block2",
      "parameters": 1048576,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_246",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block2_conv2",
      "layer": "stage4_block2",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_247",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block2_conv3",
      "layer": "stage4_block2",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_248",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block2_bn1",
      "layer": "stage4_block2",
      "parameters": 4096,
      "input_shape": "[batch, 1024, H, W]",
      "output_shape": "[batch, 1024, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_249",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block2_bn2",
      "layer": "stage4_block2",
      "parameters": 4096,
      "input_shape": "[batch, 1024, H, W]",
      "output_shape": "[batch, 1024, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_250",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block2_bn3",
      "layer": "stage4_block2",
      "parameters": 16384,
      "input_shape": "[batch, 1024, H, W]",
      "output_shape": "[batch, 1024, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_251",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage4_block2_relu",
      "layer": "stage4_block2",
      "parameters": 0,
      "input_shape": "[batch, 1024, H, W]",
      "output_shape": "[batch, 1024, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_252",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block3_conv1",
      "layer": "stage4_block3",
      "parameters": 1048576,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_253",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block3_conv2",
      "layer": "stage4_block3",
      "parameters": 9437184,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_254",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block3_conv3",
      "layer": "stage4_block3",
      "parameters": 4194304,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "ConvNeXt_Base_op_255",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block3_bn1",
      "layer": "stage4_block3",
      "parameters": 4096,
      "input_shape": "[batch, 1024, H, W]",
      "output_shape": "[batch, 1024, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_256",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block3_bn2",
      "layer": "stage4_block3",
      "parameters": 4096,
      "input_shape": "[batch, 1024, H, W]",
      "output_shape": "[batch, 1024, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_257",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block3_bn3",
      "layer": "stage4_block3",
      "parameters": 16384,
      "input_shape": "[batch, 1024, H, W]",
      "output_shape": "[batch, 1024, H, W]"
    },
    {
      "op_id": "ConvNeXt_Base_op_258",
      "model_name": "ConvNeXt-Base",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage4_block3_relu",
      "layer": "stage4_block3",
      "parameters": 0,
      "input_shape": "[batch, 1024, H, W]",
      "output_shape": "[batch, 1024, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_1",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "conv1",
      "layer": "global",
      "parameters": 9408,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_2",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "bn1",
      "layer": "global",
      "parameters": 256,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_3",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "relu",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_4",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "MaxPool2d",
      "name": "maxpool",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, H/2, W/2]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_5",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "AdaptiveAvgPool2d",
      "name": "avgpool",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, 768, H, W]",
      "output_shape": "[batch, 768, 1, 1]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_6",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Linear",
      "name": "fc",
      "layer": "global",
      "parameters": 2048000,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_7",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block1_conv1",
      "layer": "stage1_block1",
      "parameters": 4992,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_8",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block1_conv2",
      "layer": "stage1_block1",
      "parameters": 97344,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_9",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block1_conv3",
      "layer": "stage1_block1",
      "parameters": 43264,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_10",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block1_bn1",
      "layer": "stage1_block1",
      "parameters": 416,
      "input_shape": "[batch, 48, H, W]",
      "output_shape": "[batch, 48, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_11",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block1_bn2",
      "layer": "stage1_block1",
      "parameters": 416,
      "input_shape": "[batch, 48, H, W]",
      "output_shape": "[batch, 48, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_12",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block1_bn3",
      "layer": "stage1_block1",
      "parameters": 1664,
      "input_shape": "[batch, 48, H, W]",
      "output_shape": "[batch, 48, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_13",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage1_block1_relu",
      "layer": "stage1_block1",
      "parameters": 0,
      "input_shape": "[batch, 48, H, W]",
      "output_shape": "[batch, 48, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_14",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block2_conv1",
      "layer": "stage1_block2",
      "parameters": 4992,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_15",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block2_conv2",
      "layer": "stage1_block2",
      "parameters": 97344,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_16",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage1_block2_conv3",
      "layer": "stage1_block2",
      "parameters": 43264,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_17",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block2_bn1",
      "layer": "stage1_block2",
      "parameters": 416,
      "input_shape": "[batch, 48, H, W]",
      "output_shape": "[batch, 48, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_18",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block2_bn2",
      "layer": "stage1_block2",
      "parameters": 416,
      "input_shape": "[batch, 48, H, W]",
      "output_shape": "[batch, 48, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_19",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage1_block2_bn3",
      "layer": "stage1_block2",
      "parameters": 1664,
      "input_shape": "[batch, 48, H, W]",
      "output_shape": "[batch, 48, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_20",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage1_block2_relu",
      "layer": "stage1_block2",
      "parameters": 0,
      "input_shape": "[batch, 48, H, W]",
      "output_shape": "[batch, 48, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_21",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block1_conv1",
      "layer": "stage2_block1",
      "parameters": 21632,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_22",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block1_conv2",
      "layer": "stage2_block1",
      "parameters": 389376,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_23",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block1_conv3",
      "layer": "stage2_block1",
      "parameters": 173056,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_24",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block1_bn1",
      "layer": "stage2_block1",
      "parameters": 832,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_25",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block1_bn2",
      "layer": "stage2_block1",
      "parameters": 832,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_26",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block1_bn3",
      "layer": "stage2_block1",
      "parameters": 3328,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_27",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage2_block1_relu",
      "layer": "stage2_block1",
      "parameters": 0,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_28",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block2_conv1",
      "layer": "stage2_block2",
      "parameters": 21632,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_29",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block2_conv2",
      "layer": "stage2_block2",
      "parameters": 389376,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_30",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block2_conv3",
      "layer": "stage2_block2",
      "parameters": 173056,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_31",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block2_bn1",
      "layer": "stage2_block2",
      "parameters": 832,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_32",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block2_bn2",
      "layer": "stage2_block2",
      "parameters": 832,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_33",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block2_bn3",
      "layer": "stage2_block2",
      "parameters": 3328,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_34",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage2_block2_relu",
      "layer": "stage2_block2",
      "parameters": 0,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_35",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block3_conv1",
      "layer": "stage2_block3",
      "parameters": 21632,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_36",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block3_conv2",
      "layer": "stage2_block3",
      "parameters": 389376,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_37",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block3_conv3",
      "layer": "stage2_block3",
      "parameters": 173056,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_38",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block3_bn1",
      "layer": "stage2_block3",
      "parameters": 832,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_39",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block3_bn2",
      "layer": "stage2_block3",
      "parameters": 832,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_40",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block3_bn3",
      "layer": "stage2_block3",
      "parameters": 3328,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_41",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage2_block3_relu",
      "layer": "stage2_block3",
      "parameters": 0,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_42",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block4_conv1",
      "layer": "stage2_block4",
      "parameters": 21632,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_43",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block4_conv2",
      "layer": "stage2_block4",
      "parameters": 389376,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_44",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block4_conv3",
      "layer": "stage2_block4",
      "parameters": 173056,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_45",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block4_bn1",
      "layer": "stage2_block4",
      "parameters": 832,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_46",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block4_bn2",
      "layer": "stage2_block4",
      "parameters": 832,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_47",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block4_bn3",
      "layer": "stage2_block4",
      "parameters": 3328,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_48",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage2_block4_relu",
      "layer": "stage2_block4",
      "parameters": 0,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_49",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block5_conv1",
      "layer": "stage2_block5",
      "parameters": 21632,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_50",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block5_conv2",
      "layer": "stage2_block5",
      "parameters": 389376,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_51",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block5_conv3",
      "layer": "stage2_block5",
      "parameters": 173056,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_52",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block5_bn1",
      "layer": "stage2_block5",
      "parameters": 832,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_53",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block5_bn2",
      "layer": "stage2_block5",
      "parameters": 832,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_54",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block5_bn3",
      "layer": "stage2_block5",
      "parameters": 3328,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_55",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage2_block5_relu",
      "layer": "stage2_block5",
      "parameters": 0,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_56",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block6_conv1",
      "layer": "stage2_block6",
      "parameters": 21632,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_57",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block6_conv2",
      "layer": "stage2_block6",
      "parameters": 389376,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_58",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage2_block6_conv3",
      "layer": "stage2_block6",
      "parameters": 173056,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_59",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block6_bn1",
      "layer": "stage2_block6",
      "parameters": 832,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_60",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block6_bn2",
      "layer": "stage2_block6",
      "parameters": 832,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_61",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage2_block6_bn3",
      "layer": "stage2_block6",
      "parameters": 3328,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_62",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage2_block6_relu",
      "layer": "stage2_block6",
      "parameters": 0,
      "input_shape": "[batch, 104, H, W]",
      "output_shape": "[batch, 104, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_63",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block1_conv1",
      "layer": "stage3_block1",
      "parameters": 91520,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_64",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block1_conv2",
      "layer": "stage3_block1",
      "parameters": 1742400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_65",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block1_conv3",
      "layer": "stage3_block1",
      "parameters": 774400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_66",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block1_bn1",
      "layer": "stage3_block1",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_67",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block1_bn2",
      "layer": "stage3_block1",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_68",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block1_bn3",
      "layer": "stage3_block1",
      "parameters": 7040,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_69",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block1_relu",
      "layer": "stage3_block1",
      "parameters": 0,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_70",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block2_conv1",
      "layer": "stage3_block2",
      "parameters": 91520,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_71",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block2_conv2",
      "layer": "stage3_block2",
      "parameters": 1742400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_72",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block2_conv3",
      "layer": "stage3_block2",
      "parameters": 774400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_73",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block2_bn1",
      "layer": "stage3_block2",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_74",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block2_bn2",
      "layer": "stage3_block2",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_75",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block2_bn3",
      "layer": "stage3_block2",
      "parameters": 7040,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_76",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block2_relu",
      "layer": "stage3_block2",
      "parameters": 0,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_77",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block3_conv1",
      "layer": "stage3_block3",
      "parameters": 91520,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_78",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block3_conv2",
      "layer": "stage3_block3",
      "parameters": 1742400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_79",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block3_conv3",
      "layer": "stage3_block3",
      "parameters": 774400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_80",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block3_bn1",
      "layer": "stage3_block3",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_81",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block3_bn2",
      "layer": "stage3_block3",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_82",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block3_bn3",
      "layer": "stage3_block3",
      "parameters": 7040,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_83",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block3_relu",
      "layer": "stage3_block3",
      "parameters": 0,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_84",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block4_conv1",
      "layer": "stage3_block4",
      "parameters": 91520,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_85",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block4_conv2",
      "layer": "stage3_block4",
      "parameters": 1742400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_86",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block4_conv3",
      "layer": "stage3_block4",
      "parameters": 774400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_87",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block4_bn1",
      "layer": "stage3_block4",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_88",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block4_bn2",
      "layer": "stage3_block4",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_89",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block4_bn3",
      "layer": "stage3_block4",
      "parameters": 7040,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_90",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block4_relu",
      "layer": "stage3_block4",
      "parameters": 0,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_91",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block5_conv1",
      "layer": "stage3_block5",
      "parameters": 91520,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_92",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block5_conv2",
      "layer": "stage3_block5",
      "parameters": 1742400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_93",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block5_conv3",
      "layer": "stage3_block5",
      "parameters": 774400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_94",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block5_bn1",
      "layer": "stage3_block5",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_95",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block5_bn2",
      "layer": "stage3_block5",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_96",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block5_bn3",
      "layer": "stage3_block5",
      "parameters": 7040,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_97",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block5_relu",
      "layer": "stage3_block5",
      "parameters": 0,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_98",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block6_conv1",
      "layer": "stage3_block6",
      "parameters": 91520,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_99",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block6_conv2",
      "layer": "stage3_block6",
      "parameters": 1742400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_100",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block6_conv3",
      "layer": "stage3_block6",
      "parameters": 774400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_101",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block6_bn1",
      "layer": "stage3_block6",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_102",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block6_bn2",
      "layer": "stage3_block6",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_103",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block6_bn3",
      "layer": "stage3_block6",
      "parameters": 7040,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_104",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block6_relu",
      "layer": "stage3_block6",
      "parameters": 0,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_105",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block7_conv1",
      "layer": "stage3_block7",
      "parameters": 91520,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_106",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block7_conv2",
      "layer": "stage3_block7",
      "parameters": 1742400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_107",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block7_conv3",
      "layer": "stage3_block7",
      "parameters": 774400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_108",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block7_bn1",
      "layer": "stage3_block7",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_109",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block7_bn2",
      "layer": "stage3_block7",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_110",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block7_bn3",
      "layer": "stage3_block7",
      "parameters": 7040,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_111",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block7_relu",
      "layer": "stage3_block7",
      "parameters": 0,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_112",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block8_conv1",
      "layer": "stage3_block8",
      "parameters": 91520,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_113",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block8_conv2",
      "layer": "stage3_block8",
      "parameters": 1742400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_114",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block8_conv3",
      "layer": "stage3_block8",
      "parameters": 774400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_115",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block8_bn1",
      "layer": "stage3_block8",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_116",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block8_bn2",
      "layer": "stage3_block8",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_117",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block8_bn3",
      "layer": "stage3_block8",
      "parameters": 7040,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_118",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block8_relu",
      "layer": "stage3_block8",
      "parameters": 0,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_119",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block9_conv1",
      "layer": "stage3_block9",
      "parameters": 91520,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_120",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block9_conv2",
      "layer": "stage3_block9",
      "parameters": 1742400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_121",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block9_conv3",
      "layer": "stage3_block9",
      "parameters": 774400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_122",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block9_bn1",
      "layer": "stage3_block9",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_123",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block9_bn2",
      "layer": "stage3_block9",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_124",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block9_bn3",
      "layer": "stage3_block9",
      "parameters": 7040,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_125",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block9_relu",
      "layer": "stage3_block9",
      "parameters": 0,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_126",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block10_conv1",
      "layer": "stage3_block10",
      "parameters": 91520,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_127",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block10_conv2",
      "layer": "stage3_block10",
      "parameters": 1742400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_128",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block10_conv3",
      "layer": "stage3_block10",
      "parameters": 774400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_129",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block10_bn1",
      "layer": "stage3_block10",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_130",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block10_bn2",
      "layer": "stage3_block10",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_131",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block10_bn3",
      "layer": "stage3_block10",
      "parameters": 7040,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_132",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block10_relu",
      "layer": "stage3_block10",
      "parameters": 0,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_133",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block11_conv1",
      "layer": "stage3_block11",
      "parameters": 91520,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_134",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block11_conv2",
      "layer": "stage3_block11",
      "parameters": 1742400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_135",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block11_conv3",
      "layer": "stage3_block11",
      "parameters": 774400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_136",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block11_bn1",
      "layer": "stage3_block11",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_137",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block11_bn2",
      "layer": "stage3_block11",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_138",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block11_bn3",
      "layer": "stage3_block11",
      "parameters": 7040,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_139",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block11_relu",
      "layer": "stage3_block11",
      "parameters": 0,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_140",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block12_conv1",
      "layer": "stage3_block12",
      "parameters": 91520,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_141",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block12_conv2",
      "layer": "stage3_block12",
      "parameters": 1742400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_142",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage3_block12_conv3",
      "layer": "stage3_block12",
      "parameters": 774400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_143",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block12_bn1",
      "layer": "stage3_block12",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_144",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block12_bn2",
      "layer": "stage3_block12",
      "parameters": 1760,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_145",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage3_block12_bn3",
      "layer": "stage3_block12",
      "parameters": 7040,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_146",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage3_block12_relu",
      "layer": "stage3_block12",
      "parameters": 0,
      "input_shape": "[batch, 208, H, W]",
      "output_shape": "[batch, 208, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_147",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block1_conv1",
      "layer": "stage4_block1",
      "parameters": 193600,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_148",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block1_conv2",
      "layer": "stage4_block1",
      "parameters": 1742400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_149",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block1_conv3",
      "layer": "stage4_block1",
      "parameters": 774400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_150",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block1_bn1",
      "layer": "stage4_block1",
      "parameters": 1760,
      "input_shape": "[batch, 440, H, W]",
      "output_shape": "[batch, 440, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_151",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block1_bn2",
      "layer": "stage4_block1",
      "parameters": 1760,
      "input_shape": "[batch, 440, H, W]",
      "output_shape": "[batch, 440, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_152",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block1_bn3",
      "layer": "stage4_block1",
      "parameters": 7040,
      "input_shape": "[batch, 440, H, W]",
      "output_shape": "[batch, 440, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_153",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage4_block1_relu",
      "layer": "stage4_block1",
      "parameters": 0,
      "input_shape": "[batch, 440, H, W]",
      "output_shape": "[batch, 440, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_154",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block2_conv1",
      "layer": "stage4_block2",
      "parameters": 193600,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_155",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block2_conv2",
      "layer": "stage4_block2",
      "parameters": 1742400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_156",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "stage4_block2_conv3",
      "layer": "stage4_block2",
      "parameters": 774400,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "RegNet_Y_4GF_op_157",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block2_bn1",
      "layer": "stage4_block2",
      "parameters": 1760,
      "input_shape": "[batch, 440, H, W]",
      "output_shape": "[batch, 440, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_158",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block2_bn2",
      "layer": "stage4_block2",
      "parameters": 1760,
      "input_shape": "[batch, 440, H, W]",
      "output_shape": "[batch, 440, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_159",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "BatchNorm2d",
      "name": "stage4_block2_bn3",
      "layer": "stage4_block2",
      "parameters": 7040,
      "input_shape": "[batch, 440, H, W]",
      "output_shape": "[batch, 440, H, W]"
    },
    {
      "op_id": "RegNet_Y_4GF_op_160",
      "model_name": "RegNet-Y-4GF",
      "model_category": "CV",
      "type": "ReLU",
      "name": "stage4_block2_relu",
      "layer": "stage4_block2",
      "parameters": 0,
      "input_shape": "[batch, 440, H, W]",
      "output_shape": "[batch, 440, H, W]"
    },
    {
      "op_id": "BEiT_Base_op_1",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "patch_embed",
      "layer": "global",
      "parameters": 2073600000000,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "BEiT_Base_op_2",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "norm",
      "layer": "global",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_3",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "head",
      "layer": "global",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_4",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_qkv",
      "layer": "layer_0",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_5",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_proj",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_6",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_fc1",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_7",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_fc2",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_8",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer0_norm1",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_9",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer0_norm2",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_10",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BEiT_Base_op_11",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BEiT_Base_op_12",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer0_attn_drop",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_13",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer0_proj_drop",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_14",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_qkv",
      "layer": "layer_1",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_15",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_proj",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_16",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_fc1",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_17",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_fc2",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_18",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer1_norm1",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_19",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer1_norm2",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_20",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BEiT_Base_op_21",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BEiT_Base_op_22",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer1_attn_drop",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_23",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer1_proj_drop",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_24",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_qkv",
      "layer": "layer_2",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_25",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_proj",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_26",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_fc1",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_27",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_fc2",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_28",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer2_norm1",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_29",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer2_norm2",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_30",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BEiT_Base_op_31",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BEiT_Base_op_32",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer2_attn_drop",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_33",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer2_proj_drop",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_34",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_qkv",
      "layer": "layer_3",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_35",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_proj",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_36",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_fc1",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_37",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_fc2",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_38",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer3_norm1",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_39",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer3_norm2",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_40",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BEiT_Base_op_41",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BEiT_Base_op_42",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer3_attn_drop",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_43",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer3_proj_drop",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_44",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_qkv",
      "layer": "layer_4",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_45",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_proj",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_46",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_fc1",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_47",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_fc2",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_48",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer4_norm1",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_49",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer4_norm2",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_50",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BEiT_Base_op_51",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BEiT_Base_op_52",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer4_attn_drop",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_53",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer4_proj_drop",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_54",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_qkv",
      "layer": "layer_5",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_55",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_proj",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_56",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_fc1",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_57",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_fc2",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_58",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer5_norm1",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_59",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer5_norm2",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_60",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BEiT_Base_op_61",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BEiT_Base_op_62",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer5_attn_drop",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_63",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer5_proj_drop",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_64",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_qkv",
      "layer": "layer_6",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_65",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_proj",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_66",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_fc1",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_67",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_fc2",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_68",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer6_norm1",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_69",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer6_norm2",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_70",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BEiT_Base_op_71",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BEiT_Base_op_72",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer6_attn_drop",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_73",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer6_proj_drop",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_74",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_qkv",
      "layer": "layer_7",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_75",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_proj",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_76",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_fc1",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_77",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_fc2",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_78",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer7_norm1",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_79",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer7_norm2",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_80",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BEiT_Base_op_81",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BEiT_Base_op_82",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer7_attn_drop",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_83",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer7_proj_drop",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_84",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_qkv",
      "layer": "layer_8",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_85",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_proj",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_86",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_fc1",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_87",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_fc2",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_88",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer8_norm1",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_89",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer8_norm2",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_90",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BEiT_Base_op_91",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BEiT_Base_op_92",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer8_attn_drop",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_93",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer8_proj_drop",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_94",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_qkv",
      "layer": "layer_9",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_95",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_proj",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_96",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_fc1",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_97",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_fc2",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_98",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer9_norm1",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_99",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer9_norm2",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_100",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BEiT_Base_op_101",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BEiT_Base_op_102",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer9_attn_drop",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_103",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer9_proj_drop",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_104",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_qkv",
      "layer": "layer_10",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_105",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_proj",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_106",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_fc1",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_107",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_fc2",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_108",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer10_norm1",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_109",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer10_norm2",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_110",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BEiT_Base_op_111",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BEiT_Base_op_112",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer10_attn_drop",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_113",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer10_proj_drop",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_114",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_qkv",
      "layer": "layer_11",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_115",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_proj",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_116",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_fc1",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_117",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_fc2",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BEiT_Base_op_118",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer11_norm1",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_119",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer11_norm2",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_120",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BEiT_Base_op_121",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BEiT_Base_op_122",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer11_attn_drop",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BEiT_Base_op_123",
      "model_name": "BEiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer11_proj_drop",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_1",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "patch_embed",
      "layer": "global",
      "parameters": 2073600000000,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "DeiT_Base_op_2",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "norm",
      "layer": "global",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_3",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "head",
      "layer": "global",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_4",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_qkv",
      "layer": "layer_0",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_5",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_proj",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_6",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_fc1",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_7",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_fc2",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_8",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer0_norm1",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_9",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer0_norm2",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_10",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DeiT_Base_op_11",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DeiT_Base_op_12",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer0_attn_drop",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_13",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer0_proj_drop",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_14",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_qkv",
      "layer": "layer_1",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_15",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_proj",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_16",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_fc1",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_17",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_fc2",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_18",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer1_norm1",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_19",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer1_norm2",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_20",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DeiT_Base_op_21",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DeiT_Base_op_22",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer1_attn_drop",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_23",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer1_proj_drop",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_24",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_qkv",
      "layer": "layer_2",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_25",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_proj",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_26",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_fc1",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_27",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_fc2",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_28",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer2_norm1",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_29",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer2_norm2",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_30",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DeiT_Base_op_31",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DeiT_Base_op_32",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer2_attn_drop",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_33",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer2_proj_drop",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_34",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_qkv",
      "layer": "layer_3",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_35",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_proj",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_36",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_fc1",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_37",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_fc2",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_38",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer3_norm1",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_39",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer3_norm2",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_40",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DeiT_Base_op_41",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DeiT_Base_op_42",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer3_attn_drop",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_43",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer3_proj_drop",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_44",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_qkv",
      "layer": "layer_4",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_45",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_proj",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_46",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_fc1",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_47",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_fc2",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_48",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer4_norm1",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_49",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer4_norm2",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_50",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DeiT_Base_op_51",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DeiT_Base_op_52",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer4_attn_drop",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_53",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer4_proj_drop",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_54",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_qkv",
      "layer": "layer_5",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_55",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_proj",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_56",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_fc1",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_57",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_fc2",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_58",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer5_norm1",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_59",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer5_norm2",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_60",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DeiT_Base_op_61",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DeiT_Base_op_62",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer5_attn_drop",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_63",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer5_proj_drop",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_64",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_qkv",
      "layer": "layer_6",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_65",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_proj",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_66",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_fc1",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_67",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_fc2",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_68",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer6_norm1",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_69",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer6_norm2",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_70",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DeiT_Base_op_71",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DeiT_Base_op_72",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer6_attn_drop",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_73",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer6_proj_drop",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_74",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_qkv",
      "layer": "layer_7",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_75",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_proj",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_76",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_fc1",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_77",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_fc2",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_78",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer7_norm1",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_79",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer7_norm2",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_80",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DeiT_Base_op_81",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DeiT_Base_op_82",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer7_attn_drop",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_83",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer7_proj_drop",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_84",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_qkv",
      "layer": "layer_8",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_85",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_proj",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_86",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_fc1",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_87",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_fc2",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_88",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer8_norm1",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_89",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer8_norm2",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_90",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DeiT_Base_op_91",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DeiT_Base_op_92",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer8_attn_drop",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_93",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer8_proj_drop",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_94",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_qkv",
      "layer": "layer_9",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_95",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_proj",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_96",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_fc1",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_97",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_fc2",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_98",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer9_norm1",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_99",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer9_norm2",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_100",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DeiT_Base_op_101",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DeiT_Base_op_102",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer9_attn_drop",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_103",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer9_proj_drop",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_104",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_qkv",
      "layer": "layer_10",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_105",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_proj",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_106",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_fc1",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_107",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_fc2",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_108",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer10_norm1",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_109",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer10_norm2",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_110",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DeiT_Base_op_111",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DeiT_Base_op_112",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer10_attn_drop",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_113",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer10_proj_drop",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_114",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_qkv",
      "layer": "layer_11",
      "parameters": 1769472,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_115",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_proj",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_116",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_fc1",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_117",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_fc2",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DeiT_Base_op_118",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer11_norm1",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_119",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer11_norm2",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_120",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DeiT_Base_op_121",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DeiT_Base_op_122",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer11_attn_drop",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DeiT_Base_op_123",
      "model_name": "DeiT-Base",
      "model_category": "CV",
      "type": "Dropout",
      "name": "layer11_proj_drop",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_1",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "word_embeddings",
      "layer": "global",
      "parameters": 23440896,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_2",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "position_embeddings",
      "layer": "global",
      "parameters": 23440896,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_3",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "token_type_embeddings",
      "layer": "global",
      "parameters": 1536,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_4",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "embeddings_layernorm",
      "layer": "global",
      "parameters": 61044,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_5",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "pooler_dense",
      "layer": "global",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_6",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Tanh",
      "name": "pooler_activation",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_7",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_query",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_8",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_key",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_9",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_value",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_10",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_attention",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_11",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_intermediate",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_12",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_output",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_13",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer0_attention_layernorm",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_14",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer0_output_layernorm",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_15",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BERT_Base_op_16",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BERT_Base_op_17",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer0_attention_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_18",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer0_output_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_19",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_query",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_20",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_key",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_21",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_value",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_22",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_attention",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_23",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_intermediate",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_24",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_output",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_25",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer1_attention_layernorm",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_26",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer1_output_layernorm",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_27",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BERT_Base_op_28",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BERT_Base_op_29",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer1_attention_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_30",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer1_output_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_31",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_query",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_32",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_key",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_33",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_value",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_34",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_dense_attention",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_35",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_dense_intermediate",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_36",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_dense_output",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_37",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer2_attention_layernorm",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_38",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer2_output_layernorm",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_39",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BERT_Base_op_40",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BERT_Base_op_41",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer2_attention_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_42",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer2_output_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_43",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_query",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_44",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_key",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_45",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_value",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_46",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_dense_attention",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_47",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_dense_intermediate",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_48",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_dense_output",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_49",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer3_attention_layernorm",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_50",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer3_output_layernorm",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_51",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BERT_Base_op_52",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BERT_Base_op_53",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer3_attention_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_54",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer3_output_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_55",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_query",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_56",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_key",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_57",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_value",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_58",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_dense_attention",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_59",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_dense_intermediate",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_60",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_dense_output",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_61",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer4_attention_layernorm",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_62",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer4_output_layernorm",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_63",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BERT_Base_op_64",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BERT_Base_op_65",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer4_attention_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_66",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer4_output_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_67",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_query",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_68",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_key",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_69",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_value",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_70",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_dense_attention",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_71",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_dense_intermediate",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_72",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_dense_output",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_73",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer5_attention_layernorm",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_74",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer5_output_layernorm",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_75",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BERT_Base_op_76",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BERT_Base_op_77",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer5_attention_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_78",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer5_output_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_79",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_query",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_80",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_key",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_81",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_value",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_82",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_dense_attention",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_83",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_dense_intermediate",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_84",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_dense_output",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_85",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer6_attention_layernorm",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_86",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer6_output_layernorm",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_87",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BERT_Base_op_88",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BERT_Base_op_89",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer6_attention_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_90",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer6_output_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_91",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_query",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_92",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_key",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_93",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_value",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_94",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_dense_attention",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_95",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_dense_intermediate",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_96",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_dense_output",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_97",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer7_attention_layernorm",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_98",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer7_output_layernorm",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_99",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BERT_Base_op_100",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BERT_Base_op_101",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer7_attention_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_102",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer7_output_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_103",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_query",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_104",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_key",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_105",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_value",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_106",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_dense_attention",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_107",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_dense_intermediate",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_108",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_dense_output",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_109",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer8_attention_layernorm",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_110",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer8_output_layernorm",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_111",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BERT_Base_op_112",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BERT_Base_op_113",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer8_attention_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_114",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer8_output_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_115",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_query",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_116",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_key",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_117",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_value",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_118",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_dense_attention",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_119",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_dense_intermediate",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_120",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_dense_output",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_121",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer9_attention_layernorm",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_122",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer9_output_layernorm",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_123",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BERT_Base_op_124",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BERT_Base_op_125",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer9_attention_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_126",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer9_output_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_127",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_query",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_128",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_key",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_129",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_value",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_130",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_dense_attention",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_131",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_dense_intermediate",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_132",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_dense_output",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_133",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer10_attention_layernorm",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_134",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer10_output_layernorm",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_135",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BERT_Base_op_136",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BERT_Base_op_137",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer10_attention_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_138",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer10_output_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_139",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_query",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_140",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_key",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_141",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_value",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_142",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_dense_attention",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_143",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_dense_intermediate",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_144",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_dense_output",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Base_op_145",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer11_attention_layernorm",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_146",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer11_output_layernorm",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_147",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BERT_Base_op_148",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BERT_Base_op_149",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer11_attention_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BERT_Base_op_150",
      "model_name": "BERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer11_output_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_1",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "word_embeddings",
      "layer": "global",
      "parameters": 38603520,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_2",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "position_embeddings",
      "layer": "global",
      "parameters": 38603520,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_3",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "token_type_embeddings",
      "layer": "global",
      "parameters": 1536,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_4",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "embeddings_layernorm",
      "layer": "global",
      "parameters": 100530,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_5",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "pooler_dense",
      "layer": "global",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_6",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Tanh",
      "name": "pooler_activation",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_7",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_query",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_8",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_key",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_9",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_value",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_10",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_attention",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_11",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_intermediate",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_12",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_output",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_13",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer0_attention_layernorm",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_14",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer0_output_layernorm",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_15",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "RoBERTa_Base_op_16",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "RoBERTa_Base_op_17",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer0_attention_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_18",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer0_output_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_19",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_query",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_20",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_key",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_21",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_value",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_22",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_attention",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_23",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_intermediate",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_24",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_output",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_25",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer1_attention_layernorm",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_26",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer1_output_layernorm",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_27",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "RoBERTa_Base_op_28",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "RoBERTa_Base_op_29",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer1_attention_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_30",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer1_output_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_31",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_query",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_32",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_key",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_33",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_value",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_34",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_dense_attention",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_35",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_dense_intermediate",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_36",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_dense_output",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_37",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer2_attention_layernorm",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_38",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer2_output_layernorm",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_39",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "RoBERTa_Base_op_40",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "RoBERTa_Base_op_41",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer2_attention_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_42",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer2_output_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_43",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_query",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_44",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_key",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_45",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_value",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_46",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_dense_attention",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_47",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_dense_intermediate",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_48",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_dense_output",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_49",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer3_attention_layernorm",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_50",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer3_output_layernorm",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_51",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "RoBERTa_Base_op_52",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "RoBERTa_Base_op_53",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer3_attention_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_54",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer3_output_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_55",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_query",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_56",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_key",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_57",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_value",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_58",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_dense_attention",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_59",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_dense_intermediate",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_60",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_dense_output",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_61",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer4_attention_layernorm",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_62",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer4_output_layernorm",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_63",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "RoBERTa_Base_op_64",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "RoBERTa_Base_op_65",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer4_attention_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_66",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer4_output_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_67",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_query",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_68",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_key",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_69",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_value",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_70",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_dense_attention",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_71",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_dense_intermediate",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_72",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_dense_output",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_73",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer5_attention_layernorm",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_74",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer5_output_layernorm",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_75",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "RoBERTa_Base_op_76",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "RoBERTa_Base_op_77",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer5_attention_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_78",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer5_output_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_79",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_query",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_80",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_key",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_81",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_value",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_82",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_dense_attention",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_83",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_dense_intermediate",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_84",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_dense_output",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_85",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer6_attention_layernorm",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_86",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer6_output_layernorm",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_87",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "RoBERTa_Base_op_88",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "RoBERTa_Base_op_89",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer6_attention_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_90",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer6_output_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_91",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_query",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_92",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_key",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_93",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_value",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_94",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_dense_attention",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_95",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_dense_intermediate",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_96",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_dense_output",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_97",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer7_attention_layernorm",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_98",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer7_output_layernorm",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_99",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "RoBERTa_Base_op_100",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "RoBERTa_Base_op_101",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer7_attention_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_102",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer7_output_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_103",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_query",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_104",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_key",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_105",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_value",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_106",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_dense_attention",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_107",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_dense_intermediate",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_108",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_dense_output",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_109",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer8_attention_layernorm",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_110",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer8_output_layernorm",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_111",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "RoBERTa_Base_op_112",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "RoBERTa_Base_op_113",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer8_attention_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_114",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer8_output_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_115",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_query",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_116",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_key",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_117",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_value",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_118",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_dense_attention",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_119",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_dense_intermediate",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_120",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_dense_output",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_121",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer9_attention_layernorm",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_122",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer9_output_layernorm",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_123",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "RoBERTa_Base_op_124",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "RoBERTa_Base_op_125",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer9_attention_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_126",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer9_output_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_127",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_query",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_128",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_key",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_129",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_value",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_130",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_dense_attention",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_131",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_dense_intermediate",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_132",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_dense_output",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_133",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer10_attention_layernorm",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_134",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer10_output_layernorm",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_135",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "RoBERTa_Base_op_136",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "RoBERTa_Base_op_137",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer10_attention_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_138",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer10_output_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_139",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_query",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_140",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_key",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_141",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_value",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_142",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_dense_attention",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_143",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_dense_intermediate",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_144",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_dense_output",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "RoBERTa_Base_op_145",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer11_attention_layernorm",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_146",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer11_output_layernorm",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_147",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "RoBERTa_Base_op_148",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "RoBERTa_Base_op_149",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer11_attention_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "RoBERTa_Base_op_150",
      "model_name": "RoBERTa-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer11_output_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_1",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "shared",
      "layer": "global",
      "parameters": 589824,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_2",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "RMSNorm",
      "name": "final_layer_norm",
      "layer": "global",
      "parameters": 768,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_3",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_q",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_4",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_k",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_5",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_v",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_6",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_o",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_7",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_wi_0",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_8",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_wi_1",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_9",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_wo",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_10",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "RMSNorm",
      "name": "layer0_layer_norm",
      "layer": "layer_0",
      "parameters": 768,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_11",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "T5_Base_op_12",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "T5_Base_op_13",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer0_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_14",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_q",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_15",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_k",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_16",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_v",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_17",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_o",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_18",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_wi_0",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_19",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_wi_1",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_20",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_wo",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_21",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "RMSNorm",
      "name": "layer1_layer_norm",
      "layer": "layer_1",
      "parameters": 768,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_22",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "T5_Base_op_23",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "T5_Base_op_24",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer1_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_25",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_q",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_26",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_k",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_27",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_v",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_28",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_o",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_29",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_wi_0",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_30",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_wi_1",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_31",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_wo",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_32",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "RMSNorm",
      "name": "layer2_layer_norm",
      "layer": "layer_2",
      "parameters": 768,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_33",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "T5_Base_op_34",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "T5_Base_op_35",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer2_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_36",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_q",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_37",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_k",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_38",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_v",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_39",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_o",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_40",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_wi_0",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_41",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_wi_1",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_42",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_wo",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_43",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "RMSNorm",
      "name": "layer3_layer_norm",
      "layer": "layer_3",
      "parameters": 768,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_44",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "T5_Base_op_45",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "T5_Base_op_46",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer3_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_47",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_q",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_48",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_k",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_49",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_v",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_50",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_o",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_51",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_wi_0",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_52",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_wi_1",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_53",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_wo",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_54",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "RMSNorm",
      "name": "layer4_layer_norm",
      "layer": "layer_4",
      "parameters": 768,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_55",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "T5_Base_op_56",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "T5_Base_op_57",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer4_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_58",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_q",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_59",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_k",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_60",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_v",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_61",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_o",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_62",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_wi_0",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_63",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_wi_1",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_64",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_wo",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_65",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "RMSNorm",
      "name": "layer5_layer_norm",
      "layer": "layer_5",
      "parameters": 768,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_66",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "T5_Base_op_67",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "T5_Base_op_68",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer5_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_69",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_q",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_70",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_k",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_71",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_v",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_72",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_o",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_73",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_wi_0",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_74",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_wi_1",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_75",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_wo",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_76",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "RMSNorm",
      "name": "layer6_layer_norm",
      "layer": "layer_6",
      "parameters": 768,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_77",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "T5_Base_op_78",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "T5_Base_op_79",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer6_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_80",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_q",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_81",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_k",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_82",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_v",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_83",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_o",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_84",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_wi_0",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_85",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_wi_1",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_86",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_wo",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_87",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "RMSNorm",
      "name": "layer7_layer_norm",
      "layer": "layer_7",
      "parameters": 768,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_88",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "T5_Base_op_89",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "T5_Base_op_90",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer7_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_91",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_q",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_92",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_k",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_93",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_v",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_94",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_o",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_95",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_wi_0",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_96",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_wi_1",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_97",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_wo",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_98",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "RMSNorm",
      "name": "layer8_layer_norm",
      "layer": "layer_8",
      "parameters": 768,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_99",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "T5_Base_op_100",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "T5_Base_op_101",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer8_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_102",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_q",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_103",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_k",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_104",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_v",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_105",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_o",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_106",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_wi_0",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_107",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_wi_1",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_108",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_wo",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_109",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "RMSNorm",
      "name": "layer9_layer_norm",
      "layer": "layer_9",
      "parameters": 768,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_110",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "T5_Base_op_111",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "T5_Base_op_112",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer9_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_113",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_q",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_114",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_k",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_115",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_v",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_116",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_o",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_117",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_wi_0",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_118",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_wi_1",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_119",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_wo",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_120",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "RMSNorm",
      "name": "layer10_layer_norm",
      "layer": "layer_10",
      "parameters": 768,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_121",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "T5_Base_op_122",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "T5_Base_op_123",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer10_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_124",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_q",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_125",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_k",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_126",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_v",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_127",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_o",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_128",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_wi_0",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_129",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_wi_1",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_130",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_wo",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "T5_Base_op_131",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "RMSNorm",
      "name": "layer11_layer_norm",
      "layer": "layer_11",
      "parameters": 768,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "T5_Base_op_132",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "T5_Base_op_133",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "T5_Base_op_134",
      "model_name": "T5-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer11_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_1",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "word_embeddings",
      "layer": "global",
      "parameters": 23440896,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_2",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "position_embeddings",
      "layer": "global",
      "parameters": 23440896,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_3",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "token_type_embeddings",
      "layer": "global",
      "parameters": 1536,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_4",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "embeddings_layernorm",
      "layer": "global",
      "parameters": 61044,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_5",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "pooler_dense",
      "layer": "global",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_6",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Tanh",
      "name": "pooler_activation",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_7",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_query",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_8",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_key",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_9",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_value",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_10",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_attention",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_11",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_intermediate",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_12",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_output",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_13",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer0_attention_layernorm",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_14",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer0_output_layernorm",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_15",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DistilBERT_op_16",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DistilBERT_op_17",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer0_attention_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_18",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer0_output_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_19",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_query",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_20",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_key",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_21",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_value",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_22",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_attention",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_23",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_intermediate",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_24",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_output",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_25",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer1_attention_layernorm",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_26",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer1_output_layernorm",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_27",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DistilBERT_op_28",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DistilBERT_op_29",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer1_attention_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_30",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer1_output_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_31",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_query",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_32",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_key",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_33",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_value",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_34",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_dense_attention",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_35",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_dense_intermediate",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_36",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_dense_output",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_37",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer2_attention_layernorm",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_38",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer2_output_layernorm",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_39",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DistilBERT_op_40",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DistilBERT_op_41",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer2_attention_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_42",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer2_output_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_43",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_query",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_44",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_key",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_45",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_value",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_46",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_dense_attention",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_47",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_dense_intermediate",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_48",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_dense_output",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_49",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer3_attention_layernorm",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_50",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer3_output_layernorm",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_51",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DistilBERT_op_52",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DistilBERT_op_53",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer3_attention_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_54",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer3_output_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_55",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_query",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_56",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_key",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_57",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_value",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_58",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_dense_attention",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_59",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_dense_intermediate",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_60",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_dense_output",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_61",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer4_attention_layernorm",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_62",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer4_output_layernorm",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_63",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DistilBERT_op_64",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DistilBERT_op_65",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer4_attention_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_66",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer4_output_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_67",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_query",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_68",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_key",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_69",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_value",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_70",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_dense_attention",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_71",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_dense_intermediate",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_72",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_dense_output",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_op_73",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer5_attention_layernorm",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_74",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer5_output_layernorm",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_75",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DistilBERT_op_76",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DistilBERT_op_77",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer5_attention_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_op_78",
      "model_name": "DistilBERT",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer5_output_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Whisper_Base_op_1",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Conv1d",
      "name": "conv1",
      "layer": "global",
      "parameters": 122880,
      "input_shape": "[batch, C_in, L]",
      "output_shape": "[batch, C_out, L']"
    },
    {
      "op_id": "Whisper_Base_op_2",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Conv1d",
      "name": "conv2",
      "layer": "global",
      "parameters": 786432,
      "input_shape": "[batch, C_in, L]",
      "output_shape": "[batch, C_out, L']"
    },
    {
      "op_id": "Whisper_Base_op_3",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Embedding",
      "name": "embed_positions",
      "layer": "global",
      "parameters": 768000,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_4",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer_norm",
      "layer": "global",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_5",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer0_q_proj",
      "layer": "layer_0",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_6",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer0_k_proj",
      "layer": "layer_0",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_7",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer0_v_proj",
      "layer": "layer_0",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_8",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer0_out_proj",
      "layer": "layer_0",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_9",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer0_fc1",
      "layer": "layer_0",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_10",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer0_fc2",
      "layer": "layer_0",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_11",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer0_self_attn_layer_norm",
      "layer": "layer_0",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_12",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer0_final_layer_norm",
      "layer": "layer_0",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_13",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Whisper_Base_op_14",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Whisper_Base_op_15",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer1_q_proj",
      "layer": "layer_1",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_16",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer1_k_proj",
      "layer": "layer_1",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_17",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer1_v_proj",
      "layer": "layer_1",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_18",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer1_out_proj",
      "layer": "layer_1",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_19",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer1_fc1",
      "layer": "layer_1",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_20",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer1_fc2",
      "layer": "layer_1",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_21",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer1_self_attn_layer_norm",
      "layer": "layer_1",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_22",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer1_final_layer_norm",
      "layer": "layer_1",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_23",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Whisper_Base_op_24",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Whisper_Base_op_25",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer2_q_proj",
      "layer": "layer_2",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_26",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer2_k_proj",
      "layer": "layer_2",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_27",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer2_v_proj",
      "layer": "layer_2",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_28",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer2_out_proj",
      "layer": "layer_2",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_29",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer2_fc1",
      "layer": "layer_2",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_30",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer2_fc2",
      "layer": "layer_2",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_31",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer2_self_attn_layer_norm",
      "layer": "layer_2",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_32",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer2_final_layer_norm",
      "layer": "layer_2",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_33",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Whisper_Base_op_34",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Whisper_Base_op_35",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer3_q_proj",
      "layer": "layer_3",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_36",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer3_k_proj",
      "layer": "layer_3",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_37",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer3_v_proj",
      "layer": "layer_3",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_38",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer3_out_proj",
      "layer": "layer_3",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_39",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer3_fc1",
      "layer": "layer_3",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_40",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer3_fc2",
      "layer": "layer_3",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_41",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer3_self_attn_layer_norm",
      "layer": "layer_3",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_42",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer3_final_layer_norm",
      "layer": "layer_3",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_43",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Whisper_Base_op_44",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Whisper_Base_op_45",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer4_q_proj",
      "layer": "layer_4",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_46",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer4_k_proj",
      "layer": "layer_4",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_47",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer4_v_proj",
      "layer": "layer_4",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_48",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer4_out_proj",
      "layer": "layer_4",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_49",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer4_fc1",
      "layer": "layer_4",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_50",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer4_fc2",
      "layer": "layer_4",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_51",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer4_self_attn_layer_norm",
      "layer": "layer_4",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_52",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer4_final_layer_norm",
      "layer": "layer_4",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_53",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Whisper_Base_op_54",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Whisper_Base_op_55",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer5_q_proj",
      "layer": "layer_5",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_56",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer5_k_proj",
      "layer": "layer_5",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_57",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer5_v_proj",
      "layer": "layer_5",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_58",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer5_out_proj",
      "layer": "layer_5",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_59",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer5_fc1",
      "layer": "layer_5",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_60",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer5_fc2",
      "layer": "layer_5",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_61",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer5_self_attn_layer_norm",
      "layer": "layer_5",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_62",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer5_final_layer_norm",
      "layer": "layer_5",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_63",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Whisper_Base_op_64",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Whisper_Base_op_65",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer6_q_proj",
      "layer": "layer_6",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_66",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer6_k_proj",
      "layer": "layer_6",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_67",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer6_v_proj",
      "layer": "layer_6",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_68",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer6_out_proj",
      "layer": "layer_6",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_69",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer6_fc1",
      "layer": "layer_6",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_70",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer6_fc2",
      "layer": "layer_6",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_71",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer6_self_attn_layer_norm",
      "layer": "layer_6",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_72",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer6_final_layer_norm",
      "layer": "layer_6",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_73",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Whisper_Base_op_74",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Whisper_Base_op_75",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer7_q_proj",
      "layer": "layer_7",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_76",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer7_k_proj",
      "layer": "layer_7",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_77",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer7_v_proj",
      "layer": "layer_7",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_78",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer7_out_proj",
      "layer": "layer_7",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_79",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer7_fc1",
      "layer": "layer_7",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_80",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer7_fc2",
      "layer": "layer_7",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_81",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer7_self_attn_layer_norm",
      "layer": "layer_7",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_82",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer7_final_layer_norm",
      "layer": "layer_7",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_83",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Whisper_Base_op_84",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Whisper_Base_op_85",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer8_q_proj",
      "layer": "layer_8",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_86",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer8_k_proj",
      "layer": "layer_8",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_87",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer8_v_proj",
      "layer": "layer_8",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_88",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer8_out_proj",
      "layer": "layer_8",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_89",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer8_fc1",
      "layer": "layer_8",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_90",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer8_fc2",
      "layer": "layer_8",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_91",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer8_self_attn_layer_norm",
      "layer": "layer_8",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_92",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer8_final_layer_norm",
      "layer": "layer_8",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_93",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Whisper_Base_op_94",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Whisper_Base_op_95",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer9_q_proj",
      "layer": "layer_9",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_96",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer9_k_proj",
      "layer": "layer_9",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_97",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer9_v_proj",
      "layer": "layer_9",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_98",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer9_out_proj",
      "layer": "layer_9",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_99",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer9_fc1",
      "layer": "layer_9",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_100",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer9_fc2",
      "layer": "layer_9",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_101",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer9_self_attn_layer_norm",
      "layer": "layer_9",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_102",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer9_final_layer_norm",
      "layer": "layer_9",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_103",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Whisper_Base_op_104",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Whisper_Base_op_105",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer10_q_proj",
      "layer": "layer_10",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_106",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer10_k_proj",
      "layer": "layer_10",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_107",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer10_v_proj",
      "layer": "layer_10",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_108",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer10_out_proj",
      "layer": "layer_10",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_109",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer10_fc1",
      "layer": "layer_10",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_110",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer10_fc2",
      "layer": "layer_10",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_111",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer10_self_attn_layer_norm",
      "layer": "layer_10",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_112",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer10_final_layer_norm",
      "layer": "layer_10",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_113",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Whisper_Base_op_114",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Whisper_Base_op_115",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer11_q_proj",
      "layer": "layer_11",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_116",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer11_k_proj",
      "layer": "layer_11",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_117",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer11_v_proj",
      "layer": "layer_11",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_118",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer11_out_proj",
      "layer": "layer_11",
      "parameters": 262144,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_119",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer11_fc1",
      "layer": "layer_11",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_120",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer11_fc2",
      "layer": "layer_11",
      "parameters": 1048576,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Whisper_Base_op_121",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer11_self_attn_layer_norm",
      "layer": "layer_11",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_122",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer11_final_layer_norm",
      "layer": "layer_11",
      "parameters": 1024,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "Whisper_Base_op_123",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Whisper_Base_op_124",
      "model_name": "Whisper-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_1",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Embedding",
      "name": "word_embeddings",
      "layer": "global",
      "parameters": 24576,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_2",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Embedding",
      "name": "position_embeddings",
      "layer": "global",
      "parameters": 24576,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_3",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Embedding",
      "name": "token_type_embeddings",
      "layer": "global",
      "parameters": 1536,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_4",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "embeddings_layernorm",
      "layer": "global",
      "parameters": 64,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_5",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "pooler_dense",
      "layer": "global",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_6",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Tanh",
      "name": "pooler_activation",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_7",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer0_query",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_8",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer0_key",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_9",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer0_value",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_10",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer0_dense_attention",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_11",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer0_dense_intermediate",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_12",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer0_dense_output",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_13",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer0_attention_layernorm",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_14",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer0_output_layernorm",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_15",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_16",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_17",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer0_attention_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_18",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer0_output_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_19",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer1_query",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_20",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer1_key",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_21",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer1_value",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_22",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer1_dense_attention",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_23",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer1_dense_intermediate",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_24",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer1_dense_output",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_25",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer1_attention_layernorm",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_26",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer1_output_layernorm",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_27",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_28",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_29",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer1_attention_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_30",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer1_output_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_31",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer2_query",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_32",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer2_key",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_33",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer2_value",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_34",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer2_dense_attention",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_35",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer2_dense_intermediate",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_36",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer2_dense_output",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_37",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer2_attention_layernorm",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_38",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer2_output_layernorm",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_39",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_40",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_41",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer2_attention_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_42",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer2_output_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_43",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer3_query",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_44",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer3_key",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_45",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer3_value",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_46",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer3_dense_attention",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_47",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer3_dense_intermediate",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_48",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer3_dense_output",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_49",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer3_attention_layernorm",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_50",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer3_output_layernorm",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_51",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_52",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_53",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer3_attention_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_54",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer3_output_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_55",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer4_query",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_56",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer4_key",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_57",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer4_value",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_58",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer4_dense_attention",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_59",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer4_dense_intermediate",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_60",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer4_dense_output",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_61",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer4_attention_layernorm",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_62",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer4_output_layernorm",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_63",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_64",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_65",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer4_attention_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_66",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer4_output_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_67",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer5_query",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_68",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer5_key",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_69",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer5_value",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_70",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer5_dense_attention",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_71",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer5_dense_intermediate",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_72",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer5_dense_output",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_73",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer5_attention_layernorm",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_74",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer5_output_layernorm",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_75",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_76",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_77",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer5_attention_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_78",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer5_output_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_79",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer6_query",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_80",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer6_key",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_81",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer6_value",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_82",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer6_dense_attention",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_83",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer6_dense_intermediate",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_84",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer6_dense_output",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_85",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer6_attention_layernorm",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_86",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer6_output_layernorm",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_87",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_88",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_89",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer6_attention_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_90",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer6_output_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_91",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer7_query",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_92",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer7_key",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_93",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer7_value",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_94",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer7_dense_attention",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_95",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer7_dense_intermediate",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_96",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer7_dense_output",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_97",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer7_attention_layernorm",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_98",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer7_output_layernorm",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_99",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_100",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_101",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer7_attention_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_102",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer7_output_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_103",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer8_query",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_104",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer8_key",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_105",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer8_value",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_106",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer8_dense_attention",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_107",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer8_dense_intermediate",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_108",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer8_dense_output",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_109",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer8_attention_layernorm",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_110",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer8_output_layernorm",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_111",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_112",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_113",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer8_attention_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_114",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer8_output_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_115",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer9_query",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_116",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer9_key",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_117",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer9_value",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_118",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer9_dense_attention",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_119",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer9_dense_intermediate",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_120",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer9_dense_output",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_121",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer9_attention_layernorm",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_122",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer9_output_layernorm",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_123",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_124",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_125",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer9_attention_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_126",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer9_output_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_127",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer10_query",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_128",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer10_key",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_129",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer10_value",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_130",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer10_dense_attention",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_131",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer10_dense_intermediate",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_132",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer10_dense_output",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_133",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer10_attention_layernorm",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_134",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer10_output_layernorm",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_135",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_136",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_137",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer10_attention_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_138",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer10_output_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_139",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer11_query",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_140",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer11_key",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_141",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer11_value",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_142",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer11_dense_attention",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_143",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer11_dense_intermediate",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_144",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Linear",
      "name": "layer11_dense_output",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_145",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer11_attention_layernorm",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_146",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "LayerNorm",
      "name": "layer11_output_layernorm",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_147",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_148",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "GELU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_149",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer11_attention_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "Wav2Vec2_Base_op_150",
      "model_name": "Wav2Vec2-Base",
      "model_category": "Audio",
      "type": "Dropout",
      "name": "layer11_output_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_1",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Conv2d",
      "name": "patch_embedding",
      "layer": "global",
      "parameters": 5624410669056,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_2",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Embedding",
      "name": "token_embedding",
      "layer": "global",
      "parameters": 37945344,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_3",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Embedding",
      "name": "position_embedding",
      "layer": "global",
      "parameters": 37945344,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_4",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "pre_layernorm",
      "layer": "global",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_5",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "post_layernorm",
      "layer": "global",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_6",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "visual_projection",
      "layer": "global",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_7",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "text_projection",
      "layer": "global",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_8",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_q_proj",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_9",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_k_proj",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_10",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_v_proj",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_11",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_out_proj",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_12",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_fc1",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_13",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer0_fc2",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_14",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer0_layer_norm1",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_15",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer0_layer_norm2",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_16",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_17",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_18",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_q_proj",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_19",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_k_proj",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_20",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_v_proj",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_21",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_out_proj",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_22",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_fc1",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_23",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer1_fc2",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_24",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer1_layer_norm1",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_25",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer1_layer_norm2",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_26",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_27",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_28",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_q_proj",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_29",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_k_proj",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_30",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_v_proj",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_31",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_out_proj",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_32",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_fc1",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_33",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer2_fc2",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_34",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer2_layer_norm1",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_35",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer2_layer_norm2",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_36",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_37",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_38",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_q_proj",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_39",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_k_proj",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_40",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_v_proj",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_41",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_out_proj",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_42",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_fc1",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_43",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer3_fc2",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_44",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer3_layer_norm1",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_45",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer3_layer_norm2",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_46",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_47",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_48",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_q_proj",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_49",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_k_proj",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_50",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_v_proj",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_51",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_out_proj",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_52",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_fc1",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_53",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer4_fc2",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_54",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer4_layer_norm1",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_55",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer4_layer_norm2",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_56",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_57",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_58",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_q_proj",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_59",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_k_proj",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_60",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_v_proj",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_61",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_out_proj",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_62",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_fc1",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_63",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer5_fc2",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_64",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer5_layer_norm1",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_65",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer5_layer_norm2",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_66",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_67",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_68",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_q_proj",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_69",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_k_proj",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_70",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_v_proj",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_71",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_out_proj",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_72",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_fc1",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_73",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer6_fc2",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_74",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer6_layer_norm1",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_75",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer6_layer_norm2",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_76",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_77",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_78",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_q_proj",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_79",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_k_proj",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_80",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_v_proj",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_81",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_out_proj",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_82",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_fc1",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_83",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer7_fc2",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_84",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer7_layer_norm1",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_85",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer7_layer_norm2",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_86",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_87",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_88",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_q_proj",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_89",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_k_proj",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_90",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_v_proj",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_91",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_out_proj",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_92",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_fc1",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_93",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer8_fc2",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_94",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer8_layer_norm1",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_95",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer8_layer_norm2",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_96",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_97",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_98",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_q_proj",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_99",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_k_proj",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_100",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_v_proj",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_101",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_out_proj",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_102",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_fc1",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_103",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer9_fc2",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_104",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer9_layer_norm1",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_105",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer9_layer_norm2",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_106",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_107",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_108",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_q_proj",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_109",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_k_proj",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_110",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_v_proj",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_111",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_out_proj",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_112",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_fc1",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_113",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer10_fc2",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_114",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer10_layer_norm1",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_115",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer10_layer_norm2",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_116",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_117",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_118",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_q_proj",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_119",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_k_proj",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_120",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_v_proj",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_121",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_out_proj",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_122",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_fc1",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_123",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Linear",
      "name": "layer11_fc2",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_124",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer11_layer_norm1",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_125",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "LayerNorm",
      "name": "layer11_layer_norm2",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_126",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "CLIP_ViT_B_32_op_127",
      "model_name": "CLIP-ViT-B/32",
      "model_category": "CV",
      "type": "GELU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BLIP_Base_op_1",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Conv2d",
      "name": "patch_embedding",
      "layer": "global",
      "parameters": 2146670383104,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "BLIP_Base_op_2",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Embedding",
      "name": "token_embedding",
      "layer": "global",
      "parameters": 23442432,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_3",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Embedding",
      "name": "position_embedding",
      "layer": "global",
      "parameters": 23442432,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_4",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "pre_layernorm",
      "layer": "global",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_5",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "post_layernorm",
      "layer": "global",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_6",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "visual_projection",
      "layer": "global",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_7",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "text_projection",
      "layer": "global",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_8",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer0_q_proj",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_9",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer0_k_proj",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_10",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer0_v_proj",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_11",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer0_out_proj",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_12",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer0_fc1",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_13",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer0_fc2",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_14",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer0_layer_norm1",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_15",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer0_layer_norm2",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_16",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLIP_Base_op_17",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BLIP_Base_op_18",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer1_q_proj",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_19",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer1_k_proj",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_20",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer1_v_proj",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_21",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer1_out_proj",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_22",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer1_fc1",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_23",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer1_fc2",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_24",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer1_layer_norm1",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_25",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer1_layer_norm2",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_26",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLIP_Base_op_27",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BLIP_Base_op_28",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer2_q_proj",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_29",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer2_k_proj",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_30",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer2_v_proj",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_31",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer2_out_proj",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_32",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer2_fc1",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_33",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer2_fc2",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_34",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer2_layer_norm1",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_35",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer2_layer_norm2",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_36",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLIP_Base_op_37",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BLIP_Base_op_38",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer3_q_proj",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_39",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer3_k_proj",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_40",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer3_v_proj",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_41",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer3_out_proj",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_42",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer3_fc1",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_43",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer3_fc2",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_44",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer3_layer_norm1",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_45",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer3_layer_norm2",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_46",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLIP_Base_op_47",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BLIP_Base_op_48",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer4_q_proj",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_49",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer4_k_proj",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_50",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer4_v_proj",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_51",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer4_out_proj",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_52",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer4_fc1",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_53",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer4_fc2",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_54",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer4_layer_norm1",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_55",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer4_layer_norm2",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_56",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLIP_Base_op_57",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BLIP_Base_op_58",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer5_q_proj",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_59",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer5_k_proj",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_60",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer5_v_proj",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_61",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer5_out_proj",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_62",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer5_fc1",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_63",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer5_fc2",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_64",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer5_layer_norm1",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_65",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer5_layer_norm2",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_66",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLIP_Base_op_67",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BLIP_Base_op_68",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer6_q_proj",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_69",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer6_k_proj",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_70",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer6_v_proj",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_71",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer6_out_proj",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_72",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer6_fc1",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_73",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer6_fc2",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_74",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer6_layer_norm1",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_75",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer6_layer_norm2",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_76",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLIP_Base_op_77",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BLIP_Base_op_78",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer7_q_proj",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_79",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer7_k_proj",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_80",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer7_v_proj",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_81",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer7_out_proj",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_82",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer7_fc1",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_83",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer7_fc2",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_84",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer7_layer_norm1",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_85",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer7_layer_norm2",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_86",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLIP_Base_op_87",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BLIP_Base_op_88",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer8_q_proj",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_89",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer8_k_proj",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_90",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer8_v_proj",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_91",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer8_out_proj",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_92",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer8_fc1",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_93",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer8_fc2",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_94",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer8_layer_norm1",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_95",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer8_layer_norm2",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_96",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLIP_Base_op_97",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BLIP_Base_op_98",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer9_q_proj",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_99",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer9_k_proj",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_100",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer9_v_proj",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_101",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer9_out_proj",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_102",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer9_fc1",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_103",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer9_fc2",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_104",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer9_layer_norm1",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_105",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer9_layer_norm2",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_106",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLIP_Base_op_107",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BLIP_Base_op_108",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer10_q_proj",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_109",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer10_k_proj",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_110",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer10_v_proj",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_111",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer10_out_proj",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_112",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer10_fc1",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_113",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer10_fc2",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_114",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer10_layer_norm1",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_115",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer10_layer_norm2",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_116",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLIP_Base_op_117",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "BLIP_Base_op_118",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer11_q_proj",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_119",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer11_k_proj",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_120",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer11_v_proj",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_121",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer11_out_proj",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_122",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer11_fc1",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_123",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer11_fc2",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BLIP_Base_op_124",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer11_layer_norm1",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_125",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer11_layer_norm2",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "BLIP_Base_op_126",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BLIP_Base_op_127",
      "model_name": "BLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "SigLIP_Base_op_1",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Conv2d",
      "name": "patch_embedding",
      "layer": "global",
      "parameters": 2359296000000,
      "input_shape": "[batch, C_in, H, W]",
      "output_shape": "[batch, C_out, H', W']"
    },
    {
      "op_id": "SigLIP_Base_op_2",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Embedding",
      "name": "token_embedding",
      "layer": "global",
      "parameters": 24576000,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_3",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Embedding",
      "name": "position_embedding",
      "layer": "global",
      "parameters": 24576000,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_4",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "pre_layernorm",
      "layer": "global",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_5",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "post_layernorm",
      "layer": "global",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_6",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "visual_projection",
      "layer": "global",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_7",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "text_projection",
      "layer": "global",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_8",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer0_q_proj",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_9",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer0_k_proj",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_10",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer0_v_proj",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_11",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer0_out_proj",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_12",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer0_fc1",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_13",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer0_fc2",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_14",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer0_layer_norm1",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_15",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer0_layer_norm2",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_16",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "SigLIP_Base_op_17",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "SigLIP_Base_op_18",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer1_q_proj",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_19",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer1_k_proj",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_20",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer1_v_proj",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_21",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer1_out_proj",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_22",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer1_fc1",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_23",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer1_fc2",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_24",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer1_layer_norm1",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_25",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer1_layer_norm2",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_26",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "SigLIP_Base_op_27",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "SigLIP_Base_op_28",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer2_q_proj",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_29",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer2_k_proj",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_30",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer2_v_proj",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_31",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer2_out_proj",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_32",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer2_fc1",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_33",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer2_fc2",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_34",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer2_layer_norm1",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_35",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer2_layer_norm2",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_36",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "SigLIP_Base_op_37",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "SigLIP_Base_op_38",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer3_q_proj",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_39",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer3_k_proj",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_40",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer3_v_proj",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_41",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer3_out_proj",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_42",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer3_fc1",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_43",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer3_fc2",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_44",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer3_layer_norm1",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_45",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer3_layer_norm2",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_46",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "SigLIP_Base_op_47",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "SigLIP_Base_op_48",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer4_q_proj",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_49",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer4_k_proj",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_50",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer4_v_proj",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_51",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer4_out_proj",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_52",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer4_fc1",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_53",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer4_fc2",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_54",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer4_layer_norm1",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_55",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer4_layer_norm2",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_56",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "SigLIP_Base_op_57",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "SigLIP_Base_op_58",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer5_q_proj",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_59",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer5_k_proj",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_60",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer5_v_proj",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_61",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer5_out_proj",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_62",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer5_fc1",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_63",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer5_fc2",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_64",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer5_layer_norm1",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_65",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer5_layer_norm2",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_66",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "SigLIP_Base_op_67",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "SigLIP_Base_op_68",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer6_q_proj",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_69",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer6_k_proj",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_70",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer6_v_proj",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_71",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer6_out_proj",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_72",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer6_fc1",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_73",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer6_fc2",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_74",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer6_layer_norm1",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_75",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer6_layer_norm2",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_76",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "SigLIP_Base_op_77",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "SigLIP_Base_op_78",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer7_q_proj",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_79",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer7_k_proj",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_80",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer7_v_proj",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_81",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer7_out_proj",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_82",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer7_fc1",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_83",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer7_fc2",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_84",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer7_layer_norm1",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_85",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer7_layer_norm2",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_86",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "SigLIP_Base_op_87",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "SigLIP_Base_op_88",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer8_q_proj",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_89",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer8_k_proj",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_90",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer8_v_proj",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_91",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer8_out_proj",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_92",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer8_fc1",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_93",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer8_fc2",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_94",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer8_layer_norm1",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_95",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer8_layer_norm2",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_96",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "SigLIP_Base_op_97",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "SigLIP_Base_op_98",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer9_q_proj",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_99",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer9_k_proj",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_100",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer9_v_proj",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_101",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer9_out_proj",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_102",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer9_fc1",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_103",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer9_fc2",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_104",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer9_layer_norm1",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_105",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer9_layer_norm2",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_106",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "SigLIP_Base_op_107",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "SigLIP_Base_op_108",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer10_q_proj",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_109",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer10_k_proj",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_110",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer10_v_proj",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_111",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer10_out_proj",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_112",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer10_fc1",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_113",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer10_fc2",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_114",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer10_layer_norm1",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_115",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer10_layer_norm2",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_116",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "SigLIP_Base_op_117",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "SigLIP_Base_op_118",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer11_q_proj",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_119",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer11_k_proj",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_120",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer11_v_proj",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_121",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer11_out_proj",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_122",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer11_fc1",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_123",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Linear",
      "name": "layer11_fc2",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "SigLIP_Base_op_124",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer11_layer_norm1",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_125",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "LayerNorm",
      "name": "layer11_layer_norm2",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "SigLIP_Base_op_126",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "SigLIP_Base_op_127",
      "model_name": "SigLIP-Base",
      "model_category": "Multimodal",
      "type": "GELU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DistilBERT_Base_op_1",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "word_embeddings",
      "layer": "global",
      "parameters": 23440896,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_2",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "position_embeddings",
      "layer": "global",
      "parameters": 23440896,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_3",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "token_type_embeddings",
      "layer": "global",
      "parameters": 1536,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_4",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "embeddings_layernorm",
      "layer": "global",
      "parameters": 61044,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_5",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "pooler_dense",
      "layer": "global",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_6",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Tanh",
      "name": "pooler_activation",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_7",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_query",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_8",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_key",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_9",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_value",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_10",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_attention",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_11",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_intermediate",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_12",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_output",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_13",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer0_attention_layernorm",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_14",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer0_output_layernorm",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_15",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DistilBERT_Base_op_16",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DistilBERT_Base_op_17",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer0_attention_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_18",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer0_output_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_19",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_query",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_20",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_key",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_21",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_value",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_22",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_attention",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_23",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_intermediate",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_24",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_output",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_25",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer1_attention_layernorm",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_26",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer1_output_layernorm",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_27",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DistilBERT_Base_op_28",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DistilBERT_Base_op_29",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer1_attention_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_30",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer1_output_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_31",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_query",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_32",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_key",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_33",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_value",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_34",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_dense_attention",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_35",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_dense_intermediate",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_36",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_dense_output",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_37",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer2_attention_layernorm",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_38",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer2_output_layernorm",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_39",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DistilBERT_Base_op_40",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DistilBERT_Base_op_41",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer2_attention_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_42",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer2_output_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_43",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_query",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_44",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_key",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_45",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_value",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_46",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_dense_attention",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_47",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_dense_intermediate",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_48",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_dense_output",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_49",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer3_attention_layernorm",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_50",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer3_output_layernorm",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_51",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DistilBERT_Base_op_52",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DistilBERT_Base_op_53",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer3_attention_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_54",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer3_output_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_55",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_query",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_56",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_key",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_57",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_value",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_58",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_dense_attention",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_59",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_dense_intermediate",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_60",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_dense_output",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_61",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer4_attention_layernorm",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_62",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer4_output_layernorm",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_63",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DistilBERT_Base_op_64",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DistilBERT_Base_op_65",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer4_attention_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_66",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer4_output_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_67",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_query",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_68",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_key",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_69",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_value",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_70",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_dense_attention",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_71",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_dense_intermediate",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_72",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_dense_output",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "DistilBERT_Base_op_73",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer5_attention_layernorm",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_74",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer5_output_layernorm",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_75",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "DistilBERT_Base_op_76",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "DistilBERT_Base_op_77",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer5_attention_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "DistilBERT_Base_op_78",
      "model_name": "DistilBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer5_output_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_1",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "word_embeddings",
      "layer": "global",
      "parameters": 23040000,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_2",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "position_embeddings",
      "layer": "global",
      "parameters": 23040000,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_3",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "token_type_embeddings",
      "layer": "global",
      "parameters": 1536,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_4",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "embeddings_layernorm",
      "layer": "global",
      "parameters": 60000,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_5",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "pooler_dense",
      "layer": "global",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_6",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Tanh",
      "name": "pooler_activation",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_7",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_query",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_8",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_key",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_9",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_value",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_10",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_attention",
      "layer": "layer_0",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_11",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_intermediate",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_12",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_output",
      "layer": "layer_0",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_13",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer0_attention_layernorm",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_14",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer0_output_layernorm",
      "layer": "layer_0",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_15",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ALBERT_Base_op_16",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ALBERT_Base_op_17",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer0_attention_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_18",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer0_output_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_19",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_query",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_20",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_key",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_21",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_value",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_22",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_attention",
      "layer": "layer_1",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_23",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_intermediate",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_24",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_output",
      "layer": "layer_1",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_25",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer1_attention_layernorm",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_26",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer1_output_layernorm",
      "layer": "layer_1",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_27",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ALBERT_Base_op_28",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ALBERT_Base_op_29",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer1_attention_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_30",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer1_output_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_31",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_query",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_32",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_key",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_33",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_value",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_34",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_dense_attention",
      "layer": "layer_2",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_35",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_dense_intermediate",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_36",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_dense_output",
      "layer": "layer_2",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_37",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer2_attention_layernorm",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_38",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer2_output_layernorm",
      "layer": "layer_2",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_39",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ALBERT_Base_op_40",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ALBERT_Base_op_41",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer2_attention_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_42",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer2_output_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_43",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_query",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_44",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_key",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_45",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_value",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_46",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_dense_attention",
      "layer": "layer_3",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_47",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_dense_intermediate",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_48",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_dense_output",
      "layer": "layer_3",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_49",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer3_attention_layernorm",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_50",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer3_output_layernorm",
      "layer": "layer_3",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_51",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ALBERT_Base_op_52",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ALBERT_Base_op_53",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer3_attention_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_54",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer3_output_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_55",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_query",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_56",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_key",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_57",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_value",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_58",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_dense_attention",
      "layer": "layer_4",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_59",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_dense_intermediate",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_60",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer4_dense_output",
      "layer": "layer_4",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_61",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer4_attention_layernorm",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_62",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer4_output_layernorm",
      "layer": "layer_4",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_63",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ALBERT_Base_op_64",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ALBERT_Base_op_65",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer4_attention_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_66",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer4_output_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_67",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_query",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_68",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_key",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_69",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_value",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_70",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_dense_attention",
      "layer": "layer_5",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_71",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_dense_intermediate",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_72",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer5_dense_output",
      "layer": "layer_5",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_73",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer5_attention_layernorm",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_74",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer5_output_layernorm",
      "layer": "layer_5",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_75",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ALBERT_Base_op_76",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ALBERT_Base_op_77",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer5_attention_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_78",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer5_output_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_79",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_query",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_80",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_key",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_81",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_value",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_82",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_dense_attention",
      "layer": "layer_6",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_83",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_dense_intermediate",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_84",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer6_dense_output",
      "layer": "layer_6",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_85",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer6_attention_layernorm",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_86",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer6_output_layernorm",
      "layer": "layer_6",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_87",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ALBERT_Base_op_88",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ALBERT_Base_op_89",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer6_attention_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_90",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer6_output_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_91",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_query",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_92",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_key",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_93",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_value",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_94",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_dense_attention",
      "layer": "layer_7",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_95",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_dense_intermediate",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_96",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer7_dense_output",
      "layer": "layer_7",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_97",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer7_attention_layernorm",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_98",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer7_output_layernorm",
      "layer": "layer_7",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_99",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ALBERT_Base_op_100",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ALBERT_Base_op_101",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer7_attention_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_102",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer7_output_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_103",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_query",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_104",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_key",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_105",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_value",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_106",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_dense_attention",
      "layer": "layer_8",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_107",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_dense_intermediate",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_108",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer8_dense_output",
      "layer": "layer_8",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_109",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer8_attention_layernorm",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_110",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer8_output_layernorm",
      "layer": "layer_8",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_111",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ALBERT_Base_op_112",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ALBERT_Base_op_113",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer8_attention_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_114",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer8_output_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_115",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_query",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_116",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_key",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_117",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_value",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_118",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_dense_attention",
      "layer": "layer_9",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_119",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_dense_intermediate",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_120",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer9_dense_output",
      "layer": "layer_9",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_121",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer9_attention_layernorm",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_122",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer9_output_layernorm",
      "layer": "layer_9",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_123",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ALBERT_Base_op_124",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ALBERT_Base_op_125",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer9_attention_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_126",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer9_output_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_127",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_query",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_128",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_key",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_129",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_value",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_130",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_dense_attention",
      "layer": "layer_10",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_131",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_dense_intermediate",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_132",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer10_dense_output",
      "layer": "layer_10",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_133",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer10_attention_layernorm",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_134",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer10_output_layernorm",
      "layer": "layer_10",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_135",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ALBERT_Base_op_136",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ALBERT_Base_op_137",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer10_attention_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_138",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer10_output_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_139",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_query",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_140",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_key",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_141",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_value",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_142",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_dense_attention",
      "layer": "layer_11",
      "parameters": 589824,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_143",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_dense_intermediate",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_144",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer11_dense_output",
      "layer": "layer_11",
      "parameters": 2359296,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "ALBERT_Base_op_145",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer11_attention_layernorm",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_146",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer11_output_layernorm",
      "layer": "layer_11",
      "parameters": 1536,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_147",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "ALBERT_Base_op_148",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 3072]",
      "output_shape": "[batch, seq, 3072]"
    },
    {
      "op_id": "ALBERT_Base_op_149",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer11_attention_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "ALBERT_Base_op_150",
      "model_name": "ALBERT-Base",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer11_output_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 768]",
      "output_shape": "[batch, seq, 768]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_1",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Embedding",
      "name": "wte",
      "layer": "global",
      "parameters": 4194304,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_2",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Embedding",
      "name": "wpe",
      "layer": "global",
      "parameters": 4194304,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_3",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "ln_f",
      "layer": "global",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_4",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_attn",
      "layer": "layer_0",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_5",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_proj",
      "layer": "layer_0",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_6",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_fc",
      "layer": "layer_0",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_7",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer0_c_proj_mlp",
      "layer": "layer_0",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_8",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer0_ln_1",
      "layer": "layer_0",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_9",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer0_ln_2",
      "layer": "layer_0",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_10",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_11",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_12",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer0_attn_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_13",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer0_resid_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_14",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_attn",
      "layer": "layer_1",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_15",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_proj",
      "layer": "layer_1",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_16",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_fc",
      "layer": "layer_1",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_17",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer1_c_proj_mlp",
      "layer": "layer_1",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_18",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer1_ln_1",
      "layer": "layer_1",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_19",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer1_ln_2",
      "layer": "layer_1",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_20",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_21",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_22",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer1_attn_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_23",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer1_resid_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_24",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_attn",
      "layer": "layer_2",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_25",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_proj",
      "layer": "layer_2",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_26",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_fc",
      "layer": "layer_2",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_27",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer2_c_proj_mlp",
      "layer": "layer_2",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_28",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer2_ln_1",
      "layer": "layer_2",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_29",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer2_ln_2",
      "layer": "layer_2",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_30",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_31",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_32",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer2_attn_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_33",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer2_resid_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_34",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_attn",
      "layer": "layer_3",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_35",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_proj",
      "layer": "layer_3",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_36",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_fc",
      "layer": "layer_3",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_37",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer3_c_proj_mlp",
      "layer": "layer_3",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_38",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer3_ln_1",
      "layer": "layer_3",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_39",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer3_ln_2",
      "layer": "layer_3",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_40",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_41",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_42",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer3_attn_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_43",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer3_resid_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_44",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_attn",
      "layer": "layer_4",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_45",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_proj",
      "layer": "layer_4",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_46",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_fc",
      "layer": "layer_4",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_47",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer4_c_proj_mlp",
      "layer": "layer_4",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_48",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer4_ln_1",
      "layer": "layer_4",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_49",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer4_ln_2",
      "layer": "layer_4",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_50",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer4_attention_softmax",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_51",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer4_activation",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_52",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer4_attn_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_53",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer4_resid_dropout",
      "layer": "layer_4",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_54",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_attn",
      "layer": "layer_5",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_55",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_proj",
      "layer": "layer_5",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_56",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_fc",
      "layer": "layer_5",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_57",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer5_c_proj_mlp",
      "layer": "layer_5",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_58",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer5_ln_1",
      "layer": "layer_5",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_59",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer5_ln_2",
      "layer": "layer_5",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_60",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer5_attention_softmax",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_61",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer5_activation",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_62",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer5_attn_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_63",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer5_resid_dropout",
      "layer": "layer_5",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_64",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_attn",
      "layer": "layer_6",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_65",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_proj",
      "layer": "layer_6",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_66",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_fc",
      "layer": "layer_6",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_67",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer6_c_proj_mlp",
      "layer": "layer_6",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_68",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer6_ln_1",
      "layer": "layer_6",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_69",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer6_ln_2",
      "layer": "layer_6",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_70",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer6_attention_softmax",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_71",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer6_activation",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_72",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer6_attn_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_73",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer6_resid_dropout",
      "layer": "layer_6",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_74",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_attn",
      "layer": "layer_7",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_75",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_proj",
      "layer": "layer_7",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_76",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_fc",
      "layer": "layer_7",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_77",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer7_c_proj_mlp",
      "layer": "layer_7",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_78",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer7_ln_1",
      "layer": "layer_7",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_79",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer7_ln_2",
      "layer": "layer_7",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_80",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer7_attention_softmax",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_81",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer7_activation",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_82",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer7_attn_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_83",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer7_resid_dropout",
      "layer": "layer_7",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_84",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_attn",
      "layer": "layer_8",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_85",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_proj",
      "layer": "layer_8",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_86",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_fc",
      "layer": "layer_8",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_87",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer8_c_proj_mlp",
      "layer": "layer_8",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_88",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer8_ln_1",
      "layer": "layer_8",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_89",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer8_ln_2",
      "layer": "layer_8",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_90",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer8_attention_softmax",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_91",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer8_activation",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_92",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer8_attn_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_93",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer8_resid_dropout",
      "layer": "layer_8",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_94",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_attn",
      "layer": "layer_9",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_95",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_proj",
      "layer": "layer_9",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_96",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_fc",
      "layer": "layer_9",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_97",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer9_c_proj_mlp",
      "layer": "layer_9",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_98",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer9_ln_1",
      "layer": "layer_9",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_99",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer9_ln_2",
      "layer": "layer_9",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_100",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer9_attention_softmax",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_101",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer9_activation",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_102",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer9_attn_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_103",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer9_resid_dropout",
      "layer": "layer_9",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_104",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_attn",
      "layer": "layer_10",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_105",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_proj",
      "layer": "layer_10",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_106",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_fc",
      "layer": "layer_10",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_107",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer10_c_proj_mlp",
      "layer": "layer_10",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_108",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer10_ln_1",
      "layer": "layer_10",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_109",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer10_ln_2",
      "layer": "layer_10",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_110",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer10_attention_softmax",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_111",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer10_activation",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_112",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer10_attn_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_113",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer10_resid_dropout",
      "layer": "layer_10",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_114",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_attn",
      "layer": "layer_11",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_115",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_proj",
      "layer": "layer_11",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_116",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_fc",
      "layer": "layer_11",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_117",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer11_c_proj_mlp",
      "layer": "layer_11",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_118",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer11_ln_1",
      "layer": "layer_11",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_119",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer11_ln_2",
      "layer": "layer_11",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_120",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer11_attention_softmax",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_121",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer11_activation",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_122",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer11_attn_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_123",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer11_resid_dropout",
      "layer": "layer_11",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_124",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_c_attn",
      "layer": "layer_12",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_125",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_c_proj",
      "layer": "layer_12",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_126",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_c_fc",
      "layer": "layer_12",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_127",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer12_c_proj_mlp",
      "layer": "layer_12",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_128",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer12_ln_1",
      "layer": "layer_12",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_129",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer12_ln_2",
      "layer": "layer_12",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_130",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer12_attention_softmax",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_131",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer12_activation",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_132",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer12_attn_dropout",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_133",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer12_resid_dropout",
      "layer": "layer_12",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_134",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_c_attn",
      "layer": "layer_13",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_135",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_c_proj",
      "layer": "layer_13",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_136",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_c_fc",
      "layer": "layer_13",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_137",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer13_c_proj_mlp",
      "layer": "layer_13",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_138",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer13_ln_1",
      "layer": "layer_13",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_139",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer13_ln_2",
      "layer": "layer_13",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_140",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer13_attention_softmax",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_141",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer13_activation",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_142",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer13_attn_dropout",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_143",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer13_resid_dropout",
      "layer": "layer_13",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_144",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_c_attn",
      "layer": "layer_14",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_145",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_c_proj",
      "layer": "layer_14",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_146",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_c_fc",
      "layer": "layer_14",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_147",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer14_c_proj_mlp",
      "layer": "layer_14",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_148",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer14_ln_1",
      "layer": "layer_14",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_149",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer14_ln_2",
      "layer": "layer_14",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_150",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer14_attention_softmax",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_151",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer14_activation",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_152",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer14_attn_dropout",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_153",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer14_resid_dropout",
      "layer": "layer_14",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_154",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_c_attn",
      "layer": "layer_15",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_155",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_c_proj",
      "layer": "layer_15",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_156",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_c_fc",
      "layer": "layer_15",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_157",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer15_c_proj_mlp",
      "layer": "layer_15",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_158",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer15_ln_1",
      "layer": "layer_15",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_159",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer15_ln_2",
      "layer": "layer_15",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_160",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer15_attention_softmax",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_161",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer15_activation",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_162",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer15_attn_dropout",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_163",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer15_resid_dropout",
      "layer": "layer_15",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_164",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_c_attn",
      "layer": "layer_16",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_165",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_c_proj",
      "layer": "layer_16",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_166",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_c_fc",
      "layer": "layer_16",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_167",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer16_c_proj_mlp",
      "layer": "layer_16",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_168",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer16_ln_1",
      "layer": "layer_16",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_169",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer16_ln_2",
      "layer": "layer_16",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_170",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer16_attention_softmax",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_171",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer16_activation",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_172",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer16_attn_dropout",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_173",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer16_resid_dropout",
      "layer": "layer_16",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_174",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_c_attn",
      "layer": "layer_17",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_175",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_c_proj",
      "layer": "layer_17",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_176",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_c_fc",
      "layer": "layer_17",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_177",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer17_c_proj_mlp",
      "layer": "layer_17",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_178",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer17_ln_1",
      "layer": "layer_17",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_179",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer17_ln_2",
      "layer": "layer_17",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_180",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer17_attention_softmax",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_181",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer17_activation",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_182",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer17_attn_dropout",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_183",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer17_resid_dropout",
      "layer": "layer_17",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_184",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_c_attn",
      "layer": "layer_18",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_185",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_c_proj",
      "layer": "layer_18",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_186",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_c_fc",
      "layer": "layer_18",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_187",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer18_c_proj_mlp",
      "layer": "layer_18",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_188",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer18_ln_1",
      "layer": "layer_18",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_189",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer18_ln_2",
      "layer": "layer_18",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_190",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer18_attention_softmax",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_191",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer18_activation",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_192",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer18_attn_dropout",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_193",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer18_resid_dropout",
      "layer": "layer_18",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_194",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_c_attn",
      "layer": "layer_19",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_195",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_c_proj",
      "layer": "layer_19",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_196",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_c_fc",
      "layer": "layer_19",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_197",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer19_c_proj_mlp",
      "layer": "layer_19",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_198",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer19_ln_1",
      "layer": "layer_19",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_199",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer19_ln_2",
      "layer": "layer_19",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_200",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer19_attention_softmax",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_201",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer19_activation",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_202",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer19_attn_dropout",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_203",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer19_resid_dropout",
      "layer": "layer_19",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_204",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_c_attn",
      "layer": "layer_20",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_205",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_c_proj",
      "layer": "layer_20",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_206",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_c_fc",
      "layer": "layer_20",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_207",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer20_c_proj_mlp",
      "layer": "layer_20",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_208",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer20_ln_1",
      "layer": "layer_20",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_209",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer20_ln_2",
      "layer": "layer_20",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_210",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer20_attention_softmax",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_211",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer20_activation",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_212",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer20_attn_dropout",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_213",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer20_resid_dropout",
      "layer": "layer_20",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_214",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_c_attn",
      "layer": "layer_21",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_215",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_c_proj",
      "layer": "layer_21",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_216",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_c_fc",
      "layer": "layer_21",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_217",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer21_c_proj_mlp",
      "layer": "layer_21",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_218",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer21_ln_1",
      "layer": "layer_21",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_219",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer21_ln_2",
      "layer": "layer_21",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_220",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer21_attention_softmax",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_221",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer21_activation",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_222",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer21_attn_dropout",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_223",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer21_resid_dropout",
      "layer": "layer_21",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_224",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_c_attn",
      "layer": "layer_22",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_225",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_c_proj",
      "layer": "layer_22",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_226",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_c_fc",
      "layer": "layer_22",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_227",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer22_c_proj_mlp",
      "layer": "layer_22",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_228",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer22_ln_1",
      "layer": "layer_22",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_229",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer22_ln_2",
      "layer": "layer_22",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_230",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer22_attention_softmax",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_231",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer22_activation",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_232",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer22_attn_dropout",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_233",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer22_resid_dropout",
      "layer": "layer_22",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_234",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_c_attn",
      "layer": "layer_23",
      "parameters": 12582912,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_235",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_c_proj",
      "layer": "layer_23",
      "parameters": 4194304,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_236",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_c_fc",
      "layer": "layer_23",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_237",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Linear",
      "name": "layer23_c_proj_mlp",
      "layer": "layer_23",
      "parameters": 16777216,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_238",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer23_ln_1",
      "layer": "layer_23",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_239",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "LayerNorm",
      "name": "layer23_ln_2",
      "layer": "layer_23",
      "parameters": 4096,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_240",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Softmax",
      "name": "layer23_attention_softmax",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_241",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "GELU",
      "name": "layer23_activation",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 8192]",
      "output_shape": "[batch, seq, 8192]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_242",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer23_attn_dropout",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "GPT_Neo_1.3B_op_243",
      "model_name": "GPT-Neo-1.3B",
      "model_category": "LLM",
      "type": "Dropout",
      "name": "layer23_resid_dropout",
      "layer": "layer_23",
      "parameters": 0,
      "input_shape": "[batch, seq, 2048]",
      "output_shape": "[batch, seq, 2048]"
    },
    {
      "op_id": "BERT_Tiny_op_1",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "word_embeddings",
      "layer": "global",
      "parameters": 3906816,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 128]"
    },
    {
      "op_id": "BERT_Tiny_op_2",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "position_embeddings",
      "layer": "global",
      "parameters": 3906816,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 128]"
    },
    {
      "op_id": "BERT_Tiny_op_3",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "token_type_embeddings",
      "layer": "global",
      "parameters": 256,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 128]"
    },
    {
      "op_id": "BERT_Tiny_op_4",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "embeddings_layernorm",
      "layer": "global",
      "parameters": 61044,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, 128]"
    },
    {
      "op_id": "BERT_Tiny_op_5",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Linear",
      "name": "pooler_dense",
      "layer": "global",
      "parameters": 16384,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Tiny_op_6",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Tanh",
      "name": "pooler_activation",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, 128]"
    },
    {
      "op_id": "BERT_Tiny_op_7",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_query",
      "layer": "layer_0",
      "parameters": 16384,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Tiny_op_8",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_key",
      "layer": "layer_0",
      "parameters": 16384,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Tiny_op_9",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_value",
      "layer": "layer_0",
      "parameters": 16384,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Tiny_op_10",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_attention",
      "layer": "layer_0",
      "parameters": 16384,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Tiny_op_11",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_intermediate",
      "layer": "layer_0",
      "parameters": 65536,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Tiny_op_12",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_output",
      "layer": "layer_0",
      "parameters": 65536,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Tiny_op_13",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer0_attention_layernorm",
      "layer": "layer_0",
      "parameters": 256,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, 128]"
    },
    {
      "op_id": "BERT_Tiny_op_14",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer0_output_layernorm",
      "layer": "layer_0",
      "parameters": 256,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, 128]"
    },
    {
      "op_id": "BERT_Tiny_op_15",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BERT_Tiny_op_16",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "BERT_Tiny_op_17",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer0_attention_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, 128]"
    },
    {
      "op_id": "BERT_Tiny_op_18",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer0_output_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, 128]"
    },
    {
      "op_id": "BERT_Tiny_op_19",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_query",
      "layer": "layer_1",
      "parameters": 16384,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Tiny_op_20",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_key",
      "layer": "layer_1",
      "parameters": 16384,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Tiny_op_21",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_value",
      "layer": "layer_1",
      "parameters": 16384,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Tiny_op_22",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_attention",
      "layer": "layer_1",
      "parameters": 16384,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Tiny_op_23",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_intermediate",
      "layer": "layer_1",
      "parameters": 65536,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Tiny_op_24",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_output",
      "layer": "layer_1",
      "parameters": 65536,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Tiny_op_25",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer1_attention_layernorm",
      "layer": "layer_1",
      "parameters": 256,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, 128]"
    },
    {
      "op_id": "BERT_Tiny_op_26",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer1_output_layernorm",
      "layer": "layer_1",
      "parameters": 256,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, 128]"
    },
    {
      "op_id": "BERT_Tiny_op_27",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BERT_Tiny_op_28",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 512]",
      "output_shape": "[batch, seq, 512]"
    },
    {
      "op_id": "BERT_Tiny_op_29",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer1_attention_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, 128]"
    },
    {
      "op_id": "BERT_Tiny_op_30",
      "model_name": "BERT-Tiny",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer1_output_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 128]",
      "output_shape": "[batch, seq, 128]"
    },
    {
      "op_id": "BERT_Mini_op_1",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "word_embeddings",
      "layer": "global",
      "parameters": 7813632,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_2",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "position_embeddings",
      "layer": "global",
      "parameters": 7813632,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_3",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Embedding",
      "name": "token_type_embeddings",
      "layer": "global",
      "parameters": 512,
      "input_shape": "[batch, seq]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_4",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "embeddings_layernorm",
      "layer": "global",
      "parameters": 61044,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_5",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "pooler_dense",
      "layer": "global",
      "parameters": 65536,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_6",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Tanh",
      "name": "pooler_activation",
      "layer": "global",
      "parameters": 0,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_7",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_query",
      "layer": "layer_0",
      "parameters": 65536,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_8",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_key",
      "layer": "layer_0",
      "parameters": 65536,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_9",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_value",
      "layer": "layer_0",
      "parameters": 65536,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_10",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_attention",
      "layer": "layer_0",
      "parameters": 65536,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_11",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_intermediate",
      "layer": "layer_0",
      "parameters": 262144,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_12",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer0_dense_output",
      "layer": "layer_0",
      "parameters": 262144,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_13",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer0_attention_layernorm",
      "layer": "layer_0",
      "parameters": 512,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_14",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer0_output_layernorm",
      "layer": "layer_0",
      "parameters": 512,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_15",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer0_attention_softmax",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BERT_Mini_op_16",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer0_activation",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BERT_Mini_op_17",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer0_attention_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_18",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer0_output_dropout",
      "layer": "layer_0",
      "parameters": 0,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_19",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_query",
      "layer": "layer_1",
      "parameters": 65536,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_20",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_key",
      "layer": "layer_1",
      "parameters": 65536,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_21",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_value",
      "layer": "layer_1",
      "parameters": 65536,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_22",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_attention",
      "layer": "layer_1",
      "parameters": 65536,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_23",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_intermediate",
      "layer": "layer_1",
      "parameters": 262144,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_24",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer1_dense_output",
      "layer": "layer_1",
      "parameters": 262144,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_25",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer1_attention_layernorm",
      "layer": "layer_1",
      "parameters": 512,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_26",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer1_output_layernorm",
      "layer": "layer_1",
      "parameters": 512,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_27",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer1_attention_softmax",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BERT_Mini_op_28",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer1_activation",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BERT_Mini_op_29",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer1_attention_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_30",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer1_output_dropout",
      "layer": "layer_1",
      "parameters": 0,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_31",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_query",
      "layer": "layer_2",
      "parameters": 65536,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_32",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_key",
      "layer": "layer_2",
      "parameters": 65536,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_33",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_value",
      "layer": "layer_2",
      "parameters": 65536,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_34",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_dense_attention",
      "layer": "layer_2",
      "parameters": 65536,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_35",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_dense_intermediate",
      "layer": "layer_2",
      "parameters": 262144,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_36",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer2_dense_output",
      "layer": "layer_2",
      "parameters": 262144,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_37",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer2_attention_layernorm",
      "layer": "layer_2",
      "parameters": 512,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_38",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer2_output_layernorm",
      "layer": "layer_2",
      "parameters": 512,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_39",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer2_attention_softmax",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BERT_Mini_op_40",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer2_activation",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BERT_Mini_op_41",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer2_attention_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_42",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer2_output_dropout",
      "layer": "layer_2",
      "parameters": 0,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_43",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_query",
      "layer": "layer_3",
      "parameters": 65536,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_44",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_key",
      "layer": "layer_3",
      "parameters": 65536,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_45",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_value",
      "layer": "layer_3",
      "parameters": 65536,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_46",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_dense_attention",
      "layer": "layer_3",
      "parameters": 65536,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_47",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_dense_intermediate",
      "layer": "layer_3",
      "parameters": 262144,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_48",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Linear",
      "name": "layer3_dense_output",
      "layer": "layer_3",
      "parameters": 262144,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, out_features]"
    },
    {
      "op_id": "BERT_Mini_op_49",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer3_attention_layernorm",
      "layer": "layer_3",
      "parameters": 512,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_50",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "LayerNorm",
      "name": "layer3_output_layernorm",
      "layer": "layer_3",
      "parameters": 512,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_51",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Softmax",
      "name": "layer3_attention_softmax",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, heads, seq, seq]",
      "output_shape": "[batch, heads, seq, seq]"
    },
    {
      "op_id": "BERT_Mini_op_52",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "GELU",
      "name": "layer3_activation",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 1024]",
      "output_shape": "[batch, seq, 1024]"
    },
    {
      "op_id": "BERT_Mini_op_53",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer3_attention_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, 256]"
    },
    {
      "op_id": "BERT_Mini_op_54",
      "model_name": "BERT-Mini",
      "model_category": "NLP",
      "type": "Dropout",
      "name": "layer3_output_dropout",
      "layer": "layer_3",
      "parameters": 0,
      "input_shape": "[batch, seq, 256]",
      "output_shape": "[batch, seq, 256]"
    }
  ]
}